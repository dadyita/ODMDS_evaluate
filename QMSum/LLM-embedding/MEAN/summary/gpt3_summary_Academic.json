[
    "During the meeting, the discussion focused on XML tools, data quality in meetings, and the current XML format for linking up different components in data. The participants talked about the possibility of using XML as an interchange format and the advantages and disadvantages of using XML for different levels of data. They also discussed the idea of using belief-net packages to analyze the data and extract features. They considered different database formats for storing the data, including XML, the P-file format, and the ATLAS format. They discussed the advantages and disadvantages of each format and the importance of compatibility and sharing with other researchers. They also discussed the opinions of F and A on the current XML format. F mentioned that the format was based on a conceptual node annotated transcription graph and that they had developed their own external file format. A suggested finding out if the tools associated with the format would run on the current XML format and if it would be difficult to translate from one format to another. They also discussed the possibility of using a relational database and concluded that a flat file format with search tools would be sufficient. They mentioned the possibility of using the ATLAS external file representation and discussed the advantages and challenges of using it. They also discussed merging annotations from different versions of the data and the difficulty of specifying what is meant by \"merge\". They briefly discussed the P-file format and the potential need for alternatives. Overall, the meeting provided insights into XML tools, data quality, and the current XML format.",
    "During the meeting, the participants discussed the topic of electronics, specifically focusing on uncomfortable headphones and the headaches they caused. They also discussed the potential use of CrossPads for data collection and the usefulness of summaries for querying purposes. The participants debated the best way to generate queries and the importance of capturing visual information during meetings, considering using cameras to capture images of participants and content on the whiteboard. They acknowledged the potential challenges and limitations of these approaches.\n\nThe discussion also revolved around the segment, with participants mentioning the existence of a mailing list for the project and the importance of ensuring that all attendees were on the list. However, they had not yet sent out a note about the mailing list. \n\nThe results from the experiments were briefly mentioned but not discussed in detail. The participants mentioned strange data and how it differed from their intended research. They also discussed the potential usefulness of CrossPads but concluded that it may not be reliable. The idea of using email as a faster and more efficient method of communication was brought up, and the best time to gather information was debated.\n\nThe topic of intentionality was briefly discussed, with participants expressing enjoyment of the group dynamics and interactions during the meeting. They also discussed ways to detect intentionality in the data, such as searching for laughter or signs of happiness.\n\nOverall, the meeting focused on the challenges and strategies for gathering and analyzing data in the field of electronics. The participants discussed the need for a system to generate queries automatically based on summaries and the importance of having a variety of meetings with different levels of overlap and participants. They agreed to gather more data from different groups and explore different formats for higher-level information. They also discussed the importance of non-technical and non-speech people as users to get more realistic results and the need to contact other organizations and researchers for access to their data.\n\nAdditionally, the meeting touched on the topic of intentionality in language and spatial reference. They discussed the importance of intentionality, deep embodied neural differences, and the results of experiments that aligned with anecdotal evidence. The meeting also involved discussions about building a system, including the need for an ontology API or standardized ontology, a parser and analyzer related to grammar, and the possibility of incorporating construction analysis into applied and child language modeling projects. They mentioned the potential addition of new team members, including a doctoral student and undergraduate honors thesis student.\n\nThe meeting also included the sharing of results from experiments, highlighting the overall improvement in error rate across different conditions. They discussed the possibility of combining different approaches and systems for better results and the need for closer analysis of data to understand sources of degradation and potential improvements. They also mentioned the possibility of training neural nets using data from multiple languages and acoustic conditions.\n\nOverall, the meeting encompassed discussions on electronics, the segment, the results from experiments, and the topic of intentionality. It emphasized the ongoing research, the importance of system decisions, and continuously improving language processing systems' accuracy.",
    "The main thesis of the discussion was the evaluation and improvement of speech recognition systems in the Aurora program. The professor expressed their opinions on the potential for improvement in noise separation, the exploration of temporal patterns, and the need for further experiments and documentation. They also discussed ongoing discussions about evaluation criteria and the fifty percent improvement goal. Future work involves running more experiments, exploring alternative techniques, and continuing the evaluation process.\n\nAdditionally, the discussion focused on improving data collection for user-interface design. The professor and participants discussed the use of CrossPads for data collection, the benefits of having participants write summaries and queries after meetings, and the potential use of keywords and note-taking to generate structure and information for the system. The professor also mentioned the importance of communication and collaboration between different parts of the distributed center, as well as the challenges and limitations of data collection. Future work includes suggestions for future data collection and the importance of gathering a variety of recordings for analysis.\n\nFurthermore, the discussion explored the use of meeting summaries and note-taking to generate queries and gather useful information. The professor's opinions were mixed, with some seeing value in using summaries as a starting point for generating queries, while others expressed concerns about the feasibility and usefulness of automatically generating queries from summaries. The professor also discussed the possibility of using CrossPads for data collection and the importance of capturing visual information. Future work involves participants providing their own summaries and generating queries based on their own perceptions of the meeting, as well as further research on how to automatically generate queries from summaries.\n\nIn conclusion, the main thesis of the discussion was the evaluation and improvement of speech recognition systems, as well as the improvement of data collection for user-interface design and the generation of queries from meeting data. The professor expressed various opinions on these topics and discussed the need for further research and experimentation in these areas.",
    "During the meeting, there was a discussion about the discomfort of headphones and the need for a more comfortable design. The participants also discussed the idea of using transcripts and the potential requirements and agreements regarding them. The use of CrossPads for data collection and the possibility of using them to generate summaries were mentioned. The importance of capturing visual information during meetings, such as what is written on the board, was also discussed. It was agreed that summaries could be useful for generating queries and participants would provide summaries after the meeting. Note-taking during the meeting and using digital cameras to capture visual information were considered as possible methods. The participants agreed to explore these options and determine the best approach for capturing and using meeting transcripts.\n\nAnother discussion focused on the transcripts and the requirements and agreement regarding them. One suggestion was to have one or two people provide oral summaries after the meeting. The idea of participants with radio mics recording in separate rooms without hearing each other was also discussed, but concerns were raised about the accuracy of data collected from different perspectives. It was suggested to use the CrossPads system for data collection, but its reliability was questioned, and email was proposed as a more efficient method. The importance of including a variety of perspectives in data collection and gathering different types of information, such as interesting points discussed in the meeting, was emphasized. Action items included finding out about human subject requirements, creating a mailing list, and obtaining the data from specific individuals. The possibility of obtaining text sources related to the meetings and using recording equipment at UW were mentioned. The importance of having a variety of meetings, including technical and administrative, was also highlighted. The meeting concluded with a discussion about the need to process the data effectively.\n\nThe meeting also discussed the types of data, such as political debates and congressional hearings, and how they differ from the meetings they were currently working on. It was agreed that existing data that could be easily transformed for use in speech recognition would be utilized, while newly collected data would be natural meetings. The availability of data collected by CMU and its potential public availability were discussed. The participants agreed to keep in touch with Mark, who was interested in collecting as much data as possible, and to send out a note to inform everyone about the existence of a list.\n\nRegarding the transcripts, it was mentioned that the CMU participants had collected a lot of data, and the transcripts would be made available to all participants. The possibility of editing the transcripts to exclude certain sections was discussed, and a web interface was suggested to allow participants to view and mark sections for exclusion. Privacy concerns were raised, and it was proposed that each participant would have a password to access the transcripts. Participants debated whether editing should be allowed for sections where they were not speaking, with some concerned about others editing their words and others supporting the right to exclude uncomfortable sections. The issue of consent was also mentioned, with the understanding that participants had agreed to have their voices used in the transcripts. The participants agreed to provide the transcripts to all participants",
    "In the meeting, there was discussion about the opinions of PhD F and PhD B on the topic of generating queries automatically. PhD F mentioned that there might be difficulty in generating queries without an interactive system. PhD B suggested using note pads and taking photographs of the whiteboard during the meeting to capture important points of discussion. The group also discussed the possibility of using CrossPads for data collection. \n\nDuring the meeting, PhD F expressed concern about the feasibility of generating queries automatically from summaries. PhD B agreed that it may not be feasible but suggested having a small amount of automatic query generation as a proof of concept. Both PhD F and PhD B agreed that including input from users in generating queries would be important. They also discussed the need for non-technical and non-speech people to test the system for more realistic user feedback.\n\nPhD F raised the question of bias in generating queries based on what is currently important. PhD B suggested including both important and interesting aspects in generating queries. The group also discussed the need for data formats for higher-level information and agreed that PhD F and PhD B would determine the best format. \n\nIn another discussion, PhD F and PhD B did not explicitly express their opinions on generating queries automatically. The meeting focused on discussing various aspects of the SmartKom project and the belief-net system. The PhD students also discussed the availability of data and potential collaboration with the German SmartKom project. \n\nIn a separate meeting, the PhD students discussed the topic of generating queries automatically. PhD F mentioned a project called Deep Map that focused on generating spatial descriptions in different languages. PhD B expressed interest in looking at the differences between German and English in terms of reference frames. The PhD students also discussed the use of ontology API and the possibility of visiting the German AI center or Heidelberg.\n\nIn another meeting, PhD F and PhD B did not specifically express their opinions on generating queries automatically. The discussion mainly focused on the evaluation of the current system and the upcoming evaluation on Wall Street Journal data.\n\nOverall, the opinions of PhD F and PhD B on generating queries automatically were not explicitly discussed in the meetings. However, there were discussions about the feasibility, user input, bias, and data formats related to generating queries.",
    "During the meeting, there was a discussion about latency in the system. The professor had an issue with it because it could potentially affect the usefulness of the system for various applications. The duration of the latency was not specifically mentioned in the meeting. However, the professor mentioned that the more things they can get for the system, the more useful it will be. \n\nThe team mentioned that they have been working on reducing the latency by designing new filters using recursive filters instead of FIR filters. These new filters have shorter delays and have been implemented to improve the latency. They also mentioned that they are planning to add a downsampling filter and an on-line normalization filter to further reduce the latency. \n\nThe team also discussed the possibility of using spectral subtraction from Ericsson and changing the contextual KLT for LDA to improve the system's performance. They mentioned that they want to replace the non-discriminant linear transformation with a discriminant linear transformation to see if it improves over the current system. \n\nAdditionally, the team discussed the possibility of using a third-party VAD (Voice Activity Detection) to determine boundaries for the recognition task. They mentioned that this would separate the VAD from the recognition task and allow for better performance. \n\nOverall, the team had an issue with the latency in the system and discussed various methods to reduce it. They also mentioned the importance of communication and coordination with other team members, particularly Sunil. The duration of the latency was discussed to be around 240 milliseconds, which is within the acceptable range.\n\nDuring the meeting, the discussion on latency in the system was brought up. The professor mentioned that in real situations, the latency needs to be calculated online with a forgetting factor. They also discussed different methods of computing the noise spectrum and determining the signal-to-noise ratio. The professor raised the issue of whether the window used to calculate the signal-to-noise ratio would add to the latency and mentioned that it depends on whether the window extends into the past or the future. They also discussed the challenges of dealing with non-stationary noise and the limitations of spectral subtraction. \n\nIn the second part of the meeting, they discussed a research proposal on latency in the system and the duration of the latency. They talked about using multi-band systems and different methods for detecting phonetic features. They discussed the use of logistic regressions as low-level detectors and the training process using EM. They also mentioned the challenges of determining the noise spectrum and the benefits of using narrowband information for speech recognition. They also discussed the potential collaboration with another researcher on de-reverberation algorithms for speech recognition. \n\nTowards the end of the meeting, they discussed the need to improve the system's crash issue and the possibility of mapping the location without having people give their names each time. They also discussed the agenda for future meetings, suggesting focusing more on research topics rather than procedural matters. They mentioned the need to discuss the work on locating events and interruptions in speech and other potential research areas. They also mentioned",
    "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the transcription status, the possibility of the computer generating questions and engaging in a dialogue with itself, and the task of crafting a paper. Grad F provided updates on the transcription process and mentioned that IBM had made the tape for the data and it had been sent to the transcribers. Grad E asked about which meetings were being transcribed and suggested using initial data from the SmartKom data collection for transcription.\n\nRegarding storage disks, Grad E mentioned having an 18 gig drive with about 12 gigs of space left. Grad B mentioned the need for more disk space and suggested hanging disks off the new SUN-Blades that had been received. However, the placement of the disks in the machine room and overall space situation needed to be discussed with Dave Johnson.\n\nThere were no specific updates provided by Grad B regarding the meeting on disk storage in the given meeting. However, in a separate meeting, Grad B mentioned the disk space for backed up data being at about 30% on the second disk and the scratch disks for expanded meetings being at about 95-98% full. Grad B suggested hanging disks off the new SUN-Blades in the machine room for additional space, but the final decision on disk placement would need to be discussed with Dave Johnson.\n\nOverall, the meeting covered various topics including the transcription status, roles of the computer and wizard, storage disk issues, and updates on the meeting on disk storage. Grad E contributed to the discussion on storage disks by mentioning the available drive space. However, there was no specific information about Grad E's contribution to the discussion in the given meeting.",
    "SmartKom is an architecture that consists of various modules, including a knowledge modeler, function modeler, and action planner. The architecture aims to incorporate deep conceptual semantics and the ability to process and understand language input, make decisions based on that input, and generate appropriate responses. The modules in SmartKom work together to analyze and interpret input, generate appropriate responses, and provide a seamless user experience. The system also aims to incorporate external services and utilize knowledge bases to enhance its capabilities. Ongoing discussions and plans are focused on further developing and improving the architecture, including integrating syntactic analysis and incorporating more complex slots in the dialogue planning process.\n\nSmartKom is a project that involves the development of an agent with the goal of going to a specific location, along with additional situational information. The architecture of SmartKom includes a belief-net, which combines information from dialogue, ontology, and the situation to make decisions. The modules involved in SmartKom include the belief-net, ontology, user model, dialogue, and situation. The project aims to improve language understanding and generation capabilities, as well as develop a construction analyzer. The team is also working on building their own system and making decisions regarding the ontology and other system-related aspects. The goal is to create a comprehensive and effective system that can handle various tasks and provide accurate and relevant information to users.\n\nSmartKom is an architecture that involves the use of modules to provide smart and interactive communication. The importance of SmartKom lies in its ability to enhance communication and provide personalized assistance to users. The project is progressing with the development of a drive-in thesis, the addition of a new doctoral student, and plans for data collection. The meeting also discussed the importance of formalization and belief nets in the SmartKom project. The team is considering integrating FrameNet and information extraction in the project. Collaboration and integration are highlighted as important aspects of the project.",
    "During the meeting, several options were discussed regarding the location of the recording equipment. The possibility of using an external transcription service, such as Cyber Transcriber, was mentioned, but it was noted that these services may not be able to handle meetings with multiple speakers or provide certain features. Hiring graduate students to transcribe the meetings was also considered, with the going rate estimated to be around $8 to $10 per hour. The transcription conventions were discussed, including marking speaker changes and indicating backchannels, and the potential for automating these conventions was mentioned.\n\nAnother option discussed was to put the recording equipment on a website, potentially using Doctor Speech or a soft link to transcription. It was agreed that having access to the data is important, and the possibility of using a TCL plug-in or Trellix for the website was mentioned. The decision was made to have a website and use HT access to accommodate different needs.\n\nRegarding the actual recording equipment, it was suggested that it be placed under the lip of the table and connected to microphones, with a plastic sleeve to organize the cables. Securing the equipment to prevent tampering and using a user interface with a monitor, such as a laptop with a wireless connection, were also discussed. The idea of using a projector connected to a machine at the back of the room was brought up as well.\n\nThe progress of the demo and preparations for the DARPA meeting were mentioned, with suggestions for conducting a mock-up for question answering and a comparison of saying the same digits at the same or different times. No final decision was made on these tasks.\n\nThe meeting also touched on the progress of the SRI recognizer and experiments with different front-ends. The idea of using principal components analysis (PCA) to reduce the dimensionality of the feature vector was discussed, as well as the potential benefits of combining neural net outputs with regular features. The use of the CrossPad digital notepad during data collection and summarizing the meetings through notes were also mentioned.\n\nIn summary, the options discussed for the location of the recording equipment included using an external transcription service or hiring graduate students. The possibility of putting the equipment on a website and using HT access was decided upon. The actual recording equipment would be placed under the lip of the table and connected to microphones, with a user interface and potential use of a projector. The progress of the demo and preparations for the DARPA meeting were brought up, including ideas for question answering and digit comparisons. The progress of the SRI recognizer and experiments with different front-ends were also mentioned, along with the use of the CrossPad digital notepad and summarizing meetings through notes. No final decision was made on these matters.",
    "During the meeting, there were discussions about various topics including the use of close-talking microphones, the upcoming NIST visit, and the progress of transcriptions. The participants discussed the need for better quality microphones and the standardization of microphone usage to capture clear signals. They also mentioned the NIST visit and the interest in microphone arrays. The transcribers shared their progress and mentioned the time it takes to transcribe meetings. The meeting also touched on the possibility of using the ATLAS system for analyzing the transcriptions. The discussions revolved around improving the quality of recordings and transcriptions, as well as exploring new analysis methods.\n\nThe discussions also focused on the concept of an annotated transcription graph representation and how it could be used to manipulate transcription graphs of various types. The participants talked about a project between NIST and other organizations, including LDC, and the website that provides papers related to this project. The participants mentioned the use of a transcriber pool, which consists of individuals who transcribe audio recordings for IBM's speech recognition products. They discussed the training and qualifications of these transcribers, as well as the level of detail in the transcriptions they provide. There was also a conversation about the potential benefits of having Brian Kingsbury, an individual with knowledge of the project's data requirements, involved in the transcription process. The participants discussed the possibility of using a different direction for transcription, including the use of multi-trans for transcription, and the challenges of obtaining fine-grained time information from the transcriptions. They also discussed the type of transcribers IBM hires and the nature of their training. The participants talked about the difficulties of transcribing conversations and the need for context to understand reduced phonetic words. They also discussed the historical reasons for IBM's involvement in transcription and the potential benefits of expanding the transcription efforts to include more meetings. The participants discussed the potential use of transcribers for other tasks, such as labeling dialogue acts and disfluencies in the transcriptions. They also discussed the possibility of collecting more meeting data, including meetings from different departments or groups that involve heated discussions or arguments. The participants mentioned the interest in having meetings with all English speakers and the challenges of finding meetings that meet this criteria. They also discussed the potential use of transcribers in processing waveforms, such as separating speakers or improving signal-to-noise ratio.\n\nIn addition, the meeting discussed improving the waveform and microphone quality for better acoustic-phonetic analyses. The issue of cross-talk and room acoustics was brought up, and it was mentioned that lapel microphones may have more room acoustic problems. The possibility of using different ASR techniques for improved results was also mentioned.\n\nThe meeting also touched on the use of symbols or graphic symbols to mark different situations during transcription. There was a mention of using different visual displays for speech and non-speech events. The possibility of increasing the flexibility of alignment and using different acoustic events and parameters for transcription was discussed.\n\nThere was also a"
]