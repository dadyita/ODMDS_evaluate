[
    [
        "During the meeting, the discussion revolved around XML tools, data quality in meetings, and the current XML format for linking different components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting.\n\nThe meeting began with a discussion on microphone usage and ensuring that everyone could see which transcript they were on. It was suggested that participants could read digit strings individually rather than simultaneously to improve cognitive focus. The meeting then moved on to discuss the need for multiple versions of data and the importance of indicating the transcript being read.\n\nThe meeting then touched on the wearing of microphones and the importance of positioning them correctly to minimize breath sounds. Participants were reminded to fill out speaker and consent forms, with the option to edit transcripts later if desired. The meeting organizer also mentioned that the transcripts would be anonymized but not the audio.\n\nThe discussion then shifted to the purpose of the project, which was called Meeting Recorder. The project aimed to collect data on meetings using different microphones and release it as a publicly available corpus. The project involved collaboration with SRI, UW, NIST, and IBM. The meeting organizer also mentioned the use of digit strings as a more constrained task for easier comparison with other corpora.\n\nTowards the end of the meeting, the conversation focused on the deep understanding task in the tourist domain. The belief-net approach was suggested for differentiating between intentions such as viewing, entering, and interacting with objects. The structure and factors for the belief-net were not determined yet, but the meeting organizer emphasized the need to collect data to determine these factors.\n\nThe meeting concluded with a discussion on data collection, which would involve participants being in a room and performing tasks related to navigating a virtual environment. The tasks included finding locations, taking pictures, and obtaining information. The participants would interact with a computer system that would eventually be taken over by a human operator. The discussion also mentioned the possibility of including maps and dialogue in the data collection process.\n\nOverall, the meeting provided an overview of the discussion on XML tools, data quality, and the current XML format for linking components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting.",
        "During the meeting, the discussion focused on XML tools, meeting data quality, and the current XML format for linking up different components in data. The participants talked about the possibility of using XML as an interchange format and the advantages and disadvantages of using XML for different levels of data, such as word-level and phone-level information. They also discussed the idea of using belief-net packages, such as JavaBayes or the M-toolkit, to analyze the data and extract features. The participants agreed to pick a belief-net package and present their findings in the next meeting. They also talked about the need to choose a database format for storing the data, with XML being a potential option. However, they also considered other formats, such as the P-file format or the ATLAS format. The participants discussed the advantages and disadvantages of each format and the importance of compatibility and sharing with other researchers. Ultimately, they agreed to further explore the ATLAS format and determine if it would be suitable for their needs.",
        "During the meeting, the discussion focused on XML tools, data quality, and the current XML format used to link different components in data. F and A provided their opinions on the current XML format. F mentioned that the format was based on a conceptual node annotated transcription graph and that the team had developed their own external file format. However, F had not yet looked at the tools associated with the format. A suggested that they find out if the tools would run on the current format and if it would be difficult to translate from one format to another. C expressed concern about potentially missing details in the translation process. A and F agreed that it would be best to use a format that is conceptually close to what they need and that has tools that everyone else will be using. They also discussed the idea of using a relational database to store the XML data, but concluded that a flat file format with search tools would be sufficient for their current needs. They also mentioned the possibility of using the ATLAS external file representation and discussed the advantages and challenges of using it. They also discussed the issue of merging annotations from different versions of the data and the difficulty of specifying what is meant by \"merge\". They mentioned using diff tools and the possibility of developing a tool that can merge annotations based on word sequences. Finally, they briefly discussed the P-file format and the potential need for alternatives. Overall, the meeting provided insights into the team's thoughts on XML tools, data quality, and the current XML format.",
        "During the meeting, the discussion covered various topics including XML tools, data quality in meetings, and the current XML format for linking different components in data. F and A expressed their opinions on the current XML format. F mentioned that as soon as they receive confirmation from Brian that everything is okay with the transcript, they will send the next four as a batch for further work. They also discussed doing transcription and other tasks in parallel to get more work done. A mentioned that the THISL GUI front-end for Broadcast News looks great and would be easier to port to Windows. They also discussed the possibility of adding fuzzy matches and using term frequency and inverse document frequency scoring in the information retrieval tool. They talked about the user interface options for the XML tools, including a web-based one and a Tcl-TK GUI front-end. They also discussed the possibility of showing prosody features and demonstrating sentence and turn boundary detection in the demo. They discussed the need for more disk space for backup and the possibility of burning CDs for distribution. They mentioned the CrossPad devices and whether they should return them or keep them for further use. They also discussed the idea of using PDAs with wireless cards as an alternative. They mentioned ordering more wireless equipment and the plan to rewire the room for different microphone channels. They briefly mentioned ongoing work with recognition runs and feature analysis. Finally, they decided to do a simultaneous transcript to save the data before the next group comes in."
    ],
    [
        "During the meeting, the topic of electronics was discussed, specifically regarding uncomfortable headphones. The participants expressed their discomfort with the design of the headphones and the headaches it caused. They also mentioned the idea of using CrossPads for data collection and the potential usefulness of summaries for querying purposes. The participants debated the best way to generate queries and the importance of capturing visual information during meetings. They discussed the possibility of using cameras to capture images of the participants and the content on the whiteboard. Overall, they agreed that the collection of data and the generation of summaries would be beneficial, but they also acknowledged the potential challenges and limitations of these approaches.",
        "During the meeting, the discussion revolved around electronics, the segment, the results from the experiments, and the topic of intentionality. The participants talked about the strange data they were receiving and how it differed from what they intended to research. They also discussed the CrossPads and their potential usefulness. However, they concluded that it may not be a reliable source of information. The idea of using email as a faster and more efficient method of communication was also brought up. They debated the best time to gather information, with some suggesting doing it orally at the end of the meeting and others suggesting email. They also discussed the importance of generating queries from the summaries and the challenges involved in doing so. They considered the possibility of including the participants' own summaries in the data sample to increase the number of recognized words. The issue of bias in generating queries was also raised, as well as the potential bias introduced by asking participants to recall the most interesting thing they learned. They discussed the need for a system to generate queries automatically based on summaries. They also talked about the importance of having a variety of meetings with different levels of overlap and different types of participants. The participants agreed to gather more data from different groups and to explore different formats for higher-level information. They discussed the possibility of using near-field microphones to reduce overlap and the importance of having non-technical and non-speech people as users to get more realistic results. They also discussed the need to contact other organizations and researchers to access their data. Overall, the meeting focused on the challenges and strategies for gathering and analyzing data in the field of electronics.",
        "During the meeting, the discussion about electronics was brief and focused on the topic of intentionality. The participants mentioned that they had done experiments with far-field recognition using multiple microphones. However, they did not offer the data from these experiments to the community at the meeting. The participants also discussed the idea of combining the CrossPad and speech for interaction, as well as the possibility of using found data for linguistic analysis. \n\nIn terms of the segment, the participants mentioned that they had not yet sent out a note about the existence of a mailing list for the project. They also discussed the importance of checking that everyone attending the meeting was on the list. \n\nThe results from the experiments were not discussed in detail during the meeting. \n\nThe topic of intentionality was briefly mentioned, with one participant expressing their enjoyment of the group dynamics and interactions during the meeting. There was also some discussion about how to detect intentionality in the data, such as searching for laughter or signs of happiness. \n\nOverall, the discussion about electronics, the segment, the results from the experiments, and the topic of intentionality was limited during the meeting.",
        "In the meeting, the discussion focused on electronics, the segment, the results from the experiments, and the topic of intentionality. PhD A shared his experience with manipulating objects using electronic devices and how it became difficult to differentiate between real and virtual objects. Professor C mentioned that this anecdotal evidence aligns with the results of their experiments. They also discussed the deep embodied neural differences and the importance of intentionality in language and spatial reference. \n\nThe meeting then shifted to the topic of building a system and the decisions that need to be made. They talked about the need for an ontology API or a standardized ontology for the system. They also discussed the importance of building a parser and analyzer and how it relates to the grammar. The professor mentioned that they are also considering incorporating construction analysis into their applied project and child language modeling project. They also mentioned the possibility of adding a new doctoral student and an undergraduate honors thesis student to the team. \n\nIn the second part of the meeting, Professor D shared the results of the experiments conducted by PhD A and others. They discussed the overall improvement in error rate and how it varied across different conditions. They also mentioned the possibility of combining different approaches and systems to achieve even better results. They discussed the need to analyze the data more closely to understand the sources of degradation and potential improvements. They also mentioned the possibility of training neural nets using data from multiple languages and different acoustic conditions. \n\nOverall, the meeting highlighted the ongoing research and experiments in the field of electronics and language processing. It emphasized the importance of understanding intentionality, making system decisions, and continuously improving the accuracy of language processing systems."
    ],
    [
        "In the meeting, the main thesis of the discussion was to transition from focusing on demos to focusing on the basic issues and research of the project. The professor expressed the importance of understanding the demo system and its potential for future development. The professor also mentioned the need to finish the belief-net stuff and the importance of designing the connections and semantics of the belief-net. The professor also discussed the relevance of fictive motion and spatial descriptions in the project and suggested looking into linguistic differences in spatial descriptions between languages. The professor also mentioned the importance of understanding reference frames and the potential for further research in this area. The professor also mentioned a study on differences in English and German spatial descriptions. Additionally, the professor discussed the importance of understanding the brain's distinction between things within reach and things out of reach and its relevance to language. The professor also mentioned the need to make decisions on ontology and system development. The professor also discussed the potential for the construction analyzer to be used in both the applied project and child language modeling. Finally, the professor mentioned the importance of formalizing the project's formalism to cover the whole range of things and avoid limitations.",
        "Based on the given meeting, the main thesis of the discussion appears to be the evaluation and improvement of speech recognition systems in the Aurora program. The professor mentions the need to achieve a fifty percent improvement in recognition accuracy and discusses the issues surrounding voice activity detection and endpointing. \n\nThe professor expresses their opinion that there is potential for improvement in the current systems, particularly in the area of noise separation. They mention trying different techniques such as using LPC models, spectral subtraction, and ad-hoc techniques to improve the initial estimates of the mel spectrum. The professor also discusses the use of temporal patterns in recognition, specifically the use of vectors representing the energy at a given frequency over time. They mention the need to de-correlate these vectors and explore their correlation and distribution. \n\nThe professor mentions that they are still working on documentation and running experiments to further improve the systems. They discuss removing certain coefficients from the parameter vectors and observing the effects on recognition accuracy. The professor also mentions the ongoing discussions about the evaluation criteria and the possibility of sticking to the fifty percent improvement goal.\n\nIn conclusion, the main thesis of the discussion is the evaluation and improvement of speech recognition systems in the Aurora program. The professor's opinions include the potential for improvement in noise separation, the exploration of temporal patterns, and the need for further experiments and documentation. They also discuss the ongoing discussions about evaluation criteria and the fifty percent improvement goal. Future work involves running more experiments, exploring alternative techniques, and continuing the evaluation process.",
        "The main thesis of the discussion was how to improve data collection for the purpose of user-interface design. The professor and other participants discussed the use of CrossPads to collect data and the potential benefits of having participants write summaries and queries after the meetings. They also explored the idea of using keywords and note-taking to generate structure and information for the system. The professor mentioned the availability of software developed by Intel for data collection and suggested the use of jargon and pseudo-names for ease of communication. Overall, the discussion focused on finding ways to improve data collection and maximize the usefulness of the collected data for user-interface design. The professor also mentioned the importance of communication and collaboration between different parts of the distributed center and encouraged the use of a mailing list for better coordination. The professor and participants also discussed the potential challenges and limitations of data collection, including the motivation factor and the need for an interactive system to explore the data further. They also talked about the possibility of using existing note-taking practices and delegated note-takers to generate summaries and queried information. The discussion ended with suggestions for future data collection and the importance of gathering a variety of recordings for analysis.",
        "The main thesis of the discussion was to explore the use of meeting summaries and note-taking as a way to generate queries and gather useful information. The professor's opinions were mixed, with some seeing value in using summaries as a starting point for generating queries, while others expressed concerns about the feasibility and usefulness of automatically generating queries from summaries. The professor also discussed the possibility of using CrossPads for data collection, but acknowledged that it may not be feasible due to limited resources. The professor also mentioned the importance of capturing visual information, such as photographs of whiteboards, for future reference. In terms of future work, the professor suggested having meeting participants provide their own summaries and generate queries based on their own perceptions of the meeting. The professor also mentioned the need for further research on how to automatically generate queries from summaries.",
        "The main thesis of the discussion was the exploration of generating queries from meeting data. The professor's opinions were as follows: \n- The 12 second mean was not mentioned in the meeting.\n- The professor's opinions on possible hypotheses were not mentioned in the meeting.\n- The concluding comments were that generating queries from meeting data is a complex task and further research is needed.\n- The future work discussed was the need to get the recording equipment running at UW and to gather a variety of meeting data.\n\nOverall, the main focus of the discussion was on the challenges and possibilities of generating queries from meeting data, as well as the importance of obtaining diverse meeting data for research purposes."
    ],
    [
        "During the meeting, there was a discussion about the discomfort of the headphones and the need for a more comfortable design. The participants also discussed the idea of using transcripts and the potential requirements and agreements regarding them. The meeting participants mentioned the use of CrossPads for data collection and the possibility of using them to generate summaries. They also discussed the importance of capturing visual information, such as what is written on the board, during meetings. The participants agreed that summaries could be useful for generating queries and agreed to have participants in the meeting provide summaries afterwards. It was suggested that note-taking during the meeting could serve as a form of summary, and the participants discussed the possibility of using digital cameras to capture visual information during meetings. Overall, the participants agreed to explore these options and determine the best approach for capturing and using meeting transcripts.",
        "During the meeting, the discussion focused on the transcripts and the requirements and agreement regarding them. One idea that came up was having one or two people stay behind after the meeting to provide oral summaries. It was also suggested that people with radio mics could go into separate rooms and continue recording without hearing each other. However, concerns were raised about the accuracy of the data collected from different perspectives. Another suggestion was to have participants generate queries based on the summaries, but it was acknowledged that this could be a challenging task. It was mentioned that the CrossPads system could be used for data collection, but it was not considered a reliable source. Email was suggested as a more efficient method for collecting data. The importance of including a variety of perspectives in the data collection process was emphasized, as well as the need for different types of information, such as interesting points discussed in the meeting. It was also mentioned that the data format for higher-level information needed to be determined. Action items included finding out about human subject requirements, creating a mailing list, and emailing Adam or Jane to obtain the data. The possibility of obtaining text sources related to the meetings was also discussed. The recording equipment at UW was mentioned, and it was suggested to try and get a variety of meetings with different levels of overlap. It was noted that near-field mics could help with reducing overlap, and the idea of having rules of participation for certain samples was mentioned. The importance of having a variety of meetings, including technical and administrative, was emphasized. The meeting concluded with a discussion about the need to process the data effectively.",
        "During the meeting, the discussion focused on the topic of transcripts. The participants discussed the different types of data, such as political debates and congressional hearings, and how they differ from the meetings they were currently working on. It was agreed that if there was existing data that could easily be transformed for use in speech recognition, they would use it. However, newly collected data would be natural meetings. The participants also discussed the availability of data collected by CMU and whether it would be publicly available. It was mentioned that there may be some politics involved in making the data available. The participants agreed to keep in touch with Mark, who was interested in collecting as much data as possible. They also discussed the need to send out a note to inform everyone about the existence of the list. \n\nIn terms of the transcripts, it was mentioned that the CMU participants had collected a lot of data and that the transcripts would be made available to the participants. The participants discussed the possibility of editing the transcripts to exclude certain sections. A web interface was suggested to allow participants to view the transcripts and mark sections they wanted to exclude. The issue of privacy was also discussed, and it was suggested that each participant would have a password to access the transcripts. The participants debated whether participants should be allowed to edit sections of the meeting where they were not speaking. Some participants were concerned about others editing their words, while others felt that participants should have the right to exclude sections they were uncomfortable with. The issue of consent was also mentioned, with the understanding that participants had agreed to have their voices used in the transcripts. Overall, the participants agreed to provide the transcripts to all participants and allow them to mark sections for exclusion.",
        "During the meeting, several topics were discussed regarding the transcripts. The main focus was on the consent forms and the ability for participants to edit or remove offensive or sensitive content from the transcripts. It was agreed upon that the consent forms should clearly state that participants have the right to review and request changes to the transcripts. The method of distribution was also discussed, with options including email, printing, or mailing. The issue of privacy and ease of access was raised, with the suggestion that access to the transcripts should be limited to those who truly need it. The idea of using a web interface for accessing and editing the transcripts was considered, but concerns were raised about potential misuse and excessive editing. It was agreed that a balance should be struck between making it convenient for participants to review the transcripts and ensuring that editing is done only when necessary. The issue of legal requirements was also discussed, and it was determined that email consent would be sufficient. The meeting ended with a discussion about the distribution of passwords for accessing the transcripts and the possibility of providing a printable version for those who prefer it. Overall, the main agreement was to make the transcripts easily accessible to participants while also ensuring that any editing is done responsibly and with valid reasons.",
        "During the meeting, the discussion revolved around the transcripts, specifically regarding cheating, merging pre-segmented versions, and the desire for pure pre-segmented transcripts. The agreement was to ensure that there is a record of the original automatic transcripts for reference. The meeting also touched on the reorganization of the directory structure for the Meeting Recorder data and the creation of a spreadsheet to keep track of meeting details. Additionally, the discussion covered the progress of training classifiers with the Meeting Recorder data and the potential improvements that could be made by adjusting insertion penalties and the size of the Gaussian system. The meeting also mentioned the possibility of having participants approve the transcriptions for distribution. The discussion further explored the use of different features, such as time position, pitch, and speaker information, in the classifiers. It was mentioned that the pitch features in the Meeting Recorder data were better than those in the Switchboard data. The meeting also discussed the potential for future experiments, such as using principal components and combining the neural net outputs with regular features. The meeting concluded with a suggestion to debug any potential issues with the tandem system and to consider retraining the net using the tandem features."
    ],
    [
        "In the meeting, there was discussion about the opinions of PhD F and PhD B on the topic of generating queries automatically. PhD F mentioned that there might be difficulty in generating queries without an interactive system, as it would be hard to go beyond the first level of questioning. PhD B suggested using note pads to capture when people are writing during the meeting, as it could indicate important points of discussion. PhD B also proposed taking photographs of the whiteboard during the meeting to preserve the information written on it. There was also discussion about the possibility of using CrossPads for data collection, but it was unsure if it would be useful without the main person collecting data using it. Overall, there were different ideas and considerations about how to generate queries and capture important information during the meeting.",
        "In the meeting, PhD F expressed concern about the feasibility of generating queries automatically from summaries. PhD B agreed that it may not be a feasible task, but suggested that having a small amount of automatic query generation as a proof of concept would be useful. PhD B also mentioned that relying solely on automatically generated queries may not be ideal for basic modeling. PhD F and PhD B both agreed that it would be important to include input from users in generating queries and that it would be interesting to ask participants what they found most interesting or important in the meeting. PhD B also mentioned the possibility of using indicator phrases from the transcript as potential queries. The group discussed the need for non-technical and non-speech people to test the system to get more realistic user feedback. PhD F raised the question of bias in generating queries based on what is currently important, and PhD B suggested including both important and interesting aspects in generating queries. The group also discussed the need for data formats for higher-level information and agreed that PhD F and PhD B would take the lead on determining the best format. Other action items included finding out about human subject requirements, sending URIs for web pages, creating mailing lists, emailing IBM about data transfer, and contacting Landay about obtaining the recording equipment. It was also mentioned that Landay may have outside text sources that could be used for language modeling. Overall, the group agreed to try different methods of query generation and gather user feedback to improve the system.",
        "In the meeting, PhD F and PhD B did not explicitly express their opinions on the topic of generating queries automatically. However, the meeting focused on discussing various aspects of the SmartKom project and the belief-net system. PhD E mentioned a revelation about taking pictures, while PhD F stated that Jane took their answer. The meeting also touched on the availability of data and the potential collaboration with the German SmartKom project. The meeting concluded with a plan to focus on the belief-net system and design the connections based on the best knowledge of the domain. Additionally, the issue of visualizing the belief-net was discussed, and options such as Hugin and a Java applet were mentioned. PhD E offered to provide input on the internal structure of the belief-net, and PhD G expressed interest in accessing transcripts of initial interactions with the system. The meeting ended with PhD B mentioning attending a linguistics colloquium on fictive motion, which could be relevant to the project. Overall, the opinions of PhD F and PhD B on generating queries automatically were not explicitly discussed in the meeting.",
        "In the meeting, the PhD students discussed the topic of generating queries automatically. PhD F and PhD B had differing opinions on the topic. PhD F mentioned a project called Deep Map, which focused on generating spatial descriptions in German, English, and Japanese. They also discussed the use of different spatial reference frames in different languages. PhD B expressed interest in looking at the differences between German and English in terms of reference frames. PhD A brought up the relative position of objects in Hebrew and English, specifically in terms of front and back. PhD E mentioned a study on the differences between English and German in spatial descriptions. The PhD students also discussed the idea of using an ontology API or a specific ontology for the project. They talked about the possibility of visiting the German AI center or Heidelberg while in the area. The meeting also touched on the topic of reference frames and the concept of \"origo\" as the center of a frame of reference. The PhD students discussed the use of construction analyzers and parsers in the project. They also discussed the idea of building a system for the project and the potential for collaboration with other projects. The meeting concluded with a discussion on the upcoming tasks and deadlines for the PhD students.",
        "In the meeting, PhD F and PhD B did not specifically express their opinions on the topic of generating queries automatically. The discussion mainly focused on the evaluation of the current system and the upcoming evaluation on Wall Street Journal data. PhD F and PhD B mentioned the ranking of their system in the evaluation, but they did not provide their opinions on generating queries automatically."
    ],
    [
        "During the meeting, there was a discussion about latency in the system. The professor had an issue with it because it was causing discomfort and headaches for some users. However, the duration of the latency was not mentioned in the meeting.",
        "In the meeting, the discussion on latency in the system was brought up. The professor had an issue with it because it could potentially affect the usefulness of the system for various applications. The duration of the latency was not specifically mentioned in the meeting. However, the professor mentioned that the more things they can get for the system, the more useful it will be. The meeting also discussed other topics such as data collection, the use of CrossPads, and the generation of summaries. Action items were identified, including finding out about human subject requirements, sending web page information, and contacting IBM for data transfer. The meeting also touched on the topic of data formats for higher-level information, with the decision being to go with whatever format the team has been working on. Additionally, the professor mentioned the importance of getting non-technical and non-speech people to use the system in order to get realistic user feedback.",
        "During the meeting, the discussion on latency in the system was brought up. The team mentioned that they have been working on reducing the latency by designing new filters using recursive filters instead of FIR filters. These new filters have shorter delays and have been implemented to improve the latency. They also mentioned that they are planning to add a downsampling filter and an on-line normalization filter to further reduce the latency. \n\nThe team also discussed the possibility of using spectral subtraction from Ericsson and changing the contextual KLT for LDA to improve the system's performance. They mentioned that they want to replace the non-discriminant linear transformation with a discriminant linear transformation to see if it improves over the current system. \n\nAdditionally, the team discussed the possibility of using a third-party VAD (Voice Activity Detection) to determine boundaries for the recognition task. They mentioned that this would separate the VAD from the recognition task and allow for better performance. \n\nOverall, the team had an issue with the latency in the system and discussed various methods to reduce it. They also mentioned the importance of communication and coordination with other team members, particularly Sunil. The duration of the latency was discussed to be around 240 milliseconds, which is within the acceptable range.",
        "In the meeting, there was a discussion about latency in the system and why the professor had an issue with it. The professor mentioned that in real situations, the latency needs to be calculated online with a forgetting factor. They also discussed different methods of computing the noise spectrum and determining the signal-to-noise ratio. The professor mentioned a histogram method that requires a few seconds of speech to get a decent estimate. They also talked about using EM to estimate the signal and noise in each frequency band. The professor raised the issue of whether the window used to calculate the signal-to-noise ratio would add to the latency and mentioned that it depends on whether the window extends into the past or the future. They also discussed the challenges of dealing with non-stationary noise and the limitations of spectral subtraction. \n\nIn the second part of the meeting, they discussed a research proposal on latency in the system and the duration of the latency. They talked about using multi-band systems and different methods for detecting phonetic features. They discussed the use of logistic regressions as low-level detectors and the training process using EM. They also mentioned the challenges of determining the noise spectrum and the benefits of using narrowband information for speech recognition. They also discussed the potential collaboration with another researcher on de-reverberation algorithms for speech recognition. \n\nTowards the end of the meeting, they discussed the need to improve the system's crash issue and the possibility of mapping the location without having people give their names each time. They also discussed the agenda for future meetings, suggesting focusing more on research topics rather than procedural matters. They mentioned the need to discuss the work on locating events and interruptions in speech and other potential research areas. They also mentioned a potential collaboration with another researcher on working with the data.",
        "During the meeting, the discussion revolved around the topic of latency in the system. The professor had an issue with latency because it could affect the accuracy and efficiency of the system. The duration of the latency was not specifically mentioned in the meeting. However, the meeting also touched on the topic of speaker overlaps and the need to mark them in the data. The professor suggested that marking only speaker overlaps would be a more efficient way to study this phenomenon. The assistant mentioned that they are working on a program to detect speaker overlaps using a simple threshold and median filter approach. They also mentioned the possibility of using a cross-correlation filter to clean up the audio data. Overall, the meeting provided insights into the challenges and potential solutions related to latency and speaker overlap detection in the system.",
        "During the meeting, the discussion on latency in the system was brought up. The professor had an issue with it because he wanted to try the simple approach first before adding complexity. He also mentioned that having someone with experience in marking from a human standpoint would be helpful. The duration of the latency was not mentioned in the meeting."
    ],
    [
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the transcription status. Grad F provided updates on the transcription process, mentioning that IBM had finally made the tape for the data and it had been sent to the transcribers. Grad E asked which meetings were being transcribed and Grad F explained that some were being sent to IBM while the rest were being transcribed in-house. Grad E also suggested using some of the initial data from the SmartKom data collection for transcription. \n\nIn regards to storage disks, Grad E contributed to the discussion by mentioning that they had an 18 gig drive with about 12 gig of space left. Grad B mentioned the need for more disk space and suggested hanging disks off the new SUN-Blades that had been received. However, the placement of the disks in the machine room and the overall space situation needed to be discussed with Dave Johnson.\n\nUpdates provided by Grad B regarding the meeting on disk storage were that the disk space for backed up data was at about 30% on the second disk, while the scratch disks for expanded meetings were at about 95-98% full. Grad B suggested hanging disks off the new SUN-Blades in the machine room for additional space. However, the final decision on where to place the disks would need to be discussed with Dave Johnson.\n\nOverall, the meeting covered the transcription status, storage disk issues, and updates on the meeting on disk storage. The role of the computer and wizard in the transcription process was discussed, as well as the contribution of Grad E to the discussion on storage disks. Grad B provided updates on the storage disk situation.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were about the possibility of the computer generating questions and engaging in a dialogue with itself. They discussed the idea of the system being able to understand utterances and also ask questions based on certain intentions. Grad D mentioned the idea of having two parallel machines asking each other questions and how it could lead to learning and making the system more robust. Grad E mentioned that getting the system to generate the right thing in the right circumstances might be more difficult than getting it to understand. They also discussed the possibility of running randomized testing to overcome the challenge of testing all possible situations. \n\nIn regards to Grad E's contribution to the discussion on storage disks, there is no mention of Grad E's contribution in the given meeting. \n\nLastly, there is no mention of any updates provided by Grad B regarding the meeting on disk storage in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the task of crafting a paper. Grad D emphasized that having a paper is still a good thing and it is a nice exercise that can contribute to their publication lists. They also discussed the need to determine what to write about and what their take-home message should be. They mentioned the possibility of introducing a new formalism in the paper. Grad B expressed uncertainty about their role in the paper and asked about the length of the paper, to which Grad D mentioned that it would be around four pages. Grad E also contributed to the discussion by mentioning their ongoing work on storage disks.\n\nRegarding Grad E's contribution to the discussion on storage disks, the meeting did not provide any specific details about this topic. It is unclear what exactly Grad E contributed to the discussion or what updates were provided.\n\nRegarding the updates provided by Grad B regarding the meeting on disk storage, the meeting did not provide any information about Grad B's updates or the meeting on disk storage. It is unclear what updates were provided by Grad B or what was discussed in the meeting.\n\nIn summary, the key points discussed about the roles of the computer and wizard in the meeting between Grad D and Grad C were related to the task of crafting a paper, determining what to write about, and the possibility of introducing a new formalism. The meeting did not provide any specific information about Grad E's contribution to the discussion on storage disks or the updates provided by Grad B regarding the meeting on disk storage.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that some tasks are straightforward in theory but complex in reality, while others are complex in theory but straightforward in reality. They also discussed the timing of when to start wizarding and the potential for a person from Oakland to continue the wizarding after Fey leaves in August. Grad E's contribution to the discussion on storage disks was not mentioned in the given meeting. Lastly, Grad B provided updates on the meeting on disk storage, including the hiring of extra people, the progress in transcription, and the possibility of using the IBM transcription for digit recognition.\n\nRegarding the discussion on the roles of the computer and wizard, Grad D emphasized that some tasks may seem simple in theory but become complex in reality, while others may seem complex in theory but become straightforward in reality. This suggests the need for a balanced approach and consideration of the specific context in which the tasks are performed.\n\nIn terms of timing, Grad D mentioned that they needed to start wizarding at 4:10. They also mentioned that Fey, who usually does the wizarding, would not be available for the meeting and that Grad D would take on the wizarding role instead. Thilo would handle the instructing role. They also discussed the potential for someone from Oakland to continue the wizarding after Fey leaves in August, which would be beneficial for data collection and potential changes in the data collection setup.\n\nThere was no specific information provided about Grad E's contribution to the discussion on storage disks in the given meeting.\n\nIn the updates provided by Grad B regarding the meeting on disk storage, it was mentioned that extra people had been hired and more were expected to be hired. They also mentioned that the first set of transcriptions had been completed and that a second set was being edited for spelling errors. Grad B also discussed the reorganization status and mentioned that they had a plan in place for organizing the data but were waiting until closer to the next level zero back-up to avoid a large number of additional files. They also mentioned the Absinthe multiprocessor UNIX system and updates on segmentation and recognition experiments. Lastly, Grad B mentioned the possibility of discussing digits in the meeting but noted that the agenda was already quite full.\n\nOverall, the meeting covered various aspects related to the roles of the computer and wizard, updates on storage disks, and the potential for continued wizarding and data collection. The specific contribution of Grad E to the discussion on storage disks was not mentioned in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not explicitly mentioned in the provided meeting transcript. However, there was a discussion about consent issues and transcription, which Grad E mentioned was done in Munich. It was also mentioned that the format of the data should follow the SmartKom transcription conventions rather than the ICSI meeting transcription conventions. \n\nRegarding Grad E's contribution to the discussion on storage disks, there was no specific contribution mentioned in the meeting transcript.\n\nAs for the updates provided by Grad B regarding the meeting on disk storage, it was mentioned that there was a concern about the available disk space and the need for more storage. Grad F mentioned that they were using up some space that they shouldn't be using and that once everything gets converted to the proper disks, they will be at around 75% capacity. Grad B also mentioned finding disks with different capacities, but it was not clear if any action was taken based on this information.\n\nOverall, the meeting focused on various topics including consent issues, transcription, format conventions, and disk storage concerns. The roles of the computer and wizard were not explicitly discussed, and Grad E's contribution to the discussion on storage disks was not mentioned."
    ],
    [
        "SmartKom is an architecture that consists of various modules, including a knowledge modeler, function modeler, and action planner. The importance of SmartKom lies in its ability to process and understand language input, make decisions based on that input, and generate appropriate responses. The architecture aims to incorporate deep conceptual semantics, which involves mapping from discourse to conceptual semantics and then to decision-making. The modules in SmartKom work together to analyze and interpret input, generate appropriate responses, and provide a seamless user experience. The system also aims to incorporate external services and utilize knowledge bases to enhance its capabilities. There are ongoing discussions and plans to further develop and improve the architecture, including integrating syntactic analysis and incorporating more complex slots in the dialogue planning process.",
        "SmartKom is a project that involves the development of an agent with the goal of going to a specific location, along with additional situational information. The architecture of SmartKom includes a belief-net, which combines information from dialogue, ontology, and the situation to make decisions. The modules involved in SmartKom include the belief-net, ontology, user model, dialogue, and situation. The importance of SmartKom lies in its ability to understand and respond to user queries and provide relevant information based on the given context. The project also aims to improve language understanding and generation capabilities, as well as develop a construction analyzer. The project is moving towards a more scientific approach, focusing on issues such as spatial descriptions, reference frames, and discourse reference. The team is also working on building their own system and making decisions regarding the ontology and other system-related aspects. Additionally, the team is considering the use of an ontology API or standardizing on a particular ontology. The goal is to create a comprehensive and effective system that can handle various tasks and provide accurate and relevant information to users.",
        "SmartKom is an architecture that involves the use of modules to provide smart and interactive communication. The importance of SmartKom lies in its ability to enhance communication and provide personalized assistance to users. The meeting discussed the progress of SmartKom, including the development of a drive-in thesis, the addition of a new doctoral student, and the plans for data collection. The meeting also touched on the importance of formalization and belief nets in the SmartKom project. Additionally, the meeting introduced the work of Andreas, who is working on a smart FAQ system that utilizes context information to provide relevant search results. The meeting ended with a discussion on the potential integration of FrameNet and information extraction in the SmartKom project. Overall, the meeting highlighted the ongoing work and future plans for SmartKom, as well as the importance of collaboration and integration in the project."
    ],
    [
        "During the meeting, the options discussed regarding the location of the recording equipment were not explicitly stated. However, it was mentioned that the University of Washington (UW) may want to start recording meetings as well, which would require determining the equipment setup. It was also mentioned that the recording conditions at UW are clean and they use head-mounted microphones. The option of using linguistics graduate students and undergraduates to do the transcription work was discussed, as it has been done in the past. It was mentioned that this option would require a post pass to ensure accuracy. The possibility of using a commercial transcription service was briefly mentioned, but it was deemed unlikely due to cost and quality concerns. The Transcriber tool from a French group was mentioned as a tool that has been used and works well for transcription. The issue of transcription conventions, such as marking repairs and false starts, was also discussed. The idea of integrating speech recognition with the transcription tool was mentioned, but the recognition quality was deemed to be poor. The possibility of using volume on a specific channel to detect boundaries was also mentioned. It was suggested that a comparison experiment could be conducted to determine the efficiency of different transcription methods. The importance of speaker identification and the need for accurate segmentation were also discussed. Overall, the decision regarding the location of the recording equipment and the transcription method was not explicitly made in the meeting.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. The possibility of using an external service, such as Cyber Transcriber, was mentioned. It was noted that the cost for such services could be around $30 per hour. However, it was also mentioned that these services may not be able to handle meetings with multiple speakers or provide certain features, such as speaker identification or stress marking.\n\nAnother option discussed was to hire graduate students to transcribe the meetings. The going rate for graduate students was estimated to be around $8 to $10 per hour. It was suggested that this could be a more cost-effective option, especially considering the control and flexibility that could be achieved by having graduate students transcribe the meetings.\n\nThe transcription conventions were also discussed during the meeting. It was mentioned that a script had been developed to convert the transcriptions into a format that could indicate speaker ID and other relevant information. The conventions included marking speaker changes, indicating backchannels, and showing continuation of thought. It was suggested that these conventions could be refined and automated to make the transcription process more efficient.\n\nOverall, no final decision was made regarding the location of the recording equipment. However, the options of using an external service or hiring graduate students were thoroughly discussed, along with the transcription conventions and the potential for automation.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. One option was to put it on a website, while another option was to use Doctor Speech. It was also mentioned that a soft link to transcription could be used. It was agreed that having some kind of access to the data is important. There was also a discussion about consolidating the various web and document sources for the project. The possibility of using a TCL plug-in or Trellix for the website was mentioned. The decision was made to have a website and use HT access to accommodate different needs. \n\nIn terms of the recording equipment, it was discussed that the equipment would be placed under the lip of the table and connected to the microphones. The idea of using a plastic sleeve to organize the cables was suggested. It was mentioned that the recording equipment would need to be secured to prevent tampering. The idea of having a user interface with a monitor was also discussed, with the suggestion of using a laptop with a wireless connection. It was mentioned that the interface could be used to view meter readings and other information. The possibility of using a projector connected to a machine at the back of the room was also brought up. \n\nThe question was raised about the progress of the demo and whether there were any other tasks that needed to be done. It was mentioned that the DARPA meeting was approaching and that preparations needed to be made. It was suggested that a mock-up for question answering could be done, as well as a comparison of everyone saying the same digits at the same time or at different times. The decision was left open for further discussion. \n\nThe meeting also touched on the progress of the SRI recognizer and experiments with different front-ends. It was mentioned that the vocal tract length normalization was working well. The issue of applying warp factors from the SRI system to the ICSI front-end was also discussed.",
        "During the meeting, the options discussed regarding the location of the recording equipment were not mentioned. Therefore, no decision was made on this matter.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. One option mentioned was the use of a low-frequency cut-off to address problems with DC offsets in the data. Another option discussed was the use of a high-pass filter to address the issue of different sampling rates. It was mentioned that the decision was made to make the high-pass filter a parameter and to adjust it for different sampling rates. Additionally, the idea of using principal components analysis (PCA) to reduce the dimensionality of the feature vector was discussed. It was mentioned that this approach did not make the system better or worse, but it was worth trying. The meeting also touched on the idea of using the tandem system and the potential benefits of combining neural net outputs with regular features. It was suggested that the CrossPad, a digital notepad, could be used during data collection to capture important points of the meeting. The idea of having someone take notes as a summary of the meeting was also discussed. It was suggested that these summaries could be used to generate queries and identify important words and topics discussed in different types of meetings. Overall, it was agreed that more data collection and experimentation would be needed to further explore these options and make informed decisions.",
        "During the meeting, the options discussed regarding the location of the recording equipment were summarized as follows:\n\n1. The idea of having a dedicated note-taker who attends the meetings and takes notes was suggested. This person would then provide the notes to researchers who are interested in studying the meetings.\n\n2. It was mentioned that the current note-taking application being used by the team is no longer being developed, so there may not be anyone currently working on taking notes.\n\n3. The possibility of using a combination of note-taking and speech recording was discussed. This would involve recording the meetings and having someone generate a summary of the discussions afterwards.\n\n4. It was suggested that the summaries could serve two purposes: to help generate queries and as a form of minutes for the meetings.\n\n5. The question of who would generate the summaries was raised. It was suggested that the note-taker or someone else in the meeting could be responsible for this task.\n\n6. The idea of using digital cameras to capture images of the meetings, including the people and the whiteboard, was proposed. This would provide additional visual information that could be useful for future analysis.\n\n7. The potential challenges of implementing video recording were discussed, including the need for consent from participants and the potential for privacy concerns.\n\n8. It was mentioned that the collection of visual data could be beneficial for research purposes, but it would require additional resources and infrastructure.\n\nIn summary, the decision made regarding the location of the recording equipment was to try using CrossPads for data collection and to ask participants to provide summaries or minutes of the meetings if they are willing. The idea of capturing visual data using cameras was also considered, but the feasibility and practicality of implementing this option were left open for further discussion. Additionally, the potential for generating queries automatically from the summaries was mentioned, but it was acknowledged that this could be a challenging research topic and may require additional resources and expertise.",
        "During the meeting, the options discussed regarding the location of the recording equipment included using CrossPads, getting electronic summaries from a note-taking person, taking digital pictures of the table and boards, and going around the room at the end of the meeting to ask people to mention something interesting they learned. The decision made was to try CrossPads and see if they are interesting, get electronic summaries if possible, take digital pictures of the table and boards, and ask people to mention something interesting they learned at the end of the meeting. It was also decided to try to get a variety of meetings, including technical and administrative meetings, to capture different levels of overlap in the data. Additionally, the meeting discussed the issue of generating queries based on what is important now and the potential bias it may introduce. The decision made was to focus on getting the recording equipment running at UW and to try to get more variety in the data collected. The meeting also touched on the topic of found data and the potential use of existing corpora for language modeling. It was noted that different types of data, such as broadcast and web data, could be useful for different purposes. The meeting concluded with a discussion about the interesting aspects of the meeting, including the combination of CrossPads and speech, the process of generating queries, the revelation about taking pictures, and the dynamics of the group."
    ],
    [
        "During the meeting, there were discussions about various topics including the use of close-talking microphones, the upcoming NIST visit, and the progress of transcriptions. The participants discussed the need for better quality microphones and the standardization of microphone usage to capture clear signals. They also mentioned the NIST visit and the interest in microphone arrays. The transcribers shared their progress and mentioned the time it takes to transcribe meetings. The meeting also touched on the possibility of using the ATLAS system for analyzing the transcriptions. Overall, the discussions revolved around improving the quality of recordings and transcriptions, as well as exploring new analysis methods.",
        "During the meeting, the discussions were focused on various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The participants discussed the concept of an annotated transcription graph representation and how it could be used to manipulate transcription graphs of various types. They also talked about a project between NIST and other organizations, including LDC, and the web site that provides papers related to this project. The participants mentioned the use of a transcriber pool, which consists of individuals who transcribe audio recordings for IBM's speech recognition products. They discussed the training and qualifications of these transcribers, as well as the level of detail in the transcriptions they provide. There was also a conversation about the potential benefits of having Brian Kingsbury, an individual with knowledge of the project's data requirements, involved in the transcription process. The participants discussed the possibility of using a different direction for transcription, including the use of multi-trans for transcription, and the challenges of obtaining fine-grained time information from the transcriptions. They also discussed the type of transcribers IBM hires and the nature of their training. The participants talked about the difficulties of transcribing conversations and the need for context to understand reduced phonetic words. They also discussed the historical reasons for IBM's involvement in transcription and the potential benefits of expanding the transcription efforts to include more meetings. The participants discussed the potential use of transcribers for other tasks, such as labeling dialogue acts and disfluencies in the transcriptions. They also discussed the possibility of collecting more meeting data, including meetings from different departments or groups that involve heated discussions or arguments. The participants mentioned the interest in having meetings with all English speakers and the challenges of finding meetings that meet this criteria. They also discussed the potential use of transcribers in processing waveforms, such as separating speakers or improving signal-to-noise ratio. Overall, the discussions provided insights into the various aspects of talk, neurons, transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about improving the waveform and microphone quality for better acoustic-phonetic analyses. The issue of cross-talk and room acoustics was brought up, and it was mentioned that lapel microphones may have more room acoustic problems. The possibility of using different ASR techniques for improved results was also mentioned. \n\nThe topic of the transcriber pool came up, and it was mentioned that the in-house transcriptions were fine as long as no words were transcribed for individuals not speaking. However, if someone spoke even a little, there would be a problem with picking up speech from other people, especially for the person in the middle who said only a little bit. It was suggested that this issue could be related to the encoding of the energy in the transcriptions. \n\nThe meeting also discussed the use of symbols or graphic symbols to mark different situations during transcription. There was a mention of using different visual displays for speech and non-speech events. The possibility of increasing the flexibility of alignment and using different acoustic events and parameters for transcription was discussed. \n\nThere was also a discussion about the organization of meeting information and the reorganization of the directory structure for Meeting Recorder data. The idea was to create a spreadsheet with details such as start time, date, number of speakers, duration, transcription status, and comments for each meeting. This information would be exported as HTML and put on the Meeting Recorder website for easy access and updates on the status of different meetings. \n\nThe issue of transcriptions and their approval for distribution was also mentioned. It was suggested that participants should have the opportunity to approve the transcriptions, but it was acknowledged that there may be challenges in ensuring accuracy and legal considerations. The need for further discussion and clarification on this matter was acknowledged. \n\nAdditionally, the meeting briefly touched on ongoing projects and experiments, such as the IBM project and the analysis of prosodic features. The need for more data and meetings to improve results in these areas was mentioned.",
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. One of the discussions revolved around the use of forced alignment and word features such as word frequency and backchanneling in classifiers. The dominant features that were discussed included these \"cheating\" word features. There were also discussions about the positions of words in sentences and their relevance in the analysis. It was mentioned that the recognized words can provide similar information about position, but it was unclear if they would provide the same number of words. Time position and the number of words were also discussed as potential features to consider. The meeting also touched on the idea of using time position normalized by speaking rate and the potential impact of speaker effects on the results. The use of pitch features in the Switchboard dataset was also discussed, with a comparison to the cleaner behavior of pitch features in the current dataset. The need for more data and more data per speaker was mentioned, as well as the potential use of EDU meetings for further analysis. There was also a discussion about the use of insertion penalty and the size of the Gaussian system in the tandem system, and the potential benefits of vocal tract length normalization on the PLP features. The potential use of principal components analysis on the tandem features and the combination of neural net outputs and regular features in the Gaussian mixture system were also mentioned. Finally, there was a suggestion to prioritize research discussions over procedural discussions in future meetings and to explore potential collaborations with Lokendra on language understanding and inference structures.",
        "During the meeting, there were discussions about various topics including talk about neurons, the transcriber pool, and acoustic-phonetic analyses. One topic discussed was the potential use of analyzing intonational contours in narratives and how it may be relevant to the individual's research. There was also discussion about the use of text and transcripts of speech, with the suggestion that transcripts of speech may have more relevant information than prepared writing. The meeting also touched on the issue of identifying individuals in publications using data and the potential sensitivity of mentioning names. The topic of speaker overlap was also discussed, with the individual sharing their work on segmenting and labeling overlapping zones in recorded speech. The individual mentioned that they found approximately 300 instances of speaker overlap in a 45-minute session and that they were transcribing the session to study these overlaps in more detail. The meeting also touched on the differences in speech signals collected by different microphones and the potential challenges of accurately detecting speaker overlap. It was suggested that the individual could use the existing transcripts as a reference but also consider marking speaker overlaps separately. The idea of using automated methods to detect speaker overlap was also discussed, with the suggestion of using a threshold based on volume and applying a median filter. The potential use of a cross-correlation filter to clean up the signals was also mentioned. Overall, the meeting covered a range of topics related to talk, neurons, the transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The participants discussed the importance of starting with simple tasks before moving on to more complex ones. They also talked about the need for someone with experience to mark the data from a human standpoint and the possibility of speeding up the process by identifying speaker overlaps. The participants mentioned the use of energy detectors with median filters to identify runs and how this approach has been successful in the past. They also discussed the idea of using echo cancellation to improve the quality of the recordings and the challenges associated with it. The participants talked about the amount of data collected so far and the plans to collect more in the future. They mentioned the possibility of recording meetings from other sources such as friends in broadcast media or other meetings happening on campus. The participants also discussed the logistics of data collection and transcription, as well as the potential for future research projects using the collected data. Overall, the meeting covered a range of topics related to talk, neurons, transcriber pool, and acoustic-phonetic analyses."
    ]
]