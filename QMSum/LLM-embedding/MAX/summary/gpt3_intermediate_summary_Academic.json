[
    [
        "In the meeting, there was a discussion about XML tools, data quality in meetings, and the current XML format used to link different components in data. The opinions of F and A on the current XML format were not provided in the meeting.",
        "During the meeting, the discussion focused on XML tools, data quality, and the current XML format used to link different components in data. The meeting participants discussed the need to pick a package for XML tools that has good interactive abilities and is easy to modify and interact with. They also discussed the possibility of using transcript files and the importance of having a stable and reliable XML format.\n\nOpinions on the current XML format varied. F and A expressed their opinions that the current XML format is suitable for representing utterances, sentences, and other linguistic features. They also mentioned the possibility of using the ATLAS format, which is being developed by NIST, as an alternative to the current XML format. It was suggested that ATLAS may have more tools and infrastructure support, making it a potential option for the project.\n\nIn terms of data quality, the participants discussed the challenges of dealing with large amounts of data, particularly at the frame and phone level. It was suggested that a more compact format, such as P-files, could be used for frame-level data to avoid excessive file sizes. The participants also discussed the need to handle multiple speakers and the possibility of representing hierarchical relationships between utterances and words.\n\nOverall, the participants agreed that the choice of XML tools and format should be based on factors such as ease of use, compatibility with existing tools and infrastructure, and the ability to handle different types of data and annotations. They decided to further explore the ATLAS format and its compatibility with the project's needs.",
        "During the meeting, the discussion focused on XML tools, data quality in meetings, and the current XML format for linking different components in data. The opinions of F and A on the current XML format were not explicitly stated in the meeting. The meeting also touched on the progress of transcription work, the use of THISL tools for information retrieval on meeting data, and the possibility of merging Transcriber and THISL IR for the user interface. There was also a suggestion to demonstrate the prosody work done by Don during the demo. The goal is to have all the pieces together by the end of the month for the demo.",
        "In the meeting, the discussion covered several topics including XML tools, data quality, and the current XML format used to link up different components in data. F and A provided their opinions on the current XML format. \n\nRegarding XML tools, Grad H mentioned that they have been working with XML as the general format for everything and believe it is the right way to go. However, they expressed dissatisfaction with the current XML format used for transcription, as it is difficult to use in other tools due to the lack of start and end markers for each utterance. F asked for clarification on the issue, and Grad H explained that the start and end of each utterance are implicit in the XML format, but it requires additional processing to extract that information. They also mentioned their plans to work on the indirect timeline business and the ability to extract information from XML files in various languages.\n\nRegarding data quality, there was a discussion about the seat information in the Key files. Grad H mentioned that the seat information is present in the Key files for the current meetings but might be missing in the new ones. This led to a conversation about the importance of seat information and how it can be useful for analyzing meeting data.\n\nIn terms of the current XML format, Grad H mentioned that they have been converting the Key files to XML to extract various information on individual meetings. Phd G asked about the seat information in the Key files, and Grad H confirmed that it is recorded for the new meetings. Professor B clarified that the seat information refers to the location of participants in the meeting, not the audio quality. Grad H also mentioned that there have been some issues with filling in the seat information in the Key files, and they plan to improve the process using XML tools.\n\nIn summary, the discussion covered the use of XML tools, concerns about the current XML format for transcription, the importance of seat information in meeting data, and plans to improve data quality and extraction using XML tools. F and A provided their opinions and expressed the need for better organization and standardization in these areas.",
        "In the meeting, there was a discussion about XML tools, meeting data quality, and the current XML format to link up different components in data. F and A shared their opinions on the current XML format. They talked about the need for a system that can handle data quality issues and provide context information for more effective searches. They discussed the importance of formalizing the writing of context information and using shared interpretation of terms and keywords to make inferences and improve search results. They also mentioned the scalability challenge and the need to integrate knowledge from different sources and search engines. They discussed the use of Bayesian networks and probabilistic approaches in document retrieval. They also mentioned the idea of a peer-to-peer approach in information retrieval. Overall, the meeting focused on ways to improve data quality, search results, and the integration of different components in data using XML tools.",
        "In the meeting, the discussion revolved around XML tools, meeting data quality, and the current XML format used to link up different components in data. The participants discussed the need for better note-taking during meetings, as the current method of taking sparse notes makes it difficult to reconstruct what was discussed. The idea of using digital cameras to capture images of the meeting participants and the whiteboard was also suggested to provide more context to the meeting data. F and A expressed their opinions on the current XML format, with F mentioning that it would be nice to have a digital camera to capture images of the meeting and A mentioning the importance of recording the spatial position of the people in the meeting. The participants also discussed the potential usefulness of video data and the challenges associated with its collection and storage.\n\nBased on the meeting discussion, the action items identified include:\n1. Finding out about human subject requirements.\n2. Sending U R for web pages to A.\n3. Cleaning up web pages by mid-July.\n4. Creating mailing lists.\n5. Emailing A or J to discuss obtaining the data.\n\nIn conclusion, the meeting highlighted the importance of improving note-taking during meetings and the potential benefits of capturing additional data, such as images and video. The participants identified action items to further explore these ideas and enhance the quality of the meeting data.",
        "During the meeting, the discussion revolved around XML tools, data quality in meetings, and the current XML format used to link different components in data. F and A expressed their opinions on the current XML format, with F stating that the work they have been doing is satisfactory and whatever they want, the team is happy to live with. A also mentioned that while they are not directly involved in the data collection process, they are supportive of the team's efforts and are willing to provide any necessary information.\n\nThe team also discussed the process of collecting data, including the use of near-field microphones to reduce overlapping speech and the possibility of implementing rules of participation to further reduce overlap. They also talked about the importance of gathering a variety of meeting types and participants to ensure a diverse dataset.\n\nIn terms of technical updates, the team reported that they have made progress with the XML parser, successfully creating an English parser that can handle various sentence types. They mentioned the need to test and refine the parser further and expressed their intention to add new sentence types and M3L mappings in the future.\n\nThe team also discussed the upcoming data collection phase, including plans to recruit participants from various sources, such as CogSci classes and social networks. They mentioned the need for participants to sign consent forms and the possibility of adding a waiver for participants who do not wish to see the final transcript.\n\nOverall, the meeting covered a range of topics related to XML tools, data quality, and data collection, with the team expressing their progress and plans for future work.",
        "During the meeting, the discussion focused on XML tools, data quality in meetings, and the current XML format used to link different components in data. F and A expressed their opinions on the current XML format. The meeting began with a discussion on the simplicity of XML tools and the parameters involved. There was some concern about the current XML format being a step backwards from previous methods and the lack of certain notions. F and A expressed their opinions on the current XML format, with F finding it straightforward but missing some important elements, while A suggested making some changes to improve functionality.\n\nThe meeting then shifted to the topic of data quality and the challenges of linking different components in data. The discussion revolved around the need to define a global goal for the entire route and the importance of understanding the relationships between different elements. There was also a request to allocate tags for specific actions and to explore shortcuts to certain components in the data.\n\nTowards the end of the meeting, the focus shifted to the concept of Noisy-OR in Bayes nets and its potential use in the project. The idea was to use intermediate nodes to simplify the probability calculations and reduce the number of probabilities needed. The discussion highlighted the need to find a way to incorporate Noisy-OR functions into JavaBayes and the possibility of building a separate data structure to handle combining functions.\n\nOverall, the meeting touched upon various aspects related to XML tools, data quality, and the use of Noisy-OR functions in Bayes nets. It also highlighted the need for further discussions and exploration to find the best solutions for the project."
    ],
    [
        "During the meeting, the discussion revolved around several topics, including the discomfort of headphones, the use of CrossPads for data collection, the idea of generating summaries, and the potential for using photographs or videos to capture additional information during meetings. The participants discussed the challenges of making headphones more comfortable and shared their experiences with discomfort. They also discussed the potential benefits of using CrossPads for data collection, such as capturing important moments and generating queries. The idea of generating summaries was brought up as a way to refresh participants' memories and potentially generate queries based on the content discussed. The participants also discussed the possibility of using photographs or videos to capture additional information during meetings, such as the positioning of people and the content on the whiteboard. The meeting concluded with the decision to try using CrossPads for data collection and to encourage participants to generate summaries and share them after the meeting.",
        "During the meeting, the discussion revolved around the use of electronics in meetings, the segment of the population being studied, the results from experiments, and the topic of intentionality. The participants discussed the use of technology, such as recording devices, to collect data from meetings. They debated the best methods for gathering information, such as oral summaries or email. They also discussed the challenges of getting participants to stay after the meeting to provide oral summaries. The idea of generating queries from meeting summaries was brought up, and the participants discussed the potential challenges and benefits of this approach. They also discussed the possibility of including meeting summaries in the data sample to increase the recognized words by individuals. The participants debated the feasibility of automatically generating queries from meeting summaries and the potential bias that could be introduced. They also discussed the importance of including indicator phrases and text sources in the data. The participants talked about the need for different levels of queries and the importance of considering different sources of data. They discussed the potential for reducing overlap in meetings and the benefits of having a variety of meeting types. The participants also discussed the importance of having a diverse range of participants and the potential challenges of data collection. They mentioned the need for rules of participation and the potential challenges of processing data with high levels of overlap. The participants also discussed the potential sources of data, including recordings from other institutions, and the need for further communication with experts in the field. Overall, the participants agreed to continue working on data collection and analysis, with the goal of generating meaningful queries and improving the understanding of intentionality in meetings.",
        "During the meeting, the discussion touched on several topics related to electronics, experiments, and intentionality. The meeting began with a discussion about the electronic mailing list and ensuring that everyone was included on it. The conversation then shifted to the topic of \"found data,\" which refers to established corpora of linguistics and other fields that do not require funding to collect. The group discussed the importance of collecting as much data as possible and the different types of data that could be included, such as broadcast, web, TV, and radio data.\n\nThe conversation then turned to the results from the experiments conducted by the group. One experiment involved using the CrossPad and speech to take notes and explore the interaction between the two. Another experiment focused on the process of generating queries and the challenges of determining the type of query based on the purpose. The group found this discussion interesting and highlighted the factors involved in generating queries.\n\nThe topic of intentionality also came up during the meeting. One participant mentioned a revelation about taking pictures and regretted not doing so before. They discussed the possibility of using pictures of the boards from previous meetings for analysis. The group also discussed the idea of measuring people dynamics and happiness through data analysis.\n\nOverall, the meeting covered various topics related to electronics, the segment, the results from experiments, and the topic of intentionality. The group discussed the importance of the mailing list, the concept of \"found data,\" the experiments conducted, and the potential insights gained from analyzing the data.",
        "During the meeting, there was a discussion about electronics, the segment, the results from the experiments, and the topic of intentionality. The discussion started with a conversation about the different types of ego and allocentric perspectives that appear in electronics. The professor mentioned that there have been a lot of behavioral studies on this topic, but the meeting focused on the first neuro-physiological study that was seen. The group then moved on to discuss the segment and the results from the experiments. It was mentioned that Dan Montello, who works on cognitive maps, often talks about small scale spaces that can be manipulated versus large scale environmental spaces. The professor noted that all of these issues are starting to come up and that the group needs to start doing science. They also discussed the topics of reference, spatial reference, discourse reference, and deixis, which are all related to intentionality. The professor mentioned that they will need to make decisions about ontology and system integration as they start building something. They also mentioned the possibility of using an ontology API or a standard ontology from another project. The professor emphasized that their plan is not just to lay out the project, but to actually build it. They also discussed the potential for collaboration with other researchers and the involvement of new doctoral students in the project. The professor mentioned that there will be a meeting to discuss the belief-net and the ideas involved in it, and they hope to finish it up soon. They also talked about the possibility of combining their construction analyzer with another project on child language modeling. The professor mentioned that they have a shot at making these two pieces the same thing. They also discussed the timing of their projects and the upcoming deadlines for the results from the experiments. The professor mentioned that they have obtained some results from one of the researchers, but they are still waiting to hear about results from other researchers. They discussed the need to summarize the results and compare them to other proposals. The professor also mentioned the importance of understanding the data and the specific conditions in order to improve the recognition system. They also discussed the possibility of combining different approaches and trying different experiments, such as using data from multiple languages to train the neural net. They also talked about the limitations of their current system and the need for further improvements. The professor mentioned the importance of looking at the realistic room situations and the acoustic conditions in order to develop a more effective system. Overall, the meeting focused on the ongoing research and the next steps in the project.",
        "During the meeting, there was a discussion about electronics, the segment, the results from the experiments, and the topic of intentionality. The participants talked about using an example from the previous week with everyone doing the digits at once, which was a fun experience. They also discussed the idea of using a noise shield to prevent people from listening in on their meetings. They came up with the idea of giving reports at the same time and then reviewing individual channels later. They also talked about the upcoming conference and the visit from the UW folks. They discussed the agenda for the meeting and the need to prepare for the IBM transcribers. They also talked about the difficulties with forced alignment and the need for better speech detection. They discussed the possibility of using Thilo's energy segmentations to improve alignment and the challenges involved. They also discussed the possibility of using pre-segmented conversations for future experiments. Overall, the discussion covered a range of topics related to electronics, experiments, and intentionality.",
        "During the meeting, the discussion revolved around the topic of electronics and intentionality. The participants discussed the use of forced alignment in electronics and the segment. They also talked about the results from the experiments and the importance of intentionality in the context of the meeting. They debated whether it was worth using forced alignment if it was not accurate and discussed the possibility of editing the corpus instead. They also mentioned the potential of forced alignment for cleaning up the transcriptions. The participants expressed their hope that forced alignment would work, but also acknowledged the complications that could arise with lapel mics and overlap sections. They also mentioned the possibility of adapting the models for better alignment and the need to get good alignments for feature extraction. The participants discussed the idea of using forced alignment for corpus and paper purposes and the challenges they might face in redoing or editing the meetings. They also mentioned the upcoming visit of Brian Kingsbury and how his perspective could be valuable in the discussion. Towards the end of the meeting, they talked about the presentation of Morgan and the positive response it received. They discussed the humor in the presentation and shared their thoughts on the battery meter joke. They also discussed the possibility of using humor in their own presentations. The participants then shifted the discussion to the topic of electronics and the challenges they faced in finding comfortable microphones for recording. They discussed the balance and fit of the microphones and the importance of adjusting them properly. They also mentioned the plans for future meetings and the use of different recording systems and video cameras. They discussed the benefits of having multiple channels and the challenges of data adaptation and cross-talk. They also mentioned the need for good alignments and the possibility of correcting the transcriptions. The participants then talked about the Eurospeech conference and the different papers presented. They mentioned the discussion on the importance of more data and the different approaches to evaluation. They discussed the summary of the discussion and the disagreement among the participants. They also mentioned the paper by Lori Lamel and its relevance to their own research. The participants shared their thoughts on the different approaches to machine learning and the importance of understanding the properties of different algorithms. They also discussed the cost and practicality of using more data and the limitations of different learning machines. They mentioned the need for further research and evaluation in the field. Towards the end of the meeting, the participants discussed the plans for reading the digit strings and the importance of signing the consent form. They discussed the anonymity of the participants in the transcripts and the possibility of editing out sensitive information. They also mentioned the release of the data to the public and the involvement of different institutions in the project. The meeting concluded with the participants reading the digit strings and filling out the necessary forms.",
        "In the meeting, the discussion revolved around the topic of electronics, specifically focusing on the segment and the results from experiments. The participants talked about the concept of intentionality and how it relates to the different tasks and requests made by users. They noted that people have different intentions when interacting with electronic systems, such as looking at an object, entering a building, or getting close to something. They also discussed the importance of considering the type of object, the language used, and the context in which the request is made. The participants agreed that a belief-net structure could be used to differentiate between these intentions and proposed using a specific software package to build and analyze the belief-net. They also mentioned the possibility of collecting data to train and validate the belief-net, and discussed the potential challenges and considerations in doing so. Overall, the meeting aimed to determine the best approach for understanding and interpreting user intentions in the context of electronics.",
        "During the meeting, there was a discussion about electronics, specifically regarding the analyzer and converting it to English. The timeline for the projects was also discussed, with no specific deadlines mentioned. The topic of intentionality was brought up, with the idea of merging different systems into a harmonious state. The results from experiments were also mentioned, with the focus being on detecting overlapping zones in recorded speech. It was found that there were approximately 300 speaker overlaps in a 45-minute session. There was also a discussion about the accuracy of the transcription and the differences between close-talking and mixed signals. It was suggested that marking only speaker overlaps could help speed up the process. Overall, more research is needed to study the different acoustic events and improve the transcription process.",
        "In the meeting, the participants discussed various topics related to electronics, including the need for more data to analyze and the challenges of marking speaker overlap by hand. The idea of using different measures, such as energy levels and LPC residuals, was discussed, as well as the importance of having ground truth data for comparison. The possibility of using transcripts or close-talking microphones to infer speaker overlap was also mentioned. The participants talked about the potential of using echo cancellation techniques to improve the quality of the audio recordings and the challenges of dealing with reverberation and noise. They also discussed the current status of data collection, including the number of recorded meetings and the amount of transcribed data. The participants explored the possibility of recording additional meetings, such as political discussions or panels, to increase the amount of data available for analysis. They also discussed the potential of collaborating with radio stations or other organizations to collect more data. The meeting concluded with a discussion about the need for more data and the challenges of transcription and data analysis. Overall, the participants expressed a desire to continue data collection and explore new avenues for gathering more data."
    ],
    [
        "The main thesis of the discussion was to shift focus from demos to scientific research. The professor mentioned that the group should start working on the basic issues and understanding of the project, such as ontology, construction analysis, and spatial descriptions. The professor also mentioned that the belief-net project should be completed in the next few weeks, with a focus on design rather than learning. The group also discussed the differences in spatial descriptions between languages, such as English, German, and Japanese. They mentioned the importance of understanding reference frames and the concept of proximal-distal relations. Additionally, the professor shared some interesting findings on the neural differences between objects within reach and objects out of reach. The group also discussed the need for a system, including an ontology API and construction analyzer. They mentioned the possibility of aligning the construction analyzer with the needs of the child language modeling project. Overall, the meeting focused on the transition from demos to scientific research and the various aspects and challenges that need to be addressed.",
        "The main thesis of the discussion was centered around the progress and challenges of the Aurora program, specifically in relation to speaker recognition technology. The professor and other participants discussed the issue of the 12 second mean, the possibility of alternative hypothesis, concluding comments, and future work.\n\nDuring the meeting, the professor mentioned that there had been observations made regarding the lack of a hidden purist streak and the fact that certain theories had not been observed. The participants also discussed the implementation of certain theories and the importance of being purist within a specific context. The professor mentioned that future work would involve Robert picking a piece of the space for his thesis and the addition of a new doctoral student to the project.\n\nThe professor also mentioned the possibility of future collaborations and visits to other institutions. They discussed the possibility of dropping by Heidelberg or the German AI center during a visit to Switzerland. The professor also mentioned a student named Eva who would be joining the project and potentially working on belief-net stuff.\n\nThe professor also mentioned the possibility of an honors thesis being done on image schemas and the interest of other incoming graduate students in the project. The professor mentioned the importance of continuing the work on belief-net and formalization and how it would depend on the progress of the thesis and the interest of the students.\n\nIn terms of the Aurora program, the professor mentioned that there had been discussions about changing the evaluation criteria and the possibility of running new experiments. There was also discussion about the improvements made in the baseline and the need for further improvements. The professor mentioned the ongoing work on noise separation and the exploration of new techniques such as TRAPS recognition.\n\nThe professor also mentioned the absence of a team member who had taken a month-long vacation and the potential impact on the progress of the program. The professor discussed the possibility of getting fifty percent improvement and the ongoing discussions about the evaluation criteria.\n\nIn terms of future work, the professor mentioned the need for documentation and the completion of experiments. They also discussed the possibility of compressing the range of coefficients in the Gaussian mixture model and the potential impact on recognition. The professor mentioned the importance of continuing to explore alternative approaches and the need for further research in the field.\n\nOverall, the main thesis of the discussion was the progress and challenges of the Aurora program in speaker recognition technology. The professor expressed their opinions on various aspects of the program, including the 12 second mean, possible hypothesis, concluding comments, and future work.",
        "The main thesis of the discussion was to explore different ways to improve data collection for the purpose of user-interface design. The professor's opinions were focused on using CrossPads to collect data, asking participants to write summaries of the meetings, and generating queries based on the notes taken during the meetings. The professor also mentioned the possibility of using jargon and key words to identify important information and structure in the notes. The professor emphasized the importance of making the data collection process simple and efficient, as well as considering the motivation of participants outside of the core group. Additionally, the professor mentioned the availability of software developed by Lucash for the Aurora-2 system and encouraged more communication between different parts of the distributed center. The professor also discussed the potential use of the Jimlet devices and the need for further data collection and transcription.",
        "The main thesis of the discussion was to explore the use of meeting summaries and note-taking to generate queries and improve information retrieval in meetings. The professor's opinions were that meeting summaries could serve as a useful tool for generating queries and providing a refresh of the meeting's content. However, they acknowledged that generating queries automatically from summaries would be a challenging research topic.\n\nThe professor also discussed the possibility of using CrossPads, a digital note-taking device, to collect additional data during meetings. They mentioned that while CrossPads could be useful for user interface research, it should not be relied upon for modeling or query generation.\n\nThere was also a discussion about the importance of capturing the spatial organization of the meeting, such as the positions of people and what was written on the board. The professor suggested taking pictures or making notes of these details to provide a more complete record of the meeting.\n\nRegarding the generation of queries, it was suggested that participants could provide input on the most interesting things they learned from the meeting, which could help generate queries that go beyond the summary's content. It was also mentioned that this could be an optional and voluntary activity for participants.\n\nIn conclusion, the main thesis of the discussion was the use of meeting summaries and note-taking to generate queries and improve information retrieval. The professor's opinions were that meeting summaries could be a useful tool for generating queries, but automatic query generation from summaries would require further research. The professor also discussed the use of CrossPads and the importance of capturing spatial organization during meetings. Additionally, the idea of participants providing input on the most interesting things they learned was suggested as a way to generate more diverse and informative queries.",
        "The main thesis of the discussion was the generation of queries from meeting data. The professor's opinions on the 12-second mean were not explicitly stated in the meeting. Possible hypotheses were discussed regarding the generation of queries and the importance of finding what people are interested in. The concluding comments included the need for a system to capture meeting data and the importance of having a variety of meetings for analysis. Future work included contacting Adam or Jane for data, compiling a mailing list, and exploring different sources of text data.",
        "In the meeting, the main thesis of the discussion was about noise suppression and the re-synthesis of speech after suppression. The professor expressed his opinion that it is more likely for Sunil to grab the CVS mechanism when he is at OGI. The professor also mentioned that the team is working on a different task at the moment, but they will remotely access the CVS from OGI. The discussion then shifted to remotely accessing the CVS using SSH, and the team members discussed their experiences with it. \n\nRegarding the 12 second mean, there was no specific mention of it in the meeting. \n\nIn terms of possible hypotheses, the team discussed the idea of remotely accessing the CVS using SSH and the possibility of setting up an anonymous CVS server. They also discussed the idea of using TRAPS for the VAD and the potential benefits of adding a second stream to the system. \n\nIn the concluding comments, the professor mentioned the importance of freezing certain aspects of the system and focusing on improving the VAD, adding the neural net, and opening up the second front. The team also discussed the upcoming evaluation and the importance of testing the system on the Wall Street Journal data. \n\nIn terms of future work, the team discussed the need to improve the noise estimator, work on the second stream and the neural net, and consider the impact of different features on the performance of the system. They also mentioned the possibility of visiting OGI to work on the project. \n\nOverall, the main thesis of the discussion was focused on noise suppression and the team's plans for improving the system. The professor expressed his opinions on various aspects of the project and the team discussed possible hypotheses, concluding comments, and future work.",
        "The main thesis of the discussion was to find ways to improve speech recognition systems, particularly in the presence of noise and for categories that are close to one another. The professor expressed concern about the robustness of current systems and suggested that the focus should be on distinguishing between categories that are clustered together. The professor also mentioned the importance of considering the confusions made during recognition and coming up with categories that can clarify these confusions.\n\nThe professor and the grad student discussed the potential of using words as categories instead of phonemes and the difficulty of reconciling the desire for discriminative categories with the use of human-defined categories like phonemes. They also discussed the importance of top-down information in learning and the need for some reward or reinforcement in the learning process.\n\nDuring the meeting, the professor and grad students also discussed the results of their experiments on speech recognition systems. They mentioned the results for the 12-second mean and the professor expressed concern about the recognition errors made for certain sounds. They also discussed the possibility of combining different algorithms and approaches to improve the overall performance of the system.\n\nIn terms of future work, the professor suggested looking more closely at the data and understanding the specific causes of degradation in recognition. They also mentioned the possibility of using hand-labeled data from different languages to train the system and exploring the use of multiple nets or different acoustic conditions for training.\n\nOverall, the main thesis of the discussion was to improve speech recognition systems, particularly in the presence of noise, and the professor expressed his opinions on various aspects of the topic, including the 12-second mean, possible hypothesis, concluding comments, and future work.",
        "In the meeting, the main thesis of the discussion was the analysis of overlapping speech in recorded conversations. The professor suggested focusing on research points rather than mundane topics in future meetings. The professor also mentioned the importance of understanding events and interruptions in speech. The postdoc mentioned an example related to inference structures in language understanding. The professor suggested collaboration with other researchers and potential use of the data for training material. The professor also mentioned the need to be cautious about identifying individuals in the transcripts and the possibility of using gaze direction as a potential identifier. The professor then introduced the topic of analyzing overlapping speech and its challenges. The professor suggested using the close-talking microphones to mark speaker overlaps and analyze the data. The PhD student mentioned that they found a large number of acoustic events, including overlaps, in the recorded speech. The student also discussed the differences between speech signals collected by different microphones and the need to study the differences in more detail. The professor suggested comparing the transcription with Jane's marks to improve accuracy. The professor also suggested focusing on marking speaker overlaps to speed up the process. The student agreed with the suggestion and mentioned the difficulty of distinguishing between speech and noise in some cases. The professor then suggested using the mixed close-talking microphones for word-level transcription and studying the overlapping of speakers as a distinct phenomenon. The professor also mentioned the possibility of using automated measures to detect overlaps based on energy levels. The discussion concluded with the suggestion of bootstrapping from human-marked overlaps and then using automated measures to improve accuracy.",
        "The main thesis of the discussion was to discuss the data collection process for a project. The professor and the team discussed the possibility of inferring speech on-off points from close-talking microphones and how to detect it from a far-field. They also talked about a program that was written to detect speech based on volume threshold and median filter. They discussed the potential of using a cross-correlation filter to improve the program and the need for someone to do adaptation and echo cancellation. They also talked about the amount of data collected so far, which was around 12 hours, and the potential for collecting more data from other meetings and outside sources. The professor mentioned the possibility of recording meetings from local broadcast media and inviting guests to have discussions. They also discussed the limitations of the current data collection and the need for more data to be able to work on different projects. The professor mentioned the possibility of recording meetings without the need for transcriptions and the potential for using the data for different research questions. They also discussed the logistics of data collection and the need to adjust transcriptions and add more refined coding of overlaps. The team discussed the possibility of recording meetings with different topics and conflicts and the potential of getting subjects from the campus or the building to participate in the recordings. They also talked about the potential of recording meetings from radio shows and the need for additional channels for recording. Overall, the main thesis of the discussion was to explore different possibilities for data collection and discuss potential research projects based on the collected data."
    ],
    [
        "During the meeting, the participants discussed the discomfort of the headphones and potential solutions. They also discussed the possibility of using CrossPads for data collection and the challenges and benefits associated with it. The idea of generating summaries from the meetings was also brought up, with the potential for using notes taken during the meetings as a starting point. The participants also discussed the possibility of taking pictures of the whiteboard and the room during the meetings to capture additional information. Overall, the participants agreed to try out different methods and gather as much data as possible for further analysis and evaluation.",
        "During the meeting, the discussion regarding the transcripts focused on the idea of summarizing the meetings and generating queries based on the summaries. It was suggested that the summarization could be done by the participants at the end of the meeting, either by going around the table or having one or two people stay behind. It was also mentioned that people with radio mikes could go into separate rooms and continue recording without hearing each other. The purpose of the summaries was to pick out keywords and construct queries for future use.\n\nThere was a discussion about the potential bias introduced by asking people to summarize the meetings and whether the bias would affect the ability to generate queries later. It was suggested that asking participants to mention the most interesting thing they learned from the meeting could provide different types of information and reduce bias.\n\nAction items were identified during the meeting, including finding out about human subject requirements, sending UR for web pages, cleaning up web pages by mid-July, creating mailing lists, emailing Adam or Jane about getting the data, emailing Picheny about shipping address, and getting the recording equipment running at UW. It was also mentioned that data formats for higher-level information, such as prosody, needed to be considered.\n\nThe meeting concluded with a discussion about getting non-technical and non-speech people to use the system for more realistic user testing. It was suggested to ask other people to call and use the system to avoid bias from users who already know how to deal with dialogue systems. The meeting ended with a discussion about data collection and the possibility of getting meetings with less overlap for a variety of samples.",
        "During the meeting, several topics related to the transcripts were discussed. One issue raised was the possibility of allowing participants to edit or exclude sections of the transcripts that they did not want included. It was suggested that a web interface could be created where participants could view the transcripts and indicate which sections they wanted excluded. The transcripts would be password-protected, with each participant having a single password. Only participants who were present at a specific meeting would have access to the transcript for that meeting. The distribution of passwords and transcripts was also discussed, with the idea of sending web page links to participants via email. \n\nThe current status of the transcripts was also mentioned, with approximately 11 hours of transcriptions completed so far. The transcriptions were being reviewed to ensure consistency and accuracy, and additional conventions were being incorporated, such as handling numbers and acronyms. The transcriptions were also being checked for errors and inconsistencies, and spot checks were being done to compare the work of different transcribers. \n\nThe possibility of using the transcripts for speech recognition was also mentioned, and a speech-nonspeech segmentation tool was being developed to aid in this process. The tool would allow for the detection and separation of foreground and background speech, making it easier to process the transcripts for speech recognition. \n\nOverall, the discussion focused on the editing and distribution of the transcripts, as well as the progress and quality of the transcriptions themselves.",
        "During the meeting, there was a discussion about the transcripts and the requirements for them. The main concern was about privacy and the need for passwords to access the transcripts. There was also a debate about whether a signature was required for consent or if an email approval was sufficient. The possibility of editing out sections of the meeting was also discussed, with some participants expressing their preference for being able to bleep out certain parts. The meeting also touched on the need for a web interface and the ability to print out the transcripts. The issue of convenience versus privacy was raised, with some participants suggesting that making it too easy to edit the transcripts could lead to a headache. The meeting concluded with a discussion about the distribution of passwords and the need for a clear wording in the consent forms. The progress of the transcription work was also mentioned, with plans to hire more transcribers and the need for a streamlined process for transcription and editing.",
        "During the meeting, the discussion regarding the transcripts involved using them for training and creating speech-nonspeech labels. The pre-segmentations were found to be extremely helpful, although adjustments were sometimes necessary. There was also a mention of organizing the meeting information and creating a spreadsheet to track the progress of transcriptions. It was suggested that the transcribers should have a meeting to address any issues. The possibility of having participants approve the transcriptions for distribution was also discussed, with the goal of having a subset of transcripts available for the DARPA meeting in July. The meeting also touched on the progress of the project involving the use of transcripts for training classifiers. It was mentioned that the pitch features in the new data were better than in the Switchboard data, likely due to the use of close-talking microphones. The discussion also included experiments with changing insertion penalties and the use of principal components for the feature vector. The meeting concluded with the idea of debugging the coupling of the two systems and exploring the use of the tandem system for optimization.",
        "During the meeting, the discussion revolved around the use of transcripts in the research project. It was mentioned that transcripts were helpful in analyzing the data and identifying overlapping zones in speech. The current best system for analyzing the data was discussed, which involved using a KLT transform on the combined feature vector. The issue of dimensionality reduction was also brought up, as the feature vector could become too large without it. The meeting also touched upon the need to identify individuals in the transcripts without violating privacy concerns. The possibility of using acoustics to determine gaze direction and speaker identification was mentioned. It was suggested that the transcripts should include temporal marks to accurately label overlapping zones. The accuracy of the current transcription was also discussed, and the idea of marking only speaker overlaps to save time was proposed. Overall, the meeting highlighted the importance of transcripts in studying overlapping speech and the need for further analysis and improvement in this area.",
        "In the meeting, the discussion revolved around the requirements and agreement regarding the transcripts. The team discussed the need for manual marking of speaker overlap and the possibility of inferring it from the relative energy in the audio. They also discussed the challenges of finding the right combination of features to detect speaker overlap accurately. The team considered using the close-talking mics to mark speaker overlaps and then using that information to train a program. They also discussed the possibility of using other sources of data, such as recordings from local broadcast media or inviting friends to have discussions that could be recorded. The team also mentioned the need for more data and the potential for recording more meetings at ICSI or partnering with other organizations. They also discussed the limitations of echo cancellation and the possibility of using block echo cancellation to improve the audio quality. Overall, the team agreed that collecting more data and exploring different approaches would be valuable for their research.",
        "During the meeting, there was a discussion about the requirements and agreement regarding the transcripts. The main focus was on how to ensure that there is a separate channel for distant microphone recordings. It was suggested that the existing producers of the transcripts be asked to record an extra channel of a distant microphone. It was also mentioned that the transcripts should be ready by a certain date, which was set as July 15th. It was discussed that the participants should be given an opportunity to review the transcripts and make any necessary changes before they are released. The idea of sending a follow-up email to remind participants to respond was also brought up. There was some debate about how active the response needed to be, with some suggesting that a simple email response would be sufficient. The issue of ensuring that participants have received the email and have a chance to respond was also discussed, with suggestions such as using return receipts or adding a confirmation button to the email. The possibility of encrypting the transcripts or using other methods to hide sensitive information was also mentioned. Overall, there was a consensus that the participants should be given a clear deadline to respond and that efforts should be made to ensure that all participants have received and responded to the email. It was also mentioned that the transcripts should be archived and preserved for future reference.",
        "During the meeting, there was a discussion about the transcripts, their requirements, and agreement on how to handle them. The meeting participants mentioned that they would have the transcripts done by Monday and thought it would be good to release them as a group to make it less distracting. However, it was also mentioned that they could be sent out periodically once they catch up on the process. The participants also discussed receiving the transcript back from a previous meeting and mentioned that there was one small problem that was easily fixed. They also talked about the need to have someone go through the meeting to check the transcript for accuracy and to see how much was missed. The participants mentioned that the transcripts missed a lot of backchannels and discussed the possibility that it was due to the pre-segmenter not catching them. They also discussed the possibility of improving the detection of backchannels in the future. Additionally, there was discussion about sending the transcripts to the University of Washington for recognition purposes and providing them with audio files. The participants also talked about the need for more disk space and the plan to order more disks. They mentioned the need to finish the meeting by a certain time and briefly discussed the possibility of using the data for language modeling. Finally, they discussed some issues and examples related to the transcription process, such as uncertainties and errors in the transcriptions. Overall, the participants expressed a desire for more data and discussed various ways to improve the transcription process.",
        "During the meeting, the discussion revolved around the need for sufficient data for different projects and the possibility of recording more data. The idea of using transcripts for certain projects was also discussed, as well as the potential for using a distant microphone to capture additional information. The team also discussed the need to bring people to the meeting location and the possibility of offering incentives such as free lunch. They also discussed the need to clear up space on the current disk and the plan to acquire additional disks. \n\nRegarding the requirements for the transcripts, it was suggested that the team should have a parallel information to satisfy different interests and make the corpus more powerful. The idea of providing transcripts to participants after the meeting was also discussed, with the condition that it should be the same CD-ROM distributed publicly. The team also mentioned the possibility of involving non-linguists and non-engineers in the project to widen the sampling.\n\nIn terms of the agreement, it was decided that the team would focus on clearing up space on the current disk and acquiring additional disks. They also agreed that the first priority should be to detect the overlapping zones in the meeting recordings. The team discussed the use of different classifiers and models to classify and analyze the different zones, such as using a neural network or a cluster algorithm. The importance of visualizing and analyzing the features in pairs was emphasized, as well as the need to consider the temporal properties and transitions between different zones. The team also agreed on the need to have a control set for testing and validating the models.\n\nOverall, the discussion and agreement focused on the need for sufficient data, clearing up disk space, analyzing and classifying the different zones in the meeting recordings, and the importance of parallel information and providing transcripts to participants.",
        "During the meeting, there was a discussion about the transcripts, their requirements, and agreement on how to handle them. The meeting started with some technical issues and questions about the effect of low signal-to-noise ratio on speech recognition. It was agreed that starting with simpler signals and features would be more reasonable and that a collection of possible features should be examined to see how different classes separate themselves. It was also suggested to use a mixed signal and collect pairs of features to proceed with a bigger classifier. It was mentioned that it would be interesting to try using both close mixed and distant mixed features to see how they work. The importance of exploring scatter plots and analyzing spectrograms in both cases was emphasized.\n\nThe discussion then shifted to the challenges of anonymizing the data and transcripts. It was suggested to use the same name for speaker identification and in the text whenever the speaker's name is mentioned. The issue of how to handle discourse analysis and tracking speakers was raised, as changing names in the transcript could lead to confusion and make it less useful for discourse analysis. It was suggested to either keep the names as they are or use speaker-1, speaker-2, etc. as identifiers. However, it was acknowledged that this approach may not be ideal for discourse analysis. The possibility of bleeping out names in the audio was also mentioned, but it was recognized that this could affect discourse analysis as well. The need for further discussion and decision-making on this topic was highlighted.\n\nThe meeting concluded with a brief discussion about the upcoming tasks, including the need to sign new forms and the importance of addressing thresholding and anonymization issues in future meetings. It was suggested that agenda items be sent beforehand to better organize the discussions. The meeting ended with a reminder to review the transcripts and audio for accuracy and consistency."
    ],
    [
        "In the meeting, there was discussion about the opinions of PhD F and PhD B on the topic of generating queries automatically. PhD B mentioned that he found it uncomfortable to wear headphones and suggested that they could be improved. PhD F agreed and mentioned that they can give headaches and suggested calling them \"temple squeezers\". PhD B also mentioned that the quality of handwriting recognition is poor. The group discussed different methods for generating queries, such as using summaries or notes taken during the meeting, and the potential use of CrossPads for data collection. They also talked about the possibility of using cameras to capture visual information during meetings. It was mentioned that CMU has used cameras to record meetings, and while some felt it could be useful, others expressed concerns about privacy and participation. The group also discussed the importance of having a record of what was written on the board during meetings. Overall, there was no clear consensus on the best method for generating queries automatically, but the idea of using summaries and notes taken during the meeting seemed to be a potential starting point.",
        "In the meeting, there were different opinions on the topic of generating queries automatically. PhD B thought it would be useful to have a small amount of automatic query generation as a proof of concept. PhD F raised concerns about introducing bias by generating queries based on what is currently important. PhD E suggested asking participants to mention the most interesting thing they learned in the meeting as a way to generate queries. PhD B suggested that Landay and his group should be in charge of figuring out how to generate queries. The group also discussed the possibility of using indicator phrases from the transcript as a way to generate queries. It was mentioned that it would be important to have non-technical and non-speech people test the system to get more realistic users. Action items from the meeting included finding out about human subject requirements, sending web page information to PhD E, emailing Picheny with shipping address, setting up mailing lists, emailing IBM with details about the data, and discussing data formats for higher-level information. It was mentioned that the recording equipment at UW needed to be set up and that Landay might have text sources that could be used for language modeling. Overall, there were different perspectives on the topic of automatic query generation and various action items were identified for further progress.",
        "During the meeting, PhD F and PhD B did not explicitly state their opinions on the topic of generating queries automatically. The discussion focused more on the technical aspects of the SmartKom system and the belief-net structure. PhD E mentioned a revelation about taking pictures, while PhD F said he would pass on giving an opinion at the moment. The group also discussed the availability of data and visualization tools for the belief-net. Overall, the meeting did not provide a clear consensus on the opinions of PhD F and PhD B regarding generating queries automatically.",
        "In the meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly stated. However, they did discuss the topic of spatial descriptions and differences between languages such as English and German. PhD E mentioned a project on spatial descriptions in German, English, and Japanese. PhD A also brought up the topic of relative position and direction in different languages. Overall, it seems that the opinions of PhD F and PhD B on generating queries automatically were not discussed in depth during the meeting.",
        "In the given meeting, PhD F and PhD B discussed the topic of generating queries automatically. PhD B mentioned that they will initially put in a mel spectrum as the second stream because it is cheap and easy. They also discussed the idea of using mel spectra and mel cepstra as alternate features. PhD F asked about the ranking of the system, and PhD A mentioned that currently, it is ranked second. However, they have not tested it on German and Danish data yet. PhD F also asked about the opinions of PhD F and PhD B on generating queries automatically. PhD B mentioned that they were discussing what to freeze in the system and what to do after they freeze it. They mentioned the possibility of adding a second stream and improving the VAD. They also discussed the upcoming evaluation on Wall Street Journal data and the availability of the system for download. PhD F mentioned their work on clustering data and the idea of discovering intermediate categories for classification. They discussed hierarchical clustering and the possibility of clustering arbitrary windows in time. PhD F mentioned the challenge of reconciling the desire for bottom-up clustering with the need for discriminative categories. Professor B suggested considering the word error rate and feedback loops to determine the goodness of clusters. PhD E raised the question of how to reconcile the desire for bottom-up clustering with discriminative categories and mentioned the challenge of working with phonemes. Professor B suggested considering the confusions made in recognition and the importance of context in robustness. PhD E mentioned the role of higher-level processing in robustness. Overall, the opinions of PhD F and PhD B on generating queries automatically were not explicitly discussed in the meeting.",
        "In the meeting, PhD F and PhD B had different opinions on the topic of generating queries automatically. PhD F mentioned that even with diagnostic rhyme tests, humans are still better at understanding noise than machines. However, PhD B disagreed and mentioned that language models are important in improving machine-generated queries. They discussed the possibility of generating queries using digits. \n\nIn the meeting, Grad A discussed the status of transcription, mentioning that the tape for the IBM system has been made and is being transcribed. They also discussed the transcription progress from the ICSI side, with Jane assigning more meetings to be transcribed. They talked about the potential for transcribers to work on initial data from the SmartKom data collection. \n\nThey also discussed the issue of disk space and the need for more space, particularly for the expanded meetings. They discussed the possibility of hanging disks off the new SUN-Blade machines or finding space in the machine room. They also talked about the need to consolidate old disks to free up space. \n\nIn the meeting, Grad A mentioned the upcoming telephone meeting with Mari to discuss the progress and achievements of the project. They also discussed the possibility of having separate meetings to discuss recognition and other topics related to the project. PhD D shared the latest results on recognition, including the performance of the PLP configuration and the potential for using more read speech data to improve results. They also discussed the progress of the tandem system and the need for a smaller phone set for training. \n\nOverall, PhD F and PhD B had different opinions on generating queries automatically, with PhD F highlighting the limitations of machines in understanding noise and PhD B emphasizing the importance of language models. They also discussed transcription progress, disk space issues, and the upcoming telephone meeting with Mari. PhD D shared the latest results on recognition and discussed the progress of the tandem system.",
        "In the meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly stated. However, there was a discussion about training a hybrid system and the importance of the dictionary and alignment process. PhD D mentioned that the dictionary made a significant difference in reducing error rates. PhD B also mentioned the importance of alignment and initial alignments from Decipher. PhD F asked about the performance of the best Switchboard system, but there was no clear answer given. There was also a discussion about the process of transcribing meetings and the challenges of adjusting time boundaries and identifying speech in overlaps. Overall, the meeting did not provide specific opinions on generating queries automatically, but rather focused on related topics such as training systems and transcribing meetings.",
        "In the given meeting, PhD F and PhD B had different opinions on the topic of generating queries automatically. PhD F mentioned that if the pathological cases and non-natives were excluded, the average error rate for generating queries automatically was around 1.4%. PhD B added that it didn't matter whether the lapel or other microphones were used, as the error rate was consistent. They also discussed the challenges of forced alignments and the difficulties in getting clean alignments. PhD F mentioned that he had been struggling with forced alignments and had not been able to get good results using the current scheme. He also mentioned the need for a transcriber to time mark the speech and suggested comparing the alignments before and after tightening the boundaries. PhD D mentioned the possibility of using Thilo's energy segmentations to improve the alignments. They also discussed the challenges of adapting distances and the timing issues in the recordings. PhD D mentioned the possibility of using Thilo's output to approximate the alignments and suggested using reject models for non-speech segments. They also discussed the potential of using non-lapel recordings for alignment and the need for hand-tweaking. The conversation then shifted to the comfort and fit of the microphones used in the meeting. They mentioned the possibility of adjusting the microphone to fit individual head sizes and the use of counterbalance weights to improve comfort. They also discussed the plans of NIST for their own recording system, which includes close-mounted and lapel microphones, arrays, and video cameras. They also mentioned the use of adaptation techniques in speech recognition and summarization tasks. Overall, the opinions in the meeting varied, with some suggesting the use of adaptation and others mentioning the challenges and limitations of forced alignments. The need for further research and evaluation in the field of automatic query generation was also highlighted.",
        "In the meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly discussed. However, there were discussions about generating transcripts and alignments for the IBM transcription, the use of the SRI recognizer for segmentation and recognition experiments, the collection of digits and the possibility of using automated methods for transcription, and the inclusion of SmartKom dialogues in the corpus. It was mentioned that PhD F believed that more data is better for generating queries automatically, but this was not directly related to the topic of discussion. Overall, the meeting focused more on practical aspects of transcription and data collection rather than the opinions of specific individuals on generating queries automatically.",
        "In the meeting, PhD F and PhD B discussed the topic of generating queries automatically. PhD F expressed their intention to bring up the topic and discussed whether it should be handled as a special case or folded into the existing infrastructure. PhD B agreed that it made sense to handle it with the same infrastructure to avoid unnecessary duplication. PhD B also mentioned the naturalness issue and how the topic of generating queries automatically is different from regular meetings. Professor D agreed that it was scenario-based and had a different purpose. They discussed the organization of the data and whether it should be labeled as part of the meeting corpus or its own separate entity. PhD B raised concerns about consent issues and transcription, but PhD E clarified that transcription was already being done in Munich. They also discussed the possibility of storing the data on CD-ROM or DVD and the potential issues with the reliability of these media. PhD I suggested using tape for archiving and mentioned the need for more disk space. They also discussed the back-up system and the saturation of the current system. PhD I proposed using high-density tape drives and non-backed-up disks for archiving the data. They also discussed the issue of disk space and the possibility of getting more disks. Professor D suggested using the same tools and conventions for handling the data and mentioned the possibility of recycling backed-up disk space. They also discussed the distribution of the data and the need for a separate directory for other types of data. PhD I mentioned the possibility of using C-CD-ROM or DVD for normal access to the data. They also discussed the need for a separate procedure for handling the data and who would be responsible for it. PhD B raised the issue of consent and transcription, and PhD E clarified that transcription was already being done in Munich. Professor D suggested using tape for archiving and mentioned the need for more disk space. They also discussed the possibility of using high-density tape drives and non-backed-up disks for archiving the data. PhD I mentioned the potential confusion of labeling the data as part of the meeting corpus and suggested letting it be its own separate entity. PhD B raised concerns about consent issues and transcription, but PhD E clarified that transcription was already being done in Munich. Professor D suggested using tape for archiving and mentioned the need for more disk space. They also discussed the possibility of using high-density tape drives and non-backed-up disks for archiving the data. PhD I mentioned the potential confusion of labeling the data as part of the meeting corpus and suggested letting it be its own separate entity. PhD B raised concerns about consent issues and transcription, but PhD E clarified that transcription was already being done in Munich. Professor D suggested using tape for archiving and mentioned the need for more disk space. They also discussed the possibility of using high-density tape drives and non-backed-up disks for archiving the data. PhD I mentioned the potential confusion of labeling the data as part of the meeting corpus and suggested letting it be its own separate entity. PhD B raised concerns about consent issues and transcription,"
    ],
    [
        "During the meeting, there was a discussion about latency in the system. The professor had an issue with it because it could affect the user experience. However, the duration of the latency was not mentioned in the meeting. Other topics discussed in the meeting included discomfort with headphones, note-taking during meetings, the use of CrossPads for data collection, the generation of summaries, and the possibility of capturing visual information during meetings. The meeting participants had different opinions on these topics, but it was agreed that the summaries and visual information could be useful for future analysis and reference. The use of CrossPads for data collection was considered, but it was not clear if they would be used due to potential difficulties and the need for additional resources. Overall, the meeting focused on exploring different strategies for improving data collection and analysis during meetings.",
        "During the meeting, the discussion on latency in the system was not explicitly mentioned. The professor did not express any issues or concerns about latency. Therefore, there is no information to provide on the duration of the latency.",
        "In the meeting, the discussion on latency in the system was brought up. The professor had an issue with the latency because it could potentially affect the performance of the system. The duration of the latency was discussed, and it was mentioned that the latency was around 240 milliseconds. The team was working on reducing the latency by implementing new filters and downsampling techniques. They also discussed the use of spectral subtraction to improve the system's performance. Additionally, the professor mentioned the possibility of using a third-party voice activity detector to determine speech boundaries. The duration of the latency and the potential impact on the system's performance were the main concerns raised in the meeting.",
        "During the meeting, the discussion focused on various topics, including latency in the system. The professor had an issue with the latency because it affected the accuracy and performance of the system. The duration of the latency was not specifically mentioned in the meeting. \n\nThe professor mentioned that the current method of mixing all the data together is crude and not as effective as it could be. They discussed the possibility of using separate Viterbi algorithms for different frequency bands to improve the accuracy of the system. However, it was mentioned that this approach only helped for one or two iterations and did not provide long-term benefits.\n\nThe professor also expressed concerns about the performance of the system's detector. They mentioned that the system was compared to an old standard recognizer and did not perform as well, especially in noisy environments. However, it was noted that the comparison might not be fair, as the system was not trained specifically for sonorant detection.\n\nThe discussion also touched on the measurement of the system's detector performance. It was mentioned that the detector's performance was measured by looking at the confusions between sonorant and non-sonorant sounds. However, it was not clear if the detector had been applied to speech recognition or if it was solely focused on sonorant detection.\n\nAdditionally, the meeting briefly touched on the topic of other low-level detectors and features that could be used in addition to detecting sonorants. Some suggestions included detecting frication, abrupt closure, R-coloring, nasality, and voicing.\n\nOverall, the meeting provided insights into the challenges and considerations related to latency in the system and the professor's concerns with its performance. However, specific details about the duration of the latency were not discussed.",
        "During the meeting, the discussion on latency in the system was briefly mentioned by one of the PhD students. The issue with latency seemed to be related to the normalization process and the low signal-to-noise ratio in the speech files collected by the microphone. The professor expressed concern about the accuracy of the transcription and the need for more detailed temporal markings. The duration of the latency was not explicitly mentioned in the meeting.\n\nAdditionally, the meeting touched on the topic of data collection and the amount of transcribed data available. It was mentioned that there is a 45-minute piece that has been transcribed by Jane, and there are approximately 10 hours of recorded but not transcribed data. The professor mentioned the possibility of recording more meetings, particularly those with strong differences of opinion or emotional aspects. The idea of collaborating with local broadcast media to record panel shows or discussion shows was also discussed. The goal is to collect a significant amount of data, potentially exceeding 100 hours.\n\nThe discussion also touched on potential projects and research questions that could be explored with the available data. The idea of using energy patterns in the meeting as a measure of interaction was mentioned, as well as the possibility of exploring echo cancellation and adaptation techniques. The availability of the consent forms for participants was also mentioned, with the suggestion of having participants sign the form once every few meetings.\n\nOverall, the meeting provided some insights into the issues surrounding latency in the system and the ongoing data collection efforts. It also highlighted potential areas for further research and exploration with the available data.",
        "During the meeting, there was a discussion about latency in the system. The professor had an issue with it because it was causing delays in sending the ten hours of data to IBM. The duration of the latency was not specified in the meeting. Additionally, the meeting also covered other topics such as transcription status, participant approval, DARPA demo status, and disk issues. The discussion on latency was brief and did not provide detailed information on the issue.",
        "During the meeting, the discussion focused on the issue of latency in the system and the professor's concerns about it. It was discovered that the Hub-five system was performing well on the digits because there was a significant amount of read speech data in the training set. The professor had an issue with this because the digits only accounted for a fifth of the training data, which equated to around two hours. The rest of the data consisted of read TIMIT data, ATIS data, and Wall Street Journal data. The professor believed that having more read speech data helped improve the error rate and suggested that the people training the digit recognizers should consider using something other than TI-digits.\n\nThe discussion also touched on the availability of more read speech data, with the suggestion of using the focus condition zero from Hub-four from Broadcast News, which is mostly prepared speech. The professor mentioned that the dictionary used in the Hub-five system made a significant difference in the error rate reduction on Switchboard data.\n\nThe meeting also discussed the issue of latency and the duration of the latency. It was mentioned that the professor was interested in running lots of experiments once they knew the structure of what they were doing. The discussion then moved on to the topic of embedded training and whether they should use the net before doing embedded training. The suggestion was made to try running a standard hybrid system based on the features and the dictionary used in the Hub-five system.\n\nThe duration of the latency was not specifically mentioned in the meeting, but it was clear that the professor had concerns about it and wanted to address it. The meeting ended with a discussion about the size of the hidden units in the net, with the suggestion to start with a smaller size and then evaluate the performance before deciding to increase the size.\n\nIn summary, the discussion on latency in the system centered around the professor's concerns and the need to address it. The duration of the latency was not specifically mentioned, but it was clear that the professor had concerns about it. The meeting also touched on the use of read speech data and the importance of the dictionary in reducing the error rate.",
        "During the meeting, the discussion revolved around latency in the system and the professor's issue with it. The professor expressed concern about the current system's latency and mentioned that Ericsson's layoffs may affect their work on speech recognition. The duration of the latency was not specifically mentioned in the meeting. Additionally, the meeting touched on other topics such as Guenter's job at a technical college, the possibility of looking into alternative solutions, and the idea of modifying components in the model to adjust their importance. The meeting also discussed the progress made in developing noise suppression and feature nets, and the need to freeze certain aspects of the system to focus on other areas. The meeting concluded with a suggestion to improve communication between the team members and the possibility of setting up a mailing list to share updates and collaborate more effectively.",
        "During the meeting, the discussion on latency in the system was not explicitly mentioned. However, the professor did mention that they were considering adding a second stream to the system in parallel with the existing stream. This second stream would not add any latency to the system. The duration of the latency was not discussed in the meeting. \n\nThe professor had an issue with the latency in the system because they wanted to ensure that the system was able to handle both long-time effects and noise. They mentioned that the current system had difficulties with noise and long-time effects, and they needed to address both of these issues simultaneously. The professor also mentioned that there were tuning things and improvements that needed to be made to the system, such as improving the noise estimator and the voice activity detection (VAD). They also discussed the importance of adding a neural network and improving the VAD in the system.\n\nIn terms of the performance of the system, it was mentioned that the system was ranked second in the evaluation, but this was without testing it on German and Danish data. The professor also mentioned that the ranking did not change after testing it on the German and Danish data. The duration of the latency was not discussed in the meeting.\n\nOverall, the discussion on latency in the system was not the main focus of the meeting, but it was mentioned that the system did not have any latency issues and the professor had other concerns related to noise and long-time effects."
    ],
    [
        "During the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the transcription status and the progress of transcribing meetings. Grad D provided updates on the status of transcription, mentioning that IBM had made the tape for the meetings and sent it to the transcribers. Grad E also asked which meetings were being transcribed and it was mentioned that certain meetings were awaiting to go to IBM while the rest were being transcribed in-house. Grad B provided updates on the meeting regarding storage disks, mentioning that there was a need for more disk space and suggesting hanging scratch disks on the new SUN-Blades. Grad D also mentioned that there were plans to have a separate meeting to discuss the work on recognition systems, as it may not be of interest to everyone in the current meeting. Additionally, Grad D mentioned the results of testing the PLP configuration and the improvement achieved when combining the Hub-five system with the N-best ROVER system. Grad D also discussed the progress on the tandem system and mentioned plans to train a new net using the alignments provided by SRI and limit the phone set dimensions. It was also mentioned that there were plans to run a standard hybrid system based on the new MLP and dictionary.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that the computer should be able to generate questions based on certain intentions and conditions, similar to how it can understand utterances. The idea was to have the system ask itself questions, understand the answers, and enter a dialogue with itself. This would allow for learning and improvement in the system. Grad E's contribution to the discussion on storage disks was not mentioned in the meeting. Grad B provided updates on the meeting on disk storage, mentioning that they made some improvements to the dictionary and alignment in the past, but there were still areas that needed fixing. The updates on disk storage were not discussed in detail in the meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not clearly mentioned. However, they did mention the idea of using a formalism to explain certain concepts without going into intense detail. Grad E also mentioned that the paper they were discussing did not provide enough detail about the XML cases. \n\nRegarding Grad E's contribution to the discussion on storage disks, there was no mention of Grad E's contribution to this specific topic in the meeting.\n\nLastly, there were no updates provided by Grad B regarding the meeting on disk storage in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that the computer would primarily be checking through things that were already done by someone else, while the wizard would be correcting and making adjustments. Grad E's contribution to the discussion on storage disks was not mentioned in the meeting. As for the updates provided by Grad B regarding the meeting on disk storage, it was mentioned that the current disk space was about halfway through, and there was a need for more disk space. The idea of using CD-ROM or DVD as storage media was brought up, but it was mentioned that these media can degrade over time. It was suggested to use tape drives for archiving, as they are more reliable. The issue of backup capacity and the need for a new file server was also discussed. It was proposed to use non-backed-up disks for archiving and to perform the backups manually. The question of whether the SmartKom dialogues should be considered part of the meeting corpus was also raised, and it was decided that while they could be stored under the same directory tree, they would be labeled separately and not considered part of the meetings corpus.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the development of a data collection task. They talked about the error rates in the male and female portions of the development set and the differences between ICSI PLP and SRI features. They also discussed the possibility of using low-pass filters and vocal tract length normalization to improve the results. Grad E contributed to the discussion on storage disks by mentioning that the Hub-five system band-limits the channel at around 3700 Hz, and Grad B provided updates on the meeting on disk storage, including the possibility of getting more processors and upgrading the processors.\n\nIn terms of the data collection task, Grad C explained the new scenario they came up with to avoid rephrasing and ensure that subjects have clear intentions and act upon them. The idea is to give subjects a high-level category of tasks, such as going shopping or sightseeing, and let them choose specific tasks within those categories. They will be given a tourist map with symbols for objects and can make notes on it to remember their intentions. The task will involve interacting with the computer system, represented by Fey, to complete the chosen tasks. The goal is to get subjects to have intentions without giving them clear wording or phrasing of the tasks.\n\nIn terms of the SmartKom parser and natural language generation module, Grad F mentioned that he had made progress on the parser but would provide more details on Friday. Grad C mentioned that Tilman Becker had already modified the natural language generation module to produce English output. The time for the EDU Project was also fixed for the last week of April until the fourth of May, and it was emphasized that Grad F and Grad B should be present during that time.\n\nOverall, the meeting discussed the development of a data collection task, updates on the SmartKom parser and natural language generation module, and the scheduling of the EDU Project.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the SPG (Source-Path-Goal) actions. They discussed how the computer and wizard can handle different SPG actions such as Enter, View, and Approach. They also discussed the possibility of having multiple schemas and action schemas in parallel.\n\nGrad E's contribution to the discussion on storage disks was not mentioned in the meeting.\n\nRegarding the updates provided by Grad B, they discussed the structure of the XML for the SPG actions and how it can be used to define different categories and schemas. They also discussed the possibility of linking different schemas together and the need for pointers or references between them. Grad B mentioned the importance of having a clear structure for the XML and the ability to define different types of actions and their corresponding schemas.\n\nIn summary, the key points discussed in the meeting were about the roles of the computer and wizard in handling SPG actions, the structure of the XML for defining categories and schemas, and the possibility of linking different schemas together. Grad E's contribution to the discussion on storage disks was not mentioned. Grad B provided updates on the structure of the XML and the ability to define different types of actions and their corresponding schemas.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not clearly mentioned. The meeting mainly focused on scheduling the meeting time and discussing updates on storage disks. Grad E's contribution to the discussion on storage disks was not mentioned in the meeting. Grad B provided updates regarding the meeting on disk storage, but the details of the updates were not provided in the meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that the computer system is designed to understand and respond to user queries, while the wizard system is a human operator who takes over when the computer system crashes. Grad E contributed to the discussion on storage disks by asking about how the data collection process works, and Grad B provided updates on the meeting on disk storage by mentioning that the data collection was not intended for a specific purpose and that the tasks were not differentiated by intentionality.\n\nAdditionally, Grad D and Grad C discussed the concept of intention and how it relates to the tasks given to the subjects in the data collection process. They also talked about the need for a clear understanding of the contextual factors that may influence the interpretation of the data.\n\nIn terms of updates, Grad B mentioned that they have received the full versions of the SmartKom system and are working on getting it up and running on their machines. They also discussed the possibility of using XML format for data interchange and exploring the use of corpora for learning purposes.\n\nThe timeframe for the project was not specified in the meeting, but it was mentioned that there is no strict deadline for the research projects and that they will proceed opportunistically based on the availability of data and resources.\n\nOverall, the meeting focused on the progress made in implementing the SmartKom system and the challenges and considerations related to data collection and analysis.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were about setting up SmartKom as an institute-wide project and giving a talk to inform people about the project. Grad E also mentioned the need to fix bugs in the system and the possibility of collaborating with the System Gruppe. \n\nRegarding Grad E's contribution to the discussion on storage disks, there was no specific mention of Grad E's contribution in the meeting.\n\nAs for the updates provided by Grad B, he mentioned that he attended a linguistics colloquium on fictive motion, which he believed would be relevant to the project. He also discussed the differences in spatial descriptions between English and Japanese and mentioned the Deep Map project's work on spatial descriptions. Grad B also mentioned his interest in looking at initial interactions with the system and asked if there were transcripts available.\n\nIn terms of updates on the meeting on disk storage, there were no specific updates provided by Grad B in the given meeting.\n\nOverall, the meeting covered various topics related to the SmartKom project, including the roles of the computer and wizard, discussions on storage disks, and updates on the meeting on disk storage."
    ],
    [
        "SmartKom is an architecture that includes various modules, one of which is the SmartKom recognizer. In the meeting, it was discussed that the recognizer to parser module is being worked on and should not be a problem. They also talked about the generator module and the decision to either create a new syllable concatenating grammar for English generation or adopt the more in-depth style used in the German system. The importance of understanding the user's intentions and preferences in the tourist domain was emphasized, and the need for suitable interfaces and a belief-net module to guess the underlying intention was mentioned. The meeting also touched on the architecture and functionality of the action planner or dialogue manager, which is responsible for planning and guiding the conversation. The importance of feedback between the planning module and the language input module was discussed, as well as the need for robust and fast parsers for German language processing. The use of external services and the potential for synergy with other parsers, such as Morfix and Fastus, was also mentioned. Overall, the meeting provided insights into the architecture, modules, and importance of SmartKom in the context of the tourist domain.",
        "SmartKom is an architecture that combines decision networks and deep conceptual semantics based on cognitive linguistics. It involves the use of templates to capture information about an agent and the entity being discussed. The architecture also includes modules for parsing input and generating appropriate responses. The importance of SmartKom lies in its ability to provide a powerful and general notion of deep semantics, allowing for wide coverage across different domains. The meeting discussed the progress of the belief-net component of SmartKom, which involves designing the connections between nodes and considering the weighting of different factors. It was also mentioned that research on spatial descriptions and the differences between languages, such as English, German, and Japanese, could be relevant to SmartKom. Additionally, the meeting touched on the possibility of visualizing the belief-net and the availability of data for analysis. Overall, the meeting focused on the ongoing development and refinement of the SmartKom architecture.",
        "In the meeting, the architecture, modules, and importance of SmartKom were discussed. The meeting started with a conversation about manipulating objects using devices and the importance of understanding the neural differences between proximal and distal spaces. The discussion then shifted to the importance of building a system for SmartKom and the decisions that need to be made, such as the ontology and the parser. It was mentioned that a PhD student named Eva is working on a PRM (Probabilistic Relational Model) for SmartKom and has made progress in simplifying the model and creating classes and dependencies. However, the scalability of the system is still a challenge. Another visitor named Andreas discussed his work on a smart FAQ system that uses context information to improve search results. He mentioned the need for a shared interpretation of keywords and taxonomies and the use of probabilistic approaches. The meeting ended with a discussion about the potential integration of FrameNet into Andreas' system. Overall, the meeting highlighted the ongoing work and challenges in developing SmartKom and related systems.",
        "SmartKom is a project that focuses on developing a portable device for information retrieval in meetings. The project involves collecting data from meetings and releasing it as a corpus for research purposes. The architecture of SmartKom includes both close talking and far field microphones to capture high-quality audio. The goal is to differentiate between different intentions in meetings, such as viewing, entering, or getting close to an object. The importance of SmartKom lies in its potential to improve understanding and analysis of meetings, as well as its application in various domains such as tourism. The meeting discussed the need for deep understanding in SmartKom and how it can be achieved through a belief-net or similar modeling approach. The meeting also highlighted the importance of context, linguistic factors, and discourse history in interpreting intentions. The data collected from meetings will be used to extract features and train the belief-net to accurately infer intentions.",
        "SmartKom is an architecture that consists of various modules, including a parser, for understanding and processing natural language input. The importance of SmartKom lies in its ability to handle different languages and provide accurate and relevant responses based on user input. The meeting discussed the progress of the parser module, which has been successfully implemented in both German and English. The parser uses templates to match key words and phrases in the input and generate appropriate responses. The meeting also discussed the plan for data collection, which involves recruiting subjects and conducting experiments to gather data for training and improving the system. The data collection process will involve creating scripts and scenarios for subjects to interact with the system. The meeting also touched on the possibility of using existing data from other sources, such as discourse annotations, to further enhance the system's capabilities. Overall, the meeting highlighted the progress and future plans for SmartKom and emphasized the importance of collaboration and continuous improvement in the development of the system.",
        "SmartKom is an architecture that uses Bayes nets to model the relationships between different nodes and their probabilities. It is designed to handle multiple inputs to a node and uses a Noisy-OR function to combine the probabilities. The architecture consists of nodes that represent different cues or factors, and the goal is to determine the probability of a specific action or effect. The architecture includes intermediate nodes that represent the probability distribution of each node given that all other nodes are in the default or distinguish state. The architecture also includes a function that combines these intermediate nodes to determine the final probability. The Noisy-OR function is used to shortcut the full conditional probability table, making it easier to specify the probabilities. The architecture also allows for deterministic functions to be used to fill in the probabilities. The goal is to simplify the modeling process and reduce the number of probabilities that need to be specified.",
        "The architecture of SmartKom involves different modules, including the parser and the natural language generation module. The importance of SmartKom lies in its ability to understand and generate natural language, as well as its potential to assist in various tasks such as providing information on TV shows and movies. The meeting discussed the need to modify the parser and generation module, as well as the need for a schema to categorize different actions. The proposed schema includes categories such as Source-Path-Goal, Forced Motion, and Cost Action. The meeting also discussed the upcoming data collection and the need for subjects to interact with the system using high-level tasks. Overall, the meeting focused on the progress and future plans for SmartKom.",
        "SmartKom is an architecture that consists of various modules. One important module is the Source - Path - Goal (SPG) schema, which is used to describe actions such as Enter, View, and Approach. These actions have specific roles that can be filled in, and they are categorized under the SPG action schema. \n\nThe SPG action schema is a category within the overall action schema. It helps to organize and define the specific actions and their related schemas. Each action in the SPG schema has its own structure and specific roles that need to be filled in. \n\nThe importance of SmartKom lies in its ability to capture and represent complex actions and intentions. The architecture allows for the integration of different modules and the use of schemas to define and describe actions. This enables SmartKom to understand and respond to user commands and requests effectively. \n\nThe meeting discussed various aspects of the architecture, including the structure of the SPG schema, the role of action schemas, and the potential for linking different actions and intentions. There were debates about the organization and representation of the schemas, but overall, the meeting concluded that the current approach is workable and allows for flexibility in defining and categorizing actions. \n\nIn the future, the team plans to provide more examples and documentation to further clarify the architecture and its usage. They also discussed the possibility of refining and improving the architecture based on feedback and the evolving needs of the system."
    ],
    [
        "During the meeting, the options discussed regarding the location of the recording equipment were not mentioned. The meeting primarily focused on the topic of transcription. The participants discussed using a tool called \"Transcriber\" from a French group for converting audio to text. They mentioned that they are currently transcribing one meeting's worth of audio as a pilot study, and they are considering hiring linguistics grad students and undergrads to do the transcription. They also discussed the possibility of using automatic speech recognition tools for transcription and the importance of accurate timing and speaker identification. The participants mentioned the availability of a corpus of general spoken English from Santa Barbara and the potential use of that data for transcription tasks. They also briefly discussed the idea of distributing the transcripts and audio files in the future. Overall, the decision regarding the location of the recording equipment was not addressed in the meeting.",
        "During the meeting, the options and decision regarding the location of the recording equipment were discussed. It was mentioned that an external service could be hired for transcription, with an estimated cost of $300 per hour. However, it was also noted that these services may not be able to handle multiple channel data and may not provide speaker identification. Another option discussed was using graduate students for transcription, which would cost around $10 per hour. It was mentioned that the current software being used for transcription can handle multiple speakers, but the user interface only allows for two speakers. It was suggested that a web site be created to document the project and consolidate all the data and documents related to it. The idea of using TCL plug-in for the web site was also brought up. The possibility of generating the transcription automatically using tools was mentioned, but it was agreed that it would require further development. The discussion then shifted to the electronics aspect, where a box was proposed to be used for recording. The box would have two headset jacks and an LED indicator. It was suggested that the LED should be off when the box is not in use. The idea of leaving the PZMs on the table and wiring them to a bundle of cables was also mentioned. The decision to leave the PZMs on the table and create a web site for documentation was made.",
        "During the meeting, options and decisions were discussed regarding the location of the recording equipment. One option discussed was to use epoxy or screws to secure the equipment to the table. Another option was to use Velcro to attach the cables to the table. The decision was made to use a sleeve to hold the wires and to have two cables at each station. The reason for having two cables at each station was to allow two people sitting next to each other to connect to the same box. The decision was also made to have a wireless user interface using a laptop with a wireless modem. The meeting also discussed the need for a cabinet to hold the equipment and the possibility of using a monitor for displaying information. The decision was made to design a cabinet that opens up from the top to allow access to the mixer and to use a laptop with a wireless modem for the user interface. The meeting also discussed the need for training the transcribers and the progress made in transcription. It was mentioned that the transcribers would prefer a beep followed by a number at the beginning of each utterance to help them stay organized. The meeting also discussed the need to do recognition on automatic segmentations and the progress made in improving the vocal tract length normalization. The meeting concluded with the discussion of hiring additional transcribers and the plan to keep the staff on the leaner side to avoid layoffs in case the IBM project progresses quickly.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. One option mentioned was to create new segments, but it was noted that this could be complicated. Another option discussed was to keep an old copy of the old time marks to track any cheating. It was mentioned that merging the pre-segmented version with what has been done so far could be a good solution. It was also noted that in the future, it will be possible to start with pre-segmented and remain pre-segmented throughout. Another option discussed was to have someone record the meeting, and it was suggested that Chuck or Adam could do it. \n\nIn addition to the options, the decision was made to reorganize the directory structure for all of the meeting recorder data. Jane prepared a spreadsheet to organize the meetings, including start time, date, old and new meeting names, number of speakers, duration, transcription status, and comments. The plan is to export this as HTML and put it on the Meeting Recorder web page to keep people updated. The decision was also made to have the participants approve the transcriptions for distribution before the DARPA meeting in July. \n\nRegarding the location of the recording equipment, it was mentioned that the current system is not optimized for the final word error metric and that there may be room for improvement. One suggestion was to try using principal components and deltas on the tandem features to see if it improves the system. It was also suggested to retrain the tandem system with the new features and to concatenate the neural net outputs with the regular features to create a combined feature vector. \n\nOverall, the options discussed and the decision made revolved around the organization of meeting data and potential improvements to the recording equipment and transcription process.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. One option was to use CrossPads, which are note-taking devices that could potentially capture additional information during the meetings. However, it was mentioned that if the main recorder (presumably a laptop) couldn't use CrossPads, it may not be as useful for others to use them either. Another option discussed was taking pictures of the whiteboard or any other visual aids used during the meetings. This would provide a visual record of the information discussed. It was also suggested to have a designated note-taker who would summarize the meetings and email the minutes to everyone. This could serve as a summary of the meeting and potentially help generate queries later on. The idea of having oral summaries immediately after the meeting was also brought up, as it could provide a different perspective and help generate queries. Ultimately, it was agreed that having some form of visual record, such as pictures of the whiteboard, would be useful in preserving important information from the meetings.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. It was mentioned that a donation could be obtained to acquire the equipment, but it would depend on Landay and the availability of a student to set it up. It was also suggested that if the equipment requires a lot of time to set up, it may not be feasible to do so. It was agreed that the current activities were pilot projects and that they would try different options to see what works best.\n\nThe decision made regarding the location of the recording equipment was to try using CrossPads and see how it works. It was also decided to ask participants to generate queries at the end of the meeting based on what they found important or interesting. It was suggested that people could also provide oral summaries of the meeting if they were willing to stay afterwards. It was mentioned that the importance marking and summarization could be useful for generating keywords and constructing queries.\n\nIn terms of action items, it was decided to look into the requirements for human subjects, send web page information to the professor, clean up web pages by mid-July, put together mailing lists, email Landay about obtaining the recording equipment, and email Picheny about shipping address and other details. It was also mentioned that it would be helpful to have non-technical and non-speech people use the system to get more realistic user feedback.\n\nRegarding data formats, it was mentioned that the format would depend on what the team is comfortable with and that the current web pages could be used as a source of text for language modeling. The team also discussed the possibility of gathering data with less overlap by having meetings with specific rules of participation or selecting meetings with less overlap naturally.\n\nOverall, the options discussed and the decision made regarding the location of the recording equipment focused on trying out different methods and gathering feedback to determine what works best for the project.",
        "During the meeting, the options discussed regarding the location of the recording equipment were:\n\n1. Using different groups of people and different sizes to get more variety in the recordings.\n2. Considering the style and dominance relations of the group of people being recorded.\n3. Recording both technical and administrative meetings to compare the level of overlap.\n4. Exploring the use of near-field microphones to minimize problems with overlap.\n5. Considering the use of found data, such as televised political debates or congressional hearings, that have less overlap.\n6. Discussing the possibility of modifying the amount of overlap in the recordings if desired.\n7. Mentioning the availability of data collected by the CMU group, which is different from the type of meetings being recorded.\n\nNo specific decision was made regarding the location of the recording equipment during the meeting. However, there were discussions about the need for more disk space to store the recordings and the possibility of using external drives or additional disk racks. It was suggested to have a separate meeting to discuss recognition-related topics to avoid boring those who are not interested. The meeting also touched on the transcription status and participant approval processes.",
        "During the meeting, the options discussed regarding the location of the recording equipment were to either continue recording at ICSI or to set up a room in the linguistics department or another building on campus. It was suggested that if Mari from IBM is not using the equipment, it could potentially be set up in a room in the linguistics department. However, it was also mentioned that space is scarce on campus and finding a room may be difficult. Another suggestion was to have regular meetings of different types that are known in advance, such as this meeting, the front-end meeting, and a networking group meeting. It was mentioned that having data from different domains or different types of meetings would be useful for research purposes. It was also discussed that for some research, it would be beneficial to have recordings of different speakers and different types of meetings, while for other research, having recordings of the same group but with different summaries would be more useful. It was mentioned that the equipment could potentially be made portable to record meetings in different locations. It was also suggested to advertise to graduate students and professors on campus to have their meetings recorded at ICSI. It was noted that it would be important to have meetings in English to ensure language model compatibility. It was also mentioned that having a diverse range of speakers would be beneficial for acoustic research. It was discussed that for certain research purposes, having recordings of meetings with specific criteria, such as a pre-existing meeting with a consistent group of participants, would be more useful. It was mentioned that having a large variety of idiolects in the recordings could make it difficult to build language models. It was also discussed that for certain research purposes, having recordings with tabletop microphones would be sufficient, while for others, having recordings with distant and close microphones would be necessary. Overall, it was emphasized that each researcher should take charge of ensuring they have enough data for their specific research interests.",
        "During the meeting, several options and decisions were discussed regarding the location of the recording equipment. The first option discussed was using a simple setup, such as a tape recorder or a DAT machine, to record the meetings. This option was suggested as a quick and easy solution for recording meetings that only require a transcription later.\n\nAnother option discussed was the idea of bringing people to the meeting location instead of recording the meetings. It was suggested that the first priority should be to get people to come to the meeting location, as the room is underused and can accommodate the meetings. It was also mentioned that offering free lunch could be a good incentive to get people to attend the meetings.\n\nIn terms of the recording equipment, it was mentioned that there is currently limited space on the existing disk for recording meetings. However, it was mentioned that there will be additional disk space available in the future with the addition of a new disk rack and more disks.\n\nIn regards to the specific decision made, it was decided that the location of the recording equipment will remain in the current Meeting Recorder disk. It was mentioned that there is enough space on this disk to record about four more meetings. It was also suggested that the Aurora and other data should be moved off of the Meeting Recorder disk and onto the Broadcast News disk to free up more space.\n\nIn summary, the options discussed regarding the location of the recording equipment were to use a simple setup for recording meetings or to bring people to the meeting location. The decision made was to keep the recording equipment in the current Meeting Recorder disk and to move other data to the Broadcast News disk to free up more space.",
        "During the meeting, the options and decision regarding the location of the recording equipment were discussed. It was suggested to start with the simpler signal and then proceed with a mixed signal. It was also mentioned that it would be interesting to try a couple of features with both signals to see how they work. The idea of using a PDA with two microphones was also brought up, but it was noted that there may be limitations in terms of positioning and the ability to detect overlaps. The decision was made to not change the names in the transcript and audio recordings, as it would cause discrepancies and make it difficult for discourse analysis. It was suggested to use speaker identifiers in the transcript and audio to maintain consistency. The issue of anonymization and how it would impact discourse analysis was also discussed. It was noted that while anonymization may be necessary for publications and public release, it may not be practical for discourse analysis within the research group. The idea of having multiple versions of release, one with anonymization and one without, was suggested. The need for a consistent licensing policy was also mentioned. The importance of keeping track of speaker identities for discourse analysis was emphasized, and the challenge of finding a balance between privacy and usefulness for discourse analysis was acknowledged. The meeting concluded with a discussion about the possibility of reading the digits with different intonations to make the transcription process more interesting.",
        "In the meeting, the options and decision regarding the location of the recording equipment were discussed. It was mentioned that the transcript and actual numbers being read were available, so the location of the recording equipment was not solely dependent on that. The agenda of the meeting included topics such as transcription status, DARPA demos, XML tools, disks, backups, and more.\n\nDuring the meeting, it was mentioned that several more transcribers had been hired and they were making good progress. The double checking of the transcripts was taking longer than expected and would require an additional week. It was also mentioned that the data formats and information retrieval tools were being tested and would be available for use.\n\nThe decision regarding the location of the recording equipment was not explicitly stated in the meeting. However, it was discussed that having the equipment in a non-backed-up disk was not recommended, as it could lead to potential data loss. It was suggested to continue using the current backup system and explore options for additional disk space. The idea of burning CDs for distribution was mentioned, but it was noted that burners may not be reliable for long-term backup.\n\nThe CrossPad device, which allows for note-taking and time tagging, was discussed. It was mentioned that the device had been used a few times but there were concerns about the noise of the pen and the need for infrastructure to synchronize the time. It was suggested to explore alternatives such as using PDAs with wireless cards for note-taking and time marking.\n\nThe meeting also touched on other topics such as ordering more wireless equipment, ongoing recognition runs, and the progress of various projects. It was mentioned that Andreas, Dave, Chuck, and others were involved in these projects but specific details were not provided.\n\nIn summary, the meeting discussed the options and decision regarding the location of the recording equipment. It was suggested to continue using the current backup system and explore options for additional disk space. The use of the CrossPad device for note-taking and time marking was discussed, but alternative options such as using PDAs with wireless cards were also considered. Other topics related to ongoing projects and equipment orders were also mentioned."
    ],
    [
        "In the meeting, there were discussions about several topics including the use of close talking microphones, the upcoming NIST visit, and the transcription process. The participants discussed the need for better quality close talking microphones and the importance of having uniformity in microphone selection and placement. They also talked about the NIST visit and the interest in using microphone arrays for recording meetings. The transcribers provided an update on their progress and the time it takes to transcribe the meetings. Additionally, there was a discussion about the ATLAS system and the possibility of providing transcriptions for experimentation. The meeting concluded with a mention of the transcription process used by IBM for their speech recognition products.",
        "During the meeting, there were discussions about several topics including talk, neurons, the transcriber pool, and acoustic-phonetic analyses. The participants talked about the difficulty of following conversations, especially when there are reduced phonetic words. They also discussed the use of mixed signals and the volume disparity in transcriptions. The transcribers were using the mixed signal mostly, but there was a need for fine time markings. The participants also discussed the possibility of using IBM for transcriptions and the historical reasons for their involvement. They talked about the challenges of transcribing meetings with heavy accents and the need for better time markings in transcriptions. They also discussed the possibility of using transcribers for other tasks such as dialogue act tagging and disfluency tagging. The participants talked about the benefits of having Brian involved in the project due to his knowledge of data usage. They also discussed the SRI recognizer and the need for time markings. They talked about the segmentation of meetings and the challenges of forced alignment without time markings. The participants also discussed the possibility of collecting more meeting data and reaching out to different departments or groups for recordings. They talked about the importance of having all English speakers in meetings and the challenges of different accents. They also discussed the possibility of using transcribers for fine-grained analysis of speech, such as marking articulatory features. The participants discussed the need for improving signal-to-noise ratio and the challenges of cross-talk in recordings. They also discussed the possibility of using pre-processing techniques to improve accuracy. Finally, the participants talked about the need to start working on the demo for the DARPA meeting and the importance of organizing tasks and deadlines.",
        "During the meeting, there were discussions about various topics including the talk, neurons, transcriber pool, and acoustic-phonetic analyses. In regards to the talk, there was a discussion about whether to have everyone say the same digits at the same time or at different times. The decision was made to have them say the digits at the same time. The transcriber pool was also discussed, with plans to hire additional transcribers to handle the workload. There was also a discussion about using automatic segmentations for meeting recognition instead of hand-segmentations. It was suggested that this change would eliminate the need for cheating and provide more accurate results. In terms of acoustic-phonetic analyses, there was a discussion about using different features and techniques to improve the accuracy of the system. It was mentioned that the pitch features were better in the current data compared to previous data, possibly due to the close-talking microphones used. Overall, there were ongoing efforts to improve the system and explore different approaches.",
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. One of the discussions was about the use of different parameters to detect overlapping zones in speech recordings. The speaker mentioned studying acoustic events in the recorded speech and identified around 1000 acoustic events, including overlaps, in a 45-minute session. The speaker also mentioned considering silent sections as acoustic events. There was also a discussion about the need to mark the different acoustic events and study their characteristics. Another topic discussed was the need to identify and understand inference structures in language, particularly in the context of meetings. The speaker mentioned an example of how understanding the implications of certain phrases or sentences requires drawing inferences about time sequences, causality, and other aspects. The speaker expressed interest in using the recorded speech data to study these inference structures and their acoustic characteristics. Additionally, there was a discussion about the challenges of anonymizing the data and the potential sensitivity of mentioning names in the transcripts. The speaker also mentioned the need to distinguish between different acoustic events, such as speech, nonspeech sounds, and silence. Overall, the meeting covered various aspects related to talk, neurons, transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The main focus of the discussions was on the differences in the speech signal collected by different microphones and the need for accurate transcription of the speech events. It was mentioned that using the transcription to evaluate a different system would require using the speech file collected by the microphone to ensure accurate results. The idea of using the transcription as a reference for evaluating the system was also discussed. The issue of overlapping speech and the need to mark the beginning and end of overlapping zones was raised. It was suggested that speaker overlaps could be marked manually to speed up the process. The discussions also touched upon the challenges of processing speech files with low signal-to-noise ratio and the potential use of close-talking microphones for analyzing speaker overlaps. The topic of acoustic-phonetic analyses was mentioned in relation to evaluating the effects of room acoustics and echoes on speech signals. The possibility of using echo cancellation techniques and adapting filters to improve the quality of the recorded speech was discussed. Additionally, the availability of data for analysis was mentioned, including the recorded meetings and the need for more data from different types of meetings. It was suggested that additional data could be obtained by collaborating with broadcast media and recording panel discussions or other types of meetings. Overall, the discussions revolved around the challenges and strategies for accurately transcribing and analyzing speech signals in various contexts.",
        "During the meeting, the discussions were about various topics including the progress of the project, the amount of data collected, the transcripts from IBM, and the plans for future projects. The discussions also touched on the possibility of recording additional meetings, including political debates, and the potential use of the data for research purposes. There was also a discussion about the difficulties of transcribing and analyzing speech data, particularly in relation to the accuracy of phone labels and the need for more detailed annotations. The idea of incorporating articulatory features and prosodic information into the analysis was also discussed. Overall, the discussions were focused on the progress of the project and the potential avenues for future research.",
        "In the meeting, there were discussions about various topics including speech recognition, transcriber pool, acoustic-phonetic analyses, and the use of the new microphones. The discussions touched on the alignment of speech, the use of different acoustic features for spreading models, the inclusion of functional elements in transcriptions, the use of normalized features for speech-nonspeech detection, and the challenges of evaluating the system without manual references. The team also discussed the possibility of using cross-correlations to remove false overlaps in the transcriptions. The need for manually transcribed references and the potential use of forced alignment were also mentioned. The team discussed the progress of the presegmentation and channelization processes and the need to tighten up time boundaries. They also discussed the upcoming visit of the UW folks and the need for an agenda for their meeting. The team talked about the possibility of sending a sample of the transcriptions to IBM for their input and the challenges of adjusting boundaries based on the mixed signal waveform. Overall, the meeting covered a range of topics related to speech recognition and transcription.",
        "During the meeting, there were discussions about different topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions revolved around various issues and ideas related to these topics. Some of the main points discussed include:\n\n- The participants discussed the possibility of canceling a certain resolution or scrolling feature, and the potential impact on the user experience.\n- They also discussed the option of setting up multiple windows with different signals and using X Waves instead of Transcriber for faster loading.\n- The idea of preloading all the channels or using an interface that shows each waveform and ribbon for better visualization was also brought up.\n- The participants debated the pros and cons of using Transcriber interface for different windows to view the visual form of the signals.\n- There was a suggestion to change the interface to allow users to quickly switch between different channels and listen to individual channels without having to go to the menu.\n- The participants also discussed the challenges of aligning the chopped up waveforms and the possibility of expanding them if anything was cut off.\n- The issue of identifying and locating overlaps in the mixed signal was raised, and the participants discussed different strategies to handle this.\n- The participants also discussed the possibility of using forced alignment to improve the accuracy of the transcriptions and the challenges associated with it.\n- There were discussions about the potential of adapting the phone models and reject models to improve the forced alignment results.\n- The participants discussed the idea of using hand-tweaked alignments for certain meetings to improve the overall accuracy.\n- The participants also discussed the challenges of aligning non-native speakers' speech and the potential for improvement with adaptation.\n- The idea of using pre-segmented conversations with non-synchronous speech for feature extraction and analysis was brought up.\n- The participants debated the possibility of using the existing meetings for Eurospeech submission and the need for more accurate alignments.\n- The participants discussed the potential of using the NSA meetings for alignment improvement and comparing before and after results.\n- There were discussions about the design of a room with close-mounted mics, lapel mics, and arrays for recording conversations.\n- The participants also discussed the possibility of using a KEMAR head for improved recording and calibration.\n- The participants mentioned the legal issues surrounding the recording and the need for scenario-based recordings to comply with regulations.\n\nOverall, the discussions covered various aspects of talk, neurons, transcriber pool, and acoustic-phonetic analyses, focusing on the challenges, potential solutions, and future directions for research and development.",
        "During the meeting, there were discussions about various topics including the talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions started with informal conversations and introductions of the NIST folks. They then discussed a paper by Lori Lamel that focused on using data from a different task with insufficient data and adapting it for a new task. This was similar to what Liz and Andreas did with their work on the Broadcast News system. They also discussed the conclusions of the paper, which showed that using the Wall Street Journal data worked well for the task. They talked about the limitations of using simpler tasks for more complex tasks and the challenges of not having all the necessary phones in the simpler tasks. They also discussed the idea of using more data and simpler algorithms for better performance. The meeting then shifted to other topics, including the progress of the IBM transcription, the organization status, the Absinthe project, and the SmartKom data collection. They also discussed the possibility of using forced alignment for the digit transcriptions and the potential use of recognition algorithms for the task. They talked about the benefits of having clean digit transcriptions and the possibility of using the IBM transcription for this task. They also discussed the progress of the SmartKom data collection and the potential inclusion of this data in the corpus. Overall, the meeting covered a range of topics related to talk, neurons, transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, the discussions about the talk, neurons, transcriber pool, and acoustic-phonetic analyses focused on various topics. The purpose of the recording was to gather acoustic and language model training data for the SmartKom system. There was a discussion about whether to include all far-field channels or just one or two. It was decided that all channels should be included to maintain consistency. There was also a discussion about the legal aspect of collecting data and whether it could be used for other purposes. It was determined that there were no restrictions on using the data. The meeting also touched on the organization and labeling of the data, with the suggestion to create a separate directory for non-meeting data. The issue of disk space and backup was raised, and it was suggested to save the data as long as there is enough disk space available. The meeting then shifted to discussions about the SRI recognition experiments. It was mentioned that there was a difference in error rates between males and females, and various factors were explored to understand the cause of the difference. The discussions also touched on the boot models used in the experiments and the possibility of trying the experiments on different datasets. The meeting concluded with a discussion about the Absinthe system and its potential for net training and forward passes. It was mentioned that the system showed promise for achieving a speedup proportional to the number of processors. Finally, there was a brief mention of planning for a demo in July and the need for a sub-meeting to discuss it further."
    ]
]