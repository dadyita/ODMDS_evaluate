[
    [
        "In the meeting, the discussion revolved around various topics including XML tools, meeting data quality, and the current XML format for linking up different components in data. F and A both shared their opinions on the current XML format. F mentioned that the paper on the proposed system for Aurora was accepted and provided details about the conference where it will be presented. F also discussed their work on online normalization and the different approaches they tried. They mentioned that the means for the silence and speech portions can be very different, especially for certain coefficients. They also discussed the idea of varying the normalization parameters based on frequency. B suggested looking into the types of errors that occur with different normalization methods. A shared their work on cheating experiments to determine the effectiveness of intermediate categories in classification. They discussed using VTS (Vectorial Taylor Series) for noise removal and its impact on speech recognition. E talked about their experiments with VTS and how the results were not as good as expected. They mentioned using VAD (Voice Activity Detection) and LDA (Linear Discriminant Analysis) along with VTS, but the results were still not better than without using VTS. They also mentioned considering using Carlos' filters for noise estimation. D discussed their work on implementing Wiener filtering for the Aurora task and mentioned encountering some bugs in their code. They also talked about using known sections of nonspeech for noise estimation and the need for standardizing noise estimation methods. C discussed their experiments with subspace approaches and the challenges they faced. The meeting also involved discussions on the Taylor series expansion for log functions and the relationship between different expressions. Overall, the meeting covered a wide range of topics related to XML tools, meeting data quality, and the current XML format for linking up different components in data. The opinions of F and A on the current XML format were not specifically mentioned in the meeting.",
        "During the meeting, there was a discussion about XML tools, data quality, and the current XML format used to link different components in data. F and A expressed their opinions on the current XML format. Additionally, other topics discussed included the use of close-talking microphones, the upcoming NIST visit, modifications to the multitrans system, and the potential use of microphone arrays. It was suggested that the use of microphone arrays could be beneficial for capturing audio data in impromptu situations. However, it was also noted that setting up an array of microphones would require additional infrastructure and resources. Overall, the meeting covered various topics related to data quality and the tools used for data analysis.",
        "During the meeting, there was a discussion about XML tools, meeting data quality, and the current XML format used to link up different components in data. The opinions of F and A on the current XML format were not specifically mentioned in the meeting. However, there were discussions about the need for improved recording methods to ensure accurate data, the possibility of sharing resources with other interested parties, and the interest in obtaining video recordings of meetings. There were also discussions about the transcription process, including the use of transcribers to tag dialogue acts and disfluencies, as well as the potential for fine-grained analysis of speech using articulatory features. The idea of collecting more meeting data was also mentioned, with a suggestion to reach out to other departments and groups for potential collaboration. Overall, the meeting covered various aspects related to XML tools, meeting data quality, and the current XML format, but did not provide specific opinions on the current XML format from F and A.",
        "During the meeting, there were discussions on various topics such as XML tools, meeting data quality, and the current XML format used to link up different components in data. F and A shared their opinions on the current XML format. The meeting also touched on the use of English in different contexts and the challenges of speech recognition technology in different languages. \n\nIn terms of the discussion on XML tools, there was no specific mention of the tools being used or their effectiveness. However, the meeting did mention the need for data quality in XML format and the importance of accurate transcription and alignment of audio data.\n\nRegarding the current XML format, F and A expressed their opinions on the format. F mentioned a study conducted by BBN where they trained on American English and tested on different native speakers, finding that Mandarin Chinese speakers had the worst match and British English speakers had the second worst match. This suggests that F believes the current XML format should prioritize American English for recognition technology.\n\nA also shared their opinion on the current XML format, mentioning the importance of knowing the application and the National Institute of Standards. A brought up the idea of improving the signal-to-noise ratio and separating speakers in the XML format, as well as the possibility of using pre-processing techniques to enhance the quality of the data.\n\nIn terms of the SmartKom project, the meeting discussed the collection of dialogues for the project. There was a question about whether to include the data in the corpus and save the far-field channels. The decision was made to include all the far-field channels to provide a comprehensive dataset for acoustic studies.\n\nOverall, the meeting touched on various aspects of XML tools, data quality, and the current XML format. The opinions of F and A on the current XML format were shared, and the discussion also included the SmartKom project and the collection of dialogues.",
        "In the meeting, the discussion revolved around XML tools, meeting data quality, and the current XML format for linking up different components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting. However, the meeting primarily focused on other topics such as saving meeting data, defining the meeting corpus, and organizing data. The participants discussed the idea of saving meeting data and the potential usefulness of keeping it. They also debated whether the saved data should be considered part of the meetings corpus or kept separate. The participants agreed that if someone wants to include the saved data in their experiments, they can do so. They also discussed the idea of labeling the saved data as part of the meeting corpus or creating a separate directory for it. \n\nAdditionally, the meeting touched upon the issue of data quality and the need for accurate transcription. It was mentioned that transcription is done in Munich and is not a concern for the participants. The participants also discussed the current XML format used and its compatibility with the ICSI meeting transcription conventions. They debated whether the current XML format should be folded into the existing procedures or treated as a special case. It was suggested that the same tools and conventions can be used for the XML format, but it should be stored in a different directory to differentiate it from the meetings corpus.\n\nIn regards to the SRI recognition experiments, the meeting briefly mentioned them. It was mentioned that there were experiments being conducted using tandem features and PLP features. The participants discussed the differences in error rates between males and females, and the potential factors contributing to these differences. They mentioned the use of vocal tract length normalization and different filter shapes. It was noted that the results on females were slightly worse than on males, but further experimentation and analysis were needed to draw conclusions.\n\nThe meeting also briefly touched upon the use of Absinthe and Quicknet for net training and forward passes. It was mentioned that a Blass library was successfully ported to Absinthe, resulting in a speedup proportional to the number of processors. However, there were issues with Quicknet, and further investigation was needed to determine the cause.\n\nFinally, the meeting briefly mentioned the upcoming demo in July. It was suggested that a sub-meeting should be held to discuss the demo and involve key participants.",
        "During the meeting, the discussion revolved around XML tools, data quality in meetings, and the current XML format used to link up different components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting.\n\nRegarding XML tools, the assistant mentioned installing various XML tools in different languages like Java and Perl. These tools can be used to extract information from different files, such as user information, meeting transcripts, and meeting data. The assistant also mentioned converting Key files to XML format for easier extraction of information.\n\nThe meeting also touched upon the idea of using CrossPads, which are digital pads for note-taking. Some participants expressed their opinions on using CrossPads, mentioning that they found them useful for taking notes during meetings. However, others mentioned concerns about the noise of the pen and the need for infrastructure to synchronize the time on the CrossPads with the meeting recordings. The possibility of using PDAs with wireless cards as an alternative to CrossPads was also discussed.\n\nIn terms of equipment, the assistant mentioned ordering more wireless equipment, which will be used for both close-talking and far-field microphones. Additionally, the assistant mentioned plans to rewire the room to accommodate the different microphone types.\n\nOverall, the meeting provided insights into the use of XML tools, the potential benefits and challenges of using CrossPads, and plans for equipment upgrades.",
        "During the meeting, the discussion covered several topics including XML tools, data quality in meetings, and the current XML format used to link different components in data. F and A both had opinions on the current XML format. F mentioned the need for more data to conduct research and the importance of having regular meetings of known types to facilitate processing and higher-level work. A raised concerns about the language skills of participants and the need for fluency in English to build language models. The issue of disk resources and archiving was also discussed, with plans to free up space by archiving Broadcast News data. Finally, C provided an update on their work, which involved marking overlapping zones in meeting recordings and studying parameters to classify speech and overlapping speech using clustering algorithms or neural networks.",
        "During the meeting, there was a discussion on XML tools, data quality in meetings, and the current XML format used to link different components in data. F and A both provided their opinions on the current XML format. F suggested that it would be helpful to have a more clear and organized XML format to improve data quality and avoid overlapping zones in the transcription. F also mentioned that the current XML format is similar to the information obtained from Jane's segmentation by hand. A expressed interest in having the overlapping zones labeled automatically, but acknowledged the need for manual labeling to ensure accuracy. A also asked about the use of truth in labeling and the classification of different zones. The discussion continued with suggestions from other participants on using features like pitch extraction and differential derivatives to classify and analyze different frames. The idea of using a neural network or a decision tree as a classifier was also mentioned. The participants agreed that starting with simpler features and visualizing their separation in scatter plots would be beneficial before building more complex classifiers. The use of a mixed speech file was proposed to improve spectral distortion and make it easier to detect acoustic changes. The participants also discussed the possibility of using multiple microphones or arrays to enhance speaker separation and capture positional information. The meeting concluded with the suggestion of signing new agreements and the need to wind down the meeting to continue with other tasks.",
        "During the meeting, there was a discussion on XML tools, data quality in meetings, and the current XML format used to link different components in data. The opinions of F and A on the current XML format were not explicitly stated in the meeting. However, F did provide a sheet with a revised semantic specification and construction formalism. The revised notation included the ability to specify both construction and meaning types, as well as designating specific elements in the construction. There was also a discussion on the use of \"constraints\" versus \"designates\" in the notation, with F leaning towards using \"constraints\" to refer to both formal and semantic constraints. Overall, the meeting focused on refining the XML format and discussing the various aspects of data quality in meetings.",
        "During the meeting, there was a discussion on XML tools, data quality in meetings, and the current XML format used to link up different components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting. \n\nIn terms of XML tools, there was a debate on whether to include directed motion in the XML format. One option was to have more abstract constructions, such as subject and predicate, intersect with the directed motion constructions. Another option was to have subject, predicate, and verb object constructions that require certain expressions to fill the subject and object slots. The point was made that some constraints are necessary in the XML format, but the exact placement of these constraints is still being discussed.\n\nThe discussion also touched on the current XML format's ability to link up different components in data. It was noted that there are some semantic constraints that need to be addressed, such as the introduction of mental spaces. The mental space concept was acknowledged as not being included in the current XML format and it was suggested that additional notation may be needed for this.\n\nThere was also a mention of the designatum being a pair instead of just a meaning. This change was seen as a minor terminology adjustment and did not have a significant impact on the XML format.\n\nThe meeting participants also discussed the use of XML tools to highlight specific elements in a sentence, such as focus and stress. It was noted that stress as a form cue can be subjective and context-dependent, making it difficult to rely on for determining focus. The suggestion was made to focus on specifying the information structure of a sentence and leave the assignment of intonation contour to the phonology component of the XML tools.\n\nAnother topic discussed was the concept of topic-comment and how it relates to information structure. The idea of topic as the background or profile of information was mentioned, but it was noted that the precise definition of topic and its interaction with focus is still being explored.\n\nThe meeting also briefly touched on the inclusion of discourse situation context in the XML format. It was suggested that the XML format could include a list of entities being referred to in the discourse and their relevant properties. It was also noted that the discourse status of entities could be context-dependent and that additional slots may be needed to capture this information.\n\nOverall, the meeting provided a broad overview of the discussion on XML tools, data quality, and the current XML format for linking up different components in data. The opinions of F and A on the current XML format were not explicitly stated in the meeting.",
        "During the meeting, the discussion covered various topics including XML tools, data quality in meetings, and the current XML format for linking different components in data. The opinions of F and A on the current XML format were not explicitly stated in the meeting. However, there was a suggestion to focus on getting the XML format right and then potentially explore more elegant solutions such as inheritance in the future. The meeting also touched on the idea of construal and the possibility of using probabilistic relational models to generate Bayes nets for construal. Additionally, there was mention of some updates to the web site and the availability of JavaBayes for running Bayes nets. The next meeting was scheduled for Thursday at 4 PM, where A would potentially present a talk highlighting their work."
    ],
    [
        "The discussion in the meeting revolved around the topic of electronics, specifically the use of wireless microphones and the recording of data. The participants talked about the importance of wearing the microphones correctly to minimize background noise and breath sounds. They also discussed the need for everyone to fill out speaker and consent forms, as well as the option to edit the transcripts for privacy purposes.\n\nThe meeting then shifted to the topic of intentionality, particularly in relation to a project called Meeting Recorder. The project aimed to collect data on meetings and develop a portable device for information retrieval. The participants discussed the need to differentiate between different intentions, such as viewing, entering, and touching a building. They also mentioned the importance of considering contextual factors and linguistic cues in determining intentionality.\n\nThe participants acknowledged that the current system did not provide enough information to differentiate between intentions and proposed using a belief-net to combine contextual and linguistic factors. They discussed the possibility of collecting data through a scenario-based experiment, where participants would interact with a computer system to perform tasks related to visiting different locations in Heidelberg. The participants acknowledged that the data collected in this experiment may not provide clear answers regarding intentionality, but it would serve as a starting point for further research.\n\nOverall, the discussion in the meeting revolved around the use of electronics, the segment on intentionality, and the plans for data collection and analysis in the Meeting Recorder project.",
        "During the meeting, several topics were discussed including electronics, the segment, the results from the experiments, and the topic of intentionality. The discussion started with the plans for data collection and design, with Jane and Liz offering to help with the process. The conversation then shifted to the challenges of collecting data for tasks related to intentionality, as it is more complex than tasks with clear correct answers. The participants discussed the difficulty of creating an appropriate toy version of intentionality and the importance of understanding the tasks and intentions involved.\n\nThe meeting also touched on the issue of finding the best way to featurize the data collected and come up with a set of features that can be used to estimate the most likely intentions. The three intentions discussed were \"to go there,\" \"to see it,\" and \"to come as close as possible to it.\" The participants also talked about the distinction between entering an object, viewing it, and taking a picture of it.\n\nThe discussion then moved on to the selection of a belief-net package for the project. The participants considered using JavaBayes or other Java-based packages that are easy to interact with and modify. They also discussed the potential for using XML formats for data interchange and the need for a stable and reliable package.\n\nThe participants also talked about the possibility of using existing corpora and linguistic analysis to extract features for the belief-net. They mentioned the SmartKom system and the availability of XML packages for data extraction. The meeting concluded with a discussion about the time frame for the project and the next steps, including selecting a belief-net package and starting to populate it with data.\n\nIn summary, the meeting covered various aspects of the project, including data collection, design, featurization, belief-net selection, and the time frame for the project. The participants discussed the challenges of working with intentionality data and explored potential solutions and strategies.",
        "During the meeting, the discussion revolved around electronics, the segment, the results from the experiments, and the topic of intentionality. The participants talked about using a time-marked sequence of words to compute the scoring and how it simplifies the process. They also discussed the use of time constraints for references and hypotheses in Hub-five to do the scoring. The team mentioned using recognizer alignments to train the speech detector and how it would reduce the need for manual labeling. They also discussed the SmartKom project and collecting dialogues for acoustic and language model training data. The participants debated whether the SmartKom data should be part of the meeting corpus or a separate entity. They also discussed the possibility of using CD-ROMs or DVDs for archiving data and the issue of disk space and backup capacity. The team talked about the SRI recognition experiments and the difference in error rates between males and females. They discussed the use of tandem features and PLP features and the impact of vocal tract length normalization. The participants also mentioned the issue of pruning and how it affects the performance of the system. Overall, the meeting covered a range of topics related to electronics, experiments, and intentionality in the context of speech recognition.",
        "In the meeting, the discussion revolved around the topic of electronics, specifically related to smoothing, the segment, the results from experiments, and the topic of intentionality. They discussed the different techniques used for smoothing, such as auto-regressive models and mel cepstrum. They also talked about the size of the training set and how it affects the smoothing issues. The Baum-Welch algorithm was also mentioned as a factor in the smoothing process. They discussed the strategy of using a smaller training set for initial testing and then moving on to a larger training set for better results. The topic of boot models was brought up, with the conclusion that they are trained from scratch using different feature sets. They discussed the iterations involved in training the boot models, starting with context-independent models and gradually moving to context-dependent models. The effectiveness of the boot models was discussed, with the conclusion that the exact nature of the boot alignments is not a major factor in the quality of the final models. They also discussed the possibility of using different feature sets and the potential impact on the quality of the models. The meeting then shifted to discussing the upcoming demos and the need for further discussion and planning for them. They also discussed the progress made in porting libraries to Absinthe and the potential speedup it can provide. The topic of adding more processors and upgrading the processors was mentioned. The discussion then moved on to the transcription effort and microphone issues. They talked about the progress made in speech-nonspeech segmentation and the use of multi-mixture models. The effectiveness of the segmentation was discussed, and it was mentioned that the transcribers found it to be a significant improvement. The discussion then turned to the topic of microphone issues, specifically the need for a replacement for the uncomfortable head-worn mics and the difficulty in finding a compatible model. The possibility of using an existing tool for transcription was discussed, and the need for a good microphone placement was emphasized. The potential impact of breathing on speech recognition was also mentioned. Overall, the meeting covered a range of topics related to electronics, segmentation, experiment results, and intentionality.",
        "During the meeting, there was a discussion about the use of electronics, specifically microphones, and the best positioning for optimal volume and minimal interference. The topic of intentionality was also brought up, with the idea of using display to judge the correctness of breathing during speech. The results from experiments on speech recognition were also discussed, including the use of models for breathing in and out, as well as laughter. It was mentioned that there may be a possibility of using the display to detect breathing and laughter during speech. The transcribers also discussed their process and the conventions they use, including marking breaths and laughter in the transcriptions. The discussion then shifted to the segmentation of speech and the challenges in distinguishing overlaps and multiple speakers. Different approaches were suggested, including the use of pitch-related and harmonicity-related features, as well as the possibility of using a Markov model to distinguish between overlapping and non-overlapping speech. The idea of using Javier's speech segmenter was also mentioned, with the suggestion to feed the hand-segmented data into the system to see if it can accurately detect overlaps. Overall, the meeting focused on the challenges and potential solutions for accurately detecting and segmenting speech in the context of multiple speakers and overlaps.",
        "During the meeting, there was a discussion about electronics, the segment, the results from the experiments, and the topic of intentionality. The main points discussed were:\n\n1. The deadline for making the data available was set for July 15th, but there was some confusion about whether it was a hard deadline or just a reminder. It was suggested to remind people two weeks prior to the deadline.\n\n2. It was agreed that the default option for participants would be to approve the transcriptions, but they would have the option to censor or mark them as incorrect if needed. This was seen as a way to check the accuracy of the transcriptions.\n\n3. The German, Dutch, Swiss, and Spanish meetings were mentioned as being part of a different group, and it was noted that they would be ready for release the following week.\n\n4. The issue of the time frame for participants to respond was discussed. It was suggested to have a clear deadline for responses, such as a week or two weeks before the July 15th date, and to communicate this to participants. It was also mentioned that a follow-up email could be sent to remind participants to respond.\n\n5. The question of how to ensure that participants received the email and had the opportunity to respond was raised. It was suggested to have a contact email or phone number for participants and to ask them to confirm receipt of the email.\n\n6. The possibility of having participants sign a form or provide confirmation of their agreement was discussed, but it was noted that the current form did not include a specific time limit for response.\n\n7. The issue of how to handle participants who do not respond or who request changes after the deadline was raised. It was suggested to remove any requested changes from future releases but not delete them from already released data.\n\n8. The question of how to handle participants who cannot be reached or who do not respond was discussed. It was suggested to have administrative staff follow up with these participants to ensure their agreement or non-response.\n\n9. The need for legal advice on the process and the importance of having a paper or electronic trail of participants' agreement was emphasized. It was suggested to consult with a lawyer to ensure compliance with legal requirements.\n\n10. The technical aspects of the data release were also discussed, including the need to make copies of meetings with deletions and the potential use of encryption or other methods to protect the data.\n\n11. The issue of email response and the use of return receipts or confirmation buttons was raised. It was suggested to have participants respond to the email directly or use a confirmation button to acknowledge receipt and agreement.\n\n12. The question of how to handle larger batches of meetings and the frequency of data releases was discussed. It was suggested to release meetings as they become available and to consider the impact on participants' workload.\n\n13. The need for participants to review and verify the accuracy of transcriptions was mentioned, and it was noted that this process should follow the regular review process.\n\nOverall, the meeting focused on",
        "During the meeting, there was a discussion about electronics and the segment. The participants mentioned that the standard procedure for transcribing the meetings involves spending a lot of time on backchannels. They also discussed the possibility of improving the detection of backchannels in the future. The meeting attendees talked about sending transcripts and audio files to the University of Washington for recognition purposes. They mentioned the need for additional disk space and the possibility of ordering more headphones. The meeting also touched on the topic of the annual report and the upcoming conference. The participants discussed the results of experiments related to automatic transcription and intentionality. They mentioned that the current system has a latency of 230 milliseconds and needs to be reduced to 220 milliseconds. They also discussed the performance of the system and its comparison to human performance. The participants mentioned the use of a hierarchical structure for the silence probability and the need for better voice activity detection. They also discussed the training data for the tandem network and the possibility of using different noises. The meeting concluded with a discussion about the possibility of adding the pitch back into the LPC synthesis and its impact on the performance of the system.",
        "During the meeting, the discussion revolved around several topics related to electronics, the segment, the results from experiments, and the concept of intentionality. \n\nIn regards to electronics, the discussion focused on the use of synthesis in LPC synthesizers, particularly in relation to voiced and unvoiced sounds. The participants discussed the possibility of using noise for unvoiced sounds and periodic pulses for voiced sounds. They also mentioned the importance of detecting periodic components in order to use voiced sounds effectively. It was acknowledged that this topic may not be a priority, but it was suggested as a thought experiment to test the effectiveness of different approaches.\n\nThe segment of the meeting dedicated to the results from experiments mainly focused on speech recognition and the evaluation of different systems. One participant mentioned downloading software from Mississippi State and running scripts to test their LVCSR system on the Wall Street Journal data. The results showed that the Mississippi State system performed at around 8.2% word error rate, which was comparable to other systems. However, further analysis was needed to understand the testing conditions and the potential for improvement.\n\nThe topic of intentionality was briefly touched upon during the meeting. The participants discussed the use of different features and techniques to improve speech recognition. One participant mentioned the use of an auditory model of human hearing to generate speech recognition features. This approach involved two stages: the first stage utilized a filter bank with compressive nonlinearity to mimic the peripheral auditory system, while the second stage involved the use of Gabor functions to analyze the input signal in the time-frequency domain. The participant also mentioned the use of optimization procedures to select the optimal set of basis functions for the Gabor functions.\n\nOverall, the meeting covered a range of topics related to electronics, speech recognition, and the exploration of different techniques and features to improve accuracy and performance.",
        "The discussion in the meeting was focused on the topic of electronics, specifically on the segment and the results from experiments. The participants discussed the differences between a multi-band setting and an unconstrained setting in terms of looking across time and spectral extent. They also discussed the idea of using a graphical model to treat intermediate categories as hidden variables and how it can be learned through statistical training and the EM algorithm. The participants mentioned the need for further research to understand individual differences in overlaps and the types of overlaps in meetings. They also discussed the possibility of studying overlaps in two-person conversations and the factors that determine who gets the floor in a conversation. The participants acknowledged the need for more data to answer these questions and suggested recording meetings with smaller numbers of people to gather more statistics.",
        "During the meeting, the discussion revolved around various topics related to electronics, the segment, the results from experiments, and the concept of intentionality. One of the main points discussed was the comparison between two-person meetings and larger meetings, with the conclusion that two-person meetings are more similar to control conditions. The relationship between the number of people and the number of overlaps or type of overlaps was also explored.\n\nThe meeting also touched upon the use of close-talking microphones for detecting who is speaking, with the suggestion of using thresholding and filtering techniques. It was noted that the choice of parameters for these techniques greatly affects the accuracy of the segmentation. The idea of recording two-person meetings was also discussed as a way to analyze overlaps and explore the constraints that additional people may add to the competition for speaking turns.\n\nThe topic of intentionality was brought up in the context of analyzing speech data and detecting acoustic changes. It was suggested that considering energy levels and comparing them to other microphones could provide valuable information about speaker changes. The concept of audio pixelization was also introduced as a way to mask parts of the speech that participants might want to keep private.\n\nThe meeting ended with a brief discussion about the progress made in the last three months, including the recording of meetings, sorting out transcription formats, and sending data to IBM for transcription. The use of blindfolds during meetings was proposed as an interesting experiment, and the idea of using beeps for audio pixelization was discussed.\n\nOverall, the meeting covered a range of topics related to electronics, experiments, and the analysis of speech data. The participants shared their ideas and findings, providing valuable insights for future research and development."
    ],
    [
        "The main thesis of the discussion was the improvement of the quality of close-talking microphones and the use of microphone arrays for recording meetings. The professor and participants discussed the need for better quality close-talking microphones and the standardization of microphone types to capture clear and consistent audio signals. They also discussed the upcoming visit of NIST representatives and their interest in the transcription conventions and pre-segmentation methods used in the meetings. The professor mentioned a teleconference with Jonathan Fiscus, who expressed interest in using the ATLAS system for analyzing the transcriptions. The participants also discussed the progress of transcriptions by a team of transcribers, and the potential challenges of combining transcriptions from different channels. The professor and participants agreed that further research and collaboration with other institutions would be beneficial for improving the recording and analysis of meeting data. Future work may involve exploring the use of microphone arrays and the integration of video recordings into the meeting data.",
        "In the meeting, the main thesis of the discussion was about improving the accuracy of transcriptions in meetings. The professor and the other participants discussed various issues related to this, such as the difficulty of transcribing conversations with reduced phonetic speech, the challenge of following one channel of a conversation, and the need for fine time markings for forced alignment. The professor also mentioned that their transcribers use mixed signals for transcriptions and that they have not tried both ways to determine which method is better.\n\nRegarding possible hypotheses, the professor mentioned the possibility of using pre-segmentation and forced alignment to improve the accuracy of transcriptions. They also discussed the potential benefits of having transcribers do dialogue act tagging and disfluency tagging, as well as the possibility of using transcribers for other tasks, such as encoding overlaps and marking articulatory features.\n\nIn the concluding comments, the professor expressed the need for more meeting data and mentioned the possibility of recording meetings from other groups, such as Jerry Feldman's group and student groups at the business school. They also discussed the idea of having meetings with more heated discussions or emotional content for a more varied dataset. The professor also mentioned the possibility of improving waveforms through pre-processing and increasing the flexibility of alignment.\n\nIn terms of future work, the professor mentioned the need for further exploration of signal processing techniques for detecting energies and improving signal-to-noise ratio. They also discussed the potential for using symbols or graphic symbols to mark different situations during transcription. Overall, the meeting focused on ways to improve transcription accuracy and explore new research directions in the field.",
        "The main thesis of the discussion was to analyze the amount and types of overlaps in a meeting. The professor's opinions on the 12-second mean were not mentioned in the meeting. The possible hypothesis mentioned was whether overlaps are distributed evenly throughout the meeting or if there are bursts of overlaps. The concluding comments were that overlaps can be categorized into different types and that there may be individual differences in overlap behavior. The future work suggested was to study the duration and distribution of overlaps and to determine if there are differences in overlap behavior based on the number of participants in the meeting.",
        "The main thesis of the discussion was the need for more data for research purposes, specifically in the context of analyzing meeting recordings. The professor's opinions on various aspects were as follows:\n\n- The professor agreed with the idea of labeling parts of the meeting that should not be included in the record, using either beeps or silence.\n- The professor suggested a procedural change to record the digit readings at the end of the meeting to accommodate participants who need to leave early.\n- The professor emphasized the importance of having a variety of meeting types and participants to allow for different research analyses, such as summarization and acoustic-oriented research.\n- There was a discussion about the challenges of advertising for participants and the need to ensure that the participants have sufficient proficiency in English for accurate analysis.\n\nIn terms of the 12-second mean, there was no specific mention of it in the given meeting. The concluding comments were focused on the need for more data and the potential future work, such as exploring the use of different meeting types and participants for research purposes.",
        "The main thesis of the discussion was the idea of using a language model to analyze and classify overlapping speech in meeting recordings. The professor and the participants discussed the issue of overlapping speech and the need for a control set to evaluate the performance of the classification tool. The professor suggested using a cluster algorithm or a neural network to analyze the features and classify the different speech segments. The participants also discussed the need for a backup disk to store the Aurora and other data and the current availability of disk space for recording meetings. They also talked about the possibility of setting up a portable recording system in another location on campus and the importance of having a diverse group of participants in the meetings. The professor and the participants agreed to have the meetings held in English and discussed the idea of providing a CD of the recordings to the participants. The professor also mentioned plans to get more disk space and the progress of Jose's work on the project. Overall, the discussion focused on the challenges and future plans for the Meeting Recording project.",
        "The main thesis of the discussion was about the use of different features and classifiers to detect overlaps in speech. The professor expressed the opinion that using a decision tree would be effective for detecting overlaps in speech with distinct variables like pitch. However, for more complex variables like cepstral coefficients, a more advanced classifier or feature selection approach would be necessary. The professor suggested starting with a few features and visualizing them in scatter plots to gain insight into their separation. They also recommended considering the temporal properties of the speech and using features that capture a larger chunk of time. The professor concluded by suggesting that a good starting point would be to use a mixed speech dataset for the study and then compare the results with the PDA speech files. \n\nIn terms of future work, the professor mentioned the possibility of using microphone arrays to improve the detection of overlaps. They also discussed the need to anonymize the data and the challenge of balancing the need for speaker identification in discourse analysis with the need for privacy. The professor suggested that it would be helpful for everyone to send agenda items before the meeting to better organize the discussion.",
        "The main thesis of the discussion was about the challenges of anonymizing data and the impact it has on discourse analysis. The professor's opinions were that it would be difficult to implement a policy of not mentioning names in recordings because it would make the data less useful for discourse analysis. They also discussed the possibility of bleeping out names in the audio but concluded that it would still affect the analysis. They also mentioned the importance of having a consistent licensing policy and the need to consider the preferences of the funders of the work. \n\nIn terms of future work, they discussed the need to tighten up the time boundaries in the transcriptions and the possibility of using an interface that allows the transcribers to switch between different channels more easily. They also mentioned the need to run the SRI recognizer on the digit recordings and the challenges they faced with forced alignments.\n\nOverall, the discussion focused on the challenges of anonymizing data, the impact on discourse analysis, and the need for further work on time boundaries and alignments.",
        "The main thesis of the discussion was about the challenges of aligning speech recordings and the need for longer time windows to accurately align the speech. The professor's opinions on the 12-second mean were not explicitly mentioned in the meeting. Possible hypotheses were discussed regarding the issues with timing in the recordings and the need for accurate speech detection on individual channels. The concluding comments were about the difficulty of quickly adapting distances in dynamic speech and the limitations of the current recordings for a Eurospeech paper. Future work discussed included the potential use of non-lapel recordings for alignment, aligning energy segmentations with existing data, and exploring different approaches to summarization. The professor also mentioned discussions with NIST regarding their plans for recording systems and the use of different learning machines for word sense disambiguation. The meeting also touched on the need for more data and the importance of machine learning in different contexts.",
        "The main thesis of the discussion was focused on the performance of different systems in speech recognition, particularly in terms of accuracy and robustness to noise. The professor expressed the need to consider both the cost and the amount of training required for different systems. There was a debate about the effectiveness of adding more data to improve performance, with the professor suggesting that the quality of the data and the intelligence of the system are more important factors.\n\nThe professor's opinions on the 12 second mean were not explicitly mentioned in the meeting. However, there was a discussion about the effectiveness of different features and neural network architectures in improving accuracy. The professor emphasized the importance of using delta features and on-line normalization, which led to significant improvements in recognition accuracy.\n\nThe possible hypothesis discussed in the meeting was that the combination of PLP features and MSG features could improve performance. However, the results showed that the MSG features did not provide a significant improvement in accuracy, especially for the Italian language.\n\nIn the concluding comments, the participants noted that the performance of the systems varied depending on the training data and the specific language being recognized. They also discussed the need for further experiments and analysis to better understand the impact of different features and architectures on speech recognition accuracy.\n\nIn terms of future work, the participants mentioned the need to redo experiments with PLP features and delta features, as well as further investigate the combination of different features and neural network outputs. They also discussed the possibility of using a large database containing sentences from multiple languages for training and testing. Additionally, there was a mention of a server farm of IBM machines that could be used for processing-intensive tasks.",
        "The main thesis of the discussion was to evaluate the performance of different configurations of MLP (Multi-Layer Perceptron) networks in speech recognition tasks. The professor's opinions were discussed regarding the 12-second mean, possible hypothesis, concluding comments, and future work.\n\nDuring the meeting, the discussion focused on the different configurations of MLP networks, the use of MLP outputs for the PLP net, and the use of straight features with delta-delta. The professor and the other participants analyzed the accuracy of these configurations and compared them to the MLP alone.\n\nThe meeting also discussed the potential hypothesis that training on data similar to the testing data can improve performance, while training on different data can lead to problems. The professor emphasized the importance of considering the similarity between training and testing data and the potential benefits and drawbacks of using MLP networks.\n\nIn terms of concluding comments, the participants discussed the need for further experiments to evaluate the performance of different configurations across various test sets and noise conditions. They also mentioned the importance of considering the language dependency and the noise dependency in future work.\n\nRegarding future work, the participants mentioned their plans to work on integrating the MLP networks with the existing OGI system. They also discussed the possibility of using different training targets, such as articulatory or soft targets, and exploring the use of regression instead of classification in MLP networks.\n\nAdditionally, they mentioned the need to address CPU and memory issues and to improve the results from a single feature set. The participants also discussed the potential of using LogRASTA filtered features and multi-band approaches in future experiments.\n\nOverall, the meeting provided insights into the main thesis of the discussion, the professor's opinions, possible hypotheses, concluding comments, and future work related to evaluating MLP network configurations in speech recognition tasks."
    ],
    [
        "During the meeting, the discussion focused on the updates and requirements for the transcripts. The postdoc mentioned the need for an update on the transcripts and filtering for ASI refs. The discussion also touched on the progress of the TI-digits dataset and the need to train a recognizer. The postdoc then presented a new version of presegmentation that includes channel-specific speech-nonspeech detection. They mentioned using normalized features for energy and loudness to distinguish foreground and background speech. However, they requested manually transcribed references for evaluation. The postdoc also mentioned the possibility of retraining the segmenter based on the provided references. The meeting participants discussed the potential challenges and benefits of incorporating articulatory features into the transcription process. The postdoc suggested using a score-like notation to represent features such as voicing and nasality. The participants also discussed the need for a variety of meeting data for evaluation and training purposes. The postdoc mentioned having manually transcribed references for forced alignment and requested a few minutes of different meetings for training. The participants agreed to provide the necessary data and discussed potential issues with lapel mics and false overlaps. The postdoc also mentioned the possibility of using cross-correlations to address these issues. Overall, the meeting focused on the requirements and challenges related to the transcripts and discussed potential solutions and future work.",
        "During the meeting, the discussion mainly focused on the transcripts. The participants discussed the need for variety in speakers and the importance of having accurate and precise transcriptions. They discussed the process of transcribing the meetings and the progress made so far. The postdoc mentioned that they could include samples from twelve meetings and have them transcribed in an hour. The professor agreed and mentioned that the transcriptions should be adjusted for precise timebands.\n\nThe meeting also touched upon the use of XML tools for data extraction and reformatting. The assistant mentioned that they have been working on XML tools and converting the meeting data to XML format. They discussed the need for better transcription formats in XML and the issue of missing information in the Key files.\n\nThere was also a discussion about the demos and presentations. They mentioned the use of the THISL GUI tool for information retrieval and the possibility of merging it with the Transcriber interface. They also discussed the idea of showcasing the prosody work and the features developed by Don.\n\nIn terms of disk backup, it was suggested to use the NW archive to make copies of the data for backup purposes. The assistant mentioned that they had spoken with Dave Johnson and he recommended not relying solely on backups and to have multiple modalities of backup.\n\nLastly, the CrossPads were briefly mentioned, with the participants discussing their experiences with using them for note-taking. Some participants found them useful, while others found the pen noise to be a disadvantage.\n\nOverall, the meeting focused on the progress and requirements for the transcripts, as well as discussions on demos, XML tools, disk backup, and the use of CrossPads.",
        "In the meeting, the discussion regarding the transcripts focused on the idea of having a scribe to take notes during the meeting. However, this idea was not implemented consistently and eventually died out. The question arose as to whether it would be more efficient to have someone listen to the recording afterwards and transcribe the important points. The group also discussed the use of transcripts for summarizing and highlighting key points. It was suggested that individuals could mark certain points in the transcript for later reference.\n\nThe meeting also touched on the synchronization of time between the CrossPads and the recording device. It was mentioned that using a PDA with a wireless card could help with synchronization and make the process easier.\n\nRegarding the discussion on transcripts, it was suggested to have someone listen to the recording and take notes on important points. The group also discussed the possibility of using a PDA with a wireless card for easier synchronization. The idea of having individuals mark important points in the transcript was also discussed.\n\nIn terms of the ASR results, it was mentioned that the lapel microphone had poor performance due to picking up overlapping speech. It was suggested that better segmentation or echo cancellation could improve recognition on the lapel microphone. The discussion also touched on the idea of having digits embedded in real words for comparison purposes.\n\nOverall, the meeting focused on the use of transcripts, synchronization of time, ASR results, and the potential improvement of recognition on lapel microphones.",
        "In the meeting, there was a discussion about the transcripts and the requirements for them. The team talked about the need to run tests on the transcripts to see how well they can perform in real papers. They discussed the idea of determining the speaker boundaries and the foreground and background speakers in the transcripts. They also mentioned the use of cross-correlation and adaptive echo cancellation techniques to remove overlaps in the transcripts. The team agreed to move the boundaries in and to downsample the waveforms. They also discussed the need for more disk space and storage formats for the transcripts. The team also talked about the need for standardizing and streamlining the transcription process, including spell-checking and checking for identifiable speakers. They also discussed the use of glossing for certain spoken forms and the need to distinguish between different variations of \"eh\" and \"uh\" in the transcripts. The team also discussed the use of acronyms and comments in the transcripts and the need for clarification on certain words and expressions. Overall, the team agreed to continue working on improving the quality and accuracy of the transcripts.",
        "During the meeting, the discussion revolved around the transcripts, their requirements, and agreements regarding them. There was a discussion about the need to spell out certain words consistently, such as Tcl. It was agreed that the new models being created should also go through the transcripts and make any necessary changes synchronously. It was mentioned that changes to the dictionary should be consistent with the transcripts, particularly when it comes to spelling people's names. If a spelling correction is made to a name, the mispelled version should still be included in the dictionary for pronunciation purposes. The use of acronyms was also discussed, with the suggestion to have a separate pronunciation for acronyms that are sometimes said as letters and sometimes pronounced as words. The meeting participants also discussed the inclusion of vocal gestures and vocalizations in the transcripts, such as \"beep\" and mimicking sounds. They talked about the use of the \"NUMS\" tag for numbers in the transcripts, as well as the inclusion of numbers in quotation marks. The meeting participants also discussed the need for more data and the possibility of recording different types of meetings for research purposes. They debated the idea of having regular meetings with consistent participants versus a variety of meetings with different participants. The discussion also touched on the possibility of recording meetings in other locations, such as the linguistics department, and the need for portable equipment. The participants also discussed the use of different microphones for recording and the importance of having a substantial amount of data recorded with distant and close microphones for certain purposes. Overall, the meeting focused on the importance of accurate and consistent transcripts, as well as the need for a diverse and comprehensive dataset for research purposes.",
        "During the meeting, there was a discussion about using microphones to record the transcripts. The group agreed that a tape recorder or a DAT machine could be used to capture the audio. However, it was also mentioned that the data collected should be sufficient for different types of projects and perspectives. There was a suggestion to have people record their own data to ensure they get the specific information they need. It was also discussed that the current disk space is limited, but efforts are being made to clear up space by archiving and deleting unnecessary files. It was mentioned that a new disk rack with additional storage is being planned. \n\nIn regards to the transcripts, there was a discussion about how to classify and analyze the overlapping zones in the audio recordings. One participant mentioned marking the overlapping zones by hand and then using clustering algorithms or neural networks to classify them. The idea was to have a control set of pure silence and then classify the different types of speech and overlapping speech. It was suggested to start with a few features and visualize how they are separated before building more complex classifiers. The importance of temporal properties and transitions was also mentioned. The participant mentioned using a modified pitch tracker for analysis. The goal is to have models that can detect changes and classify the different zones accurately. The participant also mentioned the potential use of neural networks for classification.\n\nOverall, the discussion revolved around the need to accurately classify and analyze the overlapping zones in the audio recordings in order to extract meaningful information for transcription and analysis. Different approaches were suggested, including using clustering algorithms, neural networks, and visualizing the separation of features. The importance of considering temporal properties and transitions was emphasized.",
        "During the meeting, there was a discussion about the transcripts and the need for anonymization. It was mentioned that the LPC residual energy can be used to determine how well the low-order LPC model fits the speech. The idea of using a mixed speech file was brought up, as it provides clearer spectral distortion compared to PDA speech files. It was suggested that it would be interesting to try different features with both close-mixed and PDA speech files to see how they perform. The issue of anonymization was also discussed, with concerns about how to handle speaker identification in the transcript. It was suggested that using speaker numbers instead of names could be confusing for discourse analysis. The idea of bleeping out names in the audio was also mentioned, but it was noted that this could affect the usefulness of the data for discourse analysis. The need for a consistent licensing policy and the potential impact on the usefulness of the data for discourse analysis were also considered. It was agreed that further discussion and decision-making on anonymization would be needed.",
        "During the meeting, the discussion revolved around several topics related to the transcripts. Firstly, there was a discussion about the use of close talking microphones to capture high-quality audio. It was mentioned that having uniform microphones would make it easier for researchers to analyze discourse and prosody. There was also a suggestion to use microphone arrays, but it was noted that it would require a separate setup and more disk space. The idea of recording video during meetings was also brought up, but there were concerns about human subjects' consent and the additional infrastructure required.\n\nRegarding the transcripts, it was mentioned that eight transcribers were assigned different data sets, and two of them had already finished their work. The transcribers reported that it took approximately 12 minutes to transcribe 1 minute of meeting time. The use of pre-segmentation and the modified multitrans system were mentioned as helpful tools in the transcription process. The transcriptions still needed to be edited for word level accuracy and speaker changes.\n\nA teleconference with Jonathan Fiscus from NIST was also discussed. He expressed interest in using the ATLAS system, which is a software developed by Bird and Liberman for annotated graphs. It was agreed that the transcribed meeting data would be provided to Fiscus for experimentation in the ATLAS system. He also expressed interest in the reliability and consistency of the encoding in the transcripts.\n\nOverall, the meeting provided insights into the requirements for capturing high-quality audio, the progress of the transcriptions, and the potential use of the ATLAS system for further analysis of the meeting data.",
        "In the meeting, the discussion revolved around the requirements and agreement regarding the transcripts. The meeting participants discussed the concept of an annotated transcription graph representation and how it could be used in combination with TEI (Text Encoding Initiative) for manipulating transcription graphs. They also mentioned the project involving NIST and other organizations, including LDC, that are subcontracting the transcription work for IBM's speech recognition products. The meeting participants discussed the limitations of the transcripts provided by IBM and the need to clarify the level of time information included in them. They also discussed the possibility of using court reporters or similar professionals for transcription and mentioned that the transcribers hired by IBM are more secretarial in nature. The meeting participants talked about the challenges of transcribing overlapping speech and the potential difficulties in aligning the transcripts with the audio. They also discussed the historical reasons for IBM's involvement in the transcription process and the potential for utilizing the transcribers for other tasks, such as fine-grained encoding of overlaps. The meeting participants mentioned the possibility of recording more meetings, including those from different departments or groups outside of ICSI, to gather a diverse range of data. They also discussed the importance of having meetings with English-speaking participants and the challenges of dealing with different accents and dialects. The meeting participants talked about the potential for improving the accuracy of the transcripts through pre-processing techniques and the need to collaborate with experts in wave form processing. They also mentioned the possibility of involving artists or groups involved in artistic endeavors to gather more varied and interesting data. The meeting participants expressed the desire to collect more meetings with heated discussions or emotional content to capture a wider range of prosodic contours. They also discussed the possibility of utilizing methods for separating speakers or improving the signal-to-noise ratio in the recordings. The meeting participants mentioned the need for continued communication and collaboration with experts in speech processing and recognition techniques.",
        "During the meeting, there was a discussion about the requirements and agreement regarding the transcripts. The main topic of discussion was the need for a set of graphic symbols to transcribe different situations during the transcription process. There was also a discussion about the possibility of including these symbols in the Transcriber program. \n\nOne of the main requirements mentioned was the need for more precise timing in the transcription process. This would allow for better alignment and analysis of the speech segments. The idea was to cut out parts of the speech that were not relevant and combine segments from the same speaker to run them through the recognizer. This would help in computing prosodic features and improving the overall accuracy of the transcription.\n\nThere was also a discussion about the flexibility of the alignment and the possibility of increasing it. One suggestion was to use a technique called forced alignment, where the speech is aligned based on acoustic features. However, there were challenges in implementing this technique, such as dealing with overlaps and accurately aligning the speech segments.\n\nIn terms of the agreement, it was decided that further exploration and experimentation would be needed to find the best approach for transcription and alignment. It was also agreed that more research and testing would be required to determine the effectiveness of different techniques and tools.\n\nOverall, the meeting focused on the requirements and challenges of transcription and alignment, and the agreement was to continue exploring different approaches to improve the accuracy and efficiency of the process.",
        "During the meeting, the participants discussed the importance of transcripts and the need for more data and better alignment. They talked about the benefits of having hand-transcribed or hand-checked alignments and how it would help with reporting and understanding the real words in the transcript. They also discussed the need to know the boundaries of overlaps and whether they are true overlaps or just correlated segments. The participants mentioned the possibility of using Thilo's output for aligning different channels in meetings and the challenges of determining the boundaries of words. They also discussed the idea of using scripts to merge different types of speech segments and the challenges associated with it. The participants talked about the potential of forced alignment and the need for transcribers to correct and tighten the boundaries of the transcript. They also mentioned the possibility of using more data for training and the different approaches used by different groups. The participants discussed the evaluation of summarization techniques and the different ways to evaluate the quality of summaries. They also talked about the importance of machine learning and the impact of data on improving performance. The participants mentioned the challenges of cost and the different properties of learning machines. They also discussed the differences between tasks and the need for different approaches and considerations based on the task at hand. The participants mentioned the importance of more data and the limitations of using a limited amount of data for training. They also discussed the differences between simpler algorithms and more complex ones and the impact of data on performance. The participants mentioned the need to consider different factors such as memory usage, computation, and recall time when choosing learning machines. They also discussed the importance of cost and the implications of using more data. Finally, the participants talked about the presentation on scaling issues in word sense disambiguation and the different perspectives on the role of machine learning and data. They mentioned the importance of understanding the properties of different learning machines and the impact of data on performance. Overall, the meeting covered a range of topics related to transcripts, alignment, summarization, machine learning, and data."
    ],
    [
        "In the meeting, PhD F and PhD B discussed their opinions on the topic of generating queries automatically. PhD B mentioned that they had been working on trying to improve the latency and bugs in the system by designing new filters using recursive filters. They also discussed the possibility of implementing a routine for recursive filtering. PhD B mentioned that they had not discussed this with Sunil yet but planned to send him an email to inform him about their progress. \n\nDuring the meeting, Professor C expressed his frustration at not being informed about the conference talk and the decisions made regarding the topic of generating queries automatically. He mentioned that even if the rules were different, they were still interested in continuing their work. \n\nPhD F and PhD B discussed the possibility of using linear phase filters and downsampling to improve the system. They also mentioned the use of spectral subtraction and on-line normalization to further enhance the system. PhD B explained that the filters they designed had a shorter delay compared to the existing filters. They also discussed the challenges of estimating the noise spectrum and the use of thresholds to update the estimate. \n\nIn response to the question about the opinions of PhD F and PhD B on generating queries automatically, PhD B expressed that they were working on improving the system by implementing new filters and routines for recursive filtering. They also discussed the use of spectral subtraction and on-line normalization. Overall, their opinions seemed positive about the potential improvements that could be made to the system.",
        "In the meeting, PhD F and PhD B discussed the topic of generating queries automatically. PhD F mentioned that they were using smooth envelopes for speech recognition, but it was not performing well in determining whether something is sonorant or not. PhD B asked about other low level detectors for generating queries, such as frication, abrupt closure, R-coloring, nasality, and voicing. PhD A mentioned an experiment conducted by PhD F and PhD B, where they tried to detect sonorants perfectly and showed how it would improve speech recognition. However, Professor C did not remember that experiment. PhD A and PhD B also discussed the possibility of using other phonetic features for generating queries, such as stress and tongue position. Professor C suggested that some features, like stress, may not help distinguish words from one another, but could be useful for higher-level understanding applications. The discussion then shifted to the topic of generating queries for speech recognition in reverberant environments. PhD D presented the results of their experiments using different features and training data. They found that training on task-specific data resulted in better performance, but when training on multiple languages or broad data, the performance decreased. They also observed that the performance was worse when testing on a different language than the one used for training. PhD D mentioned that the noise condition in the training data was the same as in the test data, but there was still a decrease in performance. The meeting ended with a discussion about the need for further testing and analysis of the results.",
        "In the meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly mentioned. However, they did discuss various aspects of the topic, such as the initialization of the recursion, the use of different values for alpha, and the potential impact of using different features and outputs in the neural networks. They also discussed the challenges of using context-dependent phonemes and the trade-offs between having more or fewer classes in the neural networks. Additionally, they talked about the need to make strong decisions and draw conclusions from their experiments, as well as the resources and computational limits they have. They also mentioned the possibility of running the training and testing processes on different machines and the acceptance of their Eurospeech paper.",
        "In the meeting, PhD F and PhD B discussed their opinions on the topic of generating queries automatically. PhD F mentioned an experiment where they tried to vary a parameter based on frequency, but PhD C could not recall the specifics. PhD C also discussed their investigation into the estimation of mean values for speech and the adaptation of time constants for different utterances. PhD F and PhD C also discussed the normalization of different MFCCs and the potential benefits of combining them. Professor B suggested looking at the types of errors being made and considering how different methods may be impacting them. PhD C also mentioned their experiments with adding noise to the signal and how it affected the cepstral coefficients and speech recognition results. PhD C also mentioned the potential impact of different LDA filters on speech recognition performance. PhD C and PhD F discussed the idea of using different noise compensation techniques and the need for standardization. PhD D discussed their experiments with phase normalization and mentioned some potential issues with the implementation. They also mentioned their plans to experiment with using different noise estimation methods. Carmen discussed their experiments with VTS (Vectorial Taylor Series) for noise removal and the impact of using VAD (Voice Activity Detection) and LDA (Linear Discriminant Analysis) on the results. PhD E mentioned that they were working on implementing Wiener filtering for the Aurora task and were experiencing some issues with the results. They also mentioned their plans to explore using different noise estimation methods and codebooks. Finally, PhD B discussed their work with VTS and their experiments with the Spanish database. They mentioned that the results were not as good as expected and that they were planning to explore different approaches to improve the performance.",
        "During the meeting, PhD F and PhD B discussed the topic of generating queries automatically. PhD E explained the idea of using a linear relation to develop the query in a vector space Taylor series. PhD C also mentioned the use of a codebook to model clean speech. PhD E further explained the process of obtaining the PDF for noisy speech using minimum mean-square estimation. PhD B questioned the amount of noisy speech needed to generate good statistics for the mapping, and PhD E mentioned using TIMIT as the codebook for clean speech. PhD E also explained the process of estimating the noise and how it affects the mean and variance of the noisy speech. PhD F and PhD B discussed the complexity of the problem when using higher-order Taylor series expansion. PhD E mentioned the use of a neural network for estimating the clean speech given the noisy speech. PhD F and PhD B discussed the possibility of using more parameters to characterize the noise and the potential complications with nonlinearity. They also discussed the potential benefits of having a better model for the noise and the use of better boundaries for estimating the noise statistics. PhD E mentioned using SSH to remotely access the CVS for code sharing. PhD A mentioned the update of the code and the new features added, such as noise suppression and speech re-synthesis after suppression. PhD E asked about remotely accessing the CVS using SSH and the possibility of setting up an anonymous CVS for the Meeting Recorder project. PhD A confirmed that she was able to access the CVS remotely using SSH. PhD E also asked about the opinions of PhD F and PhD B on the topic of generating queries automatically. PhD B mentioned the importance of having good boundaries for estimating the noise and the potential benefits of using more parameters to characterize the noise. PhD F discussed the challenges of working with VTS and the need for further exploration. PhD E and PhD D discussed the current ranking of the system in the evaluation and the plans for adding a second stream to the system and improving the VAD. PhD A mentioned the use of TRAPS for the VAD and the possibility of using mel spectrum as the second stream. They also discussed the upcoming Wall Street Journal evaluation and the need to consider the parameters for the evaluation. Overall, the meeting focused on freezing certain aspects of the system and working on specific improvements to enhance performance in the evaluation.",
        "In the meeting, PhD F and PhD B discussed the topic of generating queries automatically. PhD F expressed concerns about the upcoming evaluation and the need for clear parameters and understanding behind the decision-making process. PhD B mentioned that the evaluation would likely assign a low weight to automatic query generation, as it is seen as a double check rather than the main emphasis. They also discussed the availability of the system for download and the training and testing data for the evaluation.\n\nIn terms of generating queries automatically, PhD F and PhD B had different opinions. PhD F mentioned the importance of having categories that are significant to humans, like phonemes, but also expressed a desire for a bottom-up approach. PhD B agreed with the importance of categories, but also mentioned the need to consider discrimination and the potential limitations of using phonemes as categories.\n\nPhD F also mentioned the difficulty of reconciling the desire for bottom-up categories with the need for discrimination, but PhD B suggested considering words as categories instead of phonemes. They discussed the potential impact of using words as categories and the challenges of dealing with spontaneous speech.\n\nDuring the meeting, PhD A mentioned the visit of PhD Hans-Guenter, who is part of the spectral subtraction group, and the possibility of longer collaboration. PhD A also mentioned the need for updates from the team members. PhD D discussed the results of tests on mean log magnitude spectral subtraction and the impact of different time windows on performance. They found that using shorter time windows for mean subtraction in testing did not significantly affect performance compared to using longer time windows for training.\n\nPhD E mentioned their experiments on clustering data and the challenges of finding intermediate categories. They discussed the use of TRAPs and hierarchical clustering to find patterns and categories in phonemes. PhD E also mentioned the possibility of generalizing the approach to arbitrary windows in time and clustering based on similarity.\n\nOverall, the opinions of PhD F and PhD B on generating queries automatically were mixed, with PhD F emphasizing the importance of human significant categories and a bottom-up approach, while PhD B mentioned the need for discrimination and the potential benefits of using words as categories. The team also discussed the challenges of the upcoming evaluation and the availability of the system for download.",
        "In the given meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly stated. The meeting primarily focused on discussions related to Wiener filtering and spectral subtraction techniques for noise compensation in speech recognition systems. PhD B mentioned that they have been working on Wiener filtering and found that a single-stage Wiener filter did not provide significant improvement over the baseline system. They also mentioned trying a two-stage Wiener filter with smoothing in the frequency domain and found that it improved the performance by 56.46% on the SpeechDat-Car dataset. PhD F mentioned working on spectral subtraction and applying nonlinear smoothing techniques to reduce musical noise artifacts. They found that this approach yielded good results on Italian and Finnish languages. The discussion also touched upon the use of a proper voice activity detector (VAD) for noise estimation and the potential impact of the neural network component in improving speech recognition performance. Overall, the opinions of PhD F and PhD B on the topic of generating queries automatically were not directly addressed in the meeting.",
        "In the meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly discussed. However, based on the discussion of the experiments and results, it can be inferred that both PhD F and PhD B were focused on improving the performance of the system through various techniques such as spectral subtraction, noise estimation, voice activity detection, and feature combination.\n\nPhD F mentioned the use of spectral subtraction and its effectiveness in mapping from noisy signals to clean signals. They also discussed the importance of noise estimation and its impact on the system's performance. PhD F also mentioned the use of voice activity detection and the potential benefits it could provide.\n\nPhD B discussed the optimization of different parameters, such as the time constant of the smoothing in spectral subtraction. They also mentioned the latency introduced by the smoothing recursion and the potential trade-offs in using different noise estimation techniques. PhD B also mentioned the use of features and neural network outputs together in order to improve the system's accuracy.\n\nOverall, both PhD F and PhD B were focused on improving the system's performance by exploring different techniques and combinations of features and neural networks. They were actively discussing and experimenting with different approaches to achieve better results.",
        "In the meeting, PhD F and PhD B discussed their opinions on the topic of generating queries automatically. PhD F mentioned that using only the silence output from the neural network resulted in less information. PhD B agreed with this and also mentioned that using a certain configuration gave better accuracy. They also discussed the suggestion made by Hari to scale the variances associated with the streams in order to effectively scale the streams. PhD A and Professor D had a discussion about the diagonal covariance matrices used in the HTK models and how changing the variances can affect the range of things. They also discussed the potential language and noise dependency in the training sets and the need to find better training targets. PhD A suggested using articulatory targets, soft targets, or regression instead of classification for training the neural networks. They also talked about the need to address CPU and memory issues. Professor D mentioned the importance of double-checking the results with OGI and making sure they align with the results from HTK. They also discussed the possibility of combining multiple features and MLPs, but PhD A suggested focusing more on training targets and training data. PhD B mentioned their work on a multi-band belief-net structure and the potential benefits of modeling asynchrony. The meeting concluded with a discussion about future work, including connecting with the OGI system, improving results from a single feature, and addressing CPU and memory issues."
    ],
    [
        "During the meeting, the discussion on latency in the system was brought up. The professor had an issue with the latency because it was causing coordination problems between the different groups working on the project. The duration of the latency was mentioned to be around 240 milliseconds, but there were plans to reduce it by using new filters and downsampling techniques. The professor suggested better communication between the groups to avoid further issues. Additionally, the discussion touched on the use of different features and targets for the system, as well as the need for simpler models. The meeting also mentioned ongoing work on echo cancellation and investigating acoustic features. Overall, the plan for the next week was to continue working on improving the system and addressing the latency issue.",
        "In the meeting, the discussion was focused on latency in the system and why the professor had an issue with it. The professor mentioned that they had not explicitly addressed additive noise in their system and instead focused on training the system to be more discriminant. They discussed the use of RASTA-like filtering to handle convolutional noise but did not address additive noise. The professor expressed the opinion that reducing latency to 40 or 50 milliseconds would require throwing out most of their current methods, which they did not believe was necessary. They also discussed the duration of latency in other systems, such as surgical microscopes, where it was around 250 milliseconds. The professor and the other participants agreed that a quarter-second delay for processing was not a significant issue when speaking to a recognizer on a remote server. \n\nIn another part of the meeting, the discussion shifted to the topic of detecting phonetic features in a multi-band system. The participants talked about a system that used sub-band features and logistic regression to detect sonorance in each sub-band. They discussed the use of AND and OR gates to combine the results of the detectors at different levels. The professor expressed interest in this approach because it used narrow-band information for phonetic features and because it trained the system using a product of errors rule. The professor also mentioned the possibility of training detectors for other phonetic features in addition to sonorance. \n\nTowards the end of the meeting, the participants talked about methods for dealing with reverberation in far microphone speech recognition. They discussed approaches such as using MSG and PLP, as well as speech enhancement or de-reverberation methods. One approach involved using a longer time window for de-convolution filtering, while another approach focused on reconstructing the excitation signal to reduce reverberation. They also mentioned the use of echo cancellation and the potential for using multiple microphones to improve directionality and reduce the effects of obstruction. Overall, the meeting covered a range of topics related to latency, phonetic feature detection, and reverberation in speech recognition systems.",
        "During the meeting, there was a discussion on latency in the system and the professor's issue with it. The professor mentioned that the latency in the system was a concern because it was taking too long for certain processes to occur. The duration of the latency was not explicitly mentioned in the meeting. However, based on the discussion, it can be inferred that the latency was around two hundred and seventy milliseconds. The meeting also touched on the topic of adding features to the system and the potential impact on performance. It was mentioned that adding features could potentially worsen the results, especially in highly mismatched conditions. The professor suggested exploring different training sets and improving the training of the feature set. The assistant also brought up the idea of using a KLT to de-correlate the features and potentially improve performance.",
        "During the meeting, several topics were discussed. One of the main topics was the need for better quality close-talking microphones for all speakers. The purpose of this is to capture better audio signals and improve recognition accuracy. It was suggested that head-mounted microphones could be used, and even though there might be limitations in terms of the number of radio channels available, the focus should be on having the microphone close to the speaker's mouth. \n\nAnother topic discussed was the upcoming NIST meeting, where John Fiscus and George Doddington would be present. The agenda items for this meeting included pre-segmentation and developments in multitrans. \n\nThere was also a discussion about post-processing the waveforms to improve recognition. It was mentioned that any knowledge or techniques to enhance the speech signal would be helpful. \n\nThe issue of speech vs. nonspeech detection was brought up, and it was mentioned that work was still ongoing to improve this area. \n\nFinally, the need for standardizing the microphone setup and having a uniform set of microphones for all speakers was emphasized. It was suggested that more close-talking microphones should be acquired to replace the existing ones and ensure uniformity in audio capture. \n\nOverall, the meeting covered various topics related to improving audio quality, recognition accuracy, and future research plans.",
        "During the meeting, the discussion on latency in the system was briefly touched upon. The professor had an issue with the latency, particularly in regards to the transcribers' ability to accurately capture the dialogue due to equipment and microphone issues. The duration of the latency was not explicitly mentioned in the meeting. Additionally, the meeting also discussed the transcription process and the progress made by the transcribers. It was mentioned that each transcriber was given their own data set, with meetings ranging from one to two hours in length. The transcribers reported that it took them about 60 minutes to transcribe every 5 minutes of real time. The meeting also touched upon the collaboration with NIST and their interest in using the data for the ATLAS system. The professor also mentioned the possibility of using microphone arrays in future recordings. The meeting concluded with a discussion on the SRI recognizer and the need for time markings in the transcription process. It was mentioned that the transcriptions are currently being chopped into smaller segments for the recognizer, but the lack of time marks presents a challenge in accurately aligning the transcriptions with the audio.",
        "The discussion in the meeting focused on the topic of latency in the system. The professor had an issue with latency because it can cause delays in processing and affect the overall performance of the system. The duration of the latency was not specifically mentioned in the meeting. \n\nDuring the meeting, there were discussions about forced alignment and the challenges it presents. The team mentioned the need for a reference of which words belong to which segment, as well as the proposal for IBM to do an initial forced alignment. However, there were uncertainties about the process and the availability of data. \n\nThe team also discussed the possibility of collecting more meeting data from different sources. They mentioned reaching out to other departments and groups, such as the business school, to gather more diverse and interesting meetings for analysis. They also discussed the potential value of having meetings with heated discussions or emotional elements. \n\nIn terms of the experiments conducted, the team discussed the results of different training sets and feature combinations. They found that using delta features improved the accuracy of the system. They also explored the combination of different features and MLP outputs, but there were challenges in achieving significant improvements. The team also experimented with a large database containing sentences from different languages, but further analysis and adjustments were needed. \n\nOverall, the meeting provided insights into the challenges and progress in dealing with latency in the system and the ongoing experiments to improve accuracy and performance.",
        "During the meeting, the discussion focused on the topic of latency in the system. The professor had an issue with the latency and there was a discussion about the duration of the latency. The meeting also touched on various other topics such as the accuracy of different configurations, the use of PLP and MSG features, the impact of neural networks, the effectiveness of on-line normalization, the language and noise dependency, and the training set used.\n\nIn terms of latency, it was mentioned that when applying on-line normalization or a neural network, the system experienced a jump in accuracy. However, the duration of the latency was not specified in the meeting.\n\nRegarding the professor's issue with latency, it was suggested that further investigation should be done to determine if there is a difference between PLP and mel cepstra features or if the neural net is not providing the desired help. It was also mentioned that the addition of MSG did not have a significant impact on the accuracy.\n\nThe discussion then shifted to the duration of the latency. It was noted that the duration varied depending on the specific configuration being used. For example, when using PLP alone, the accuracy was 88.6%, while adding MSG increased it to 89.7%. However, without on-line normalization, the accuracy dropped to 82%. The professor expressed confusion about the different results and the impact of on-line normalization.\n\nThe meeting also touched on the topic of language and noise dependency. It was mentioned that the TIMIT network performed the best, but it was unclear if this was due to language dependency or the fact that TIMIT was hand-labeled. The discussion highlighted the need to compare different networks on a range of test sets to better understand their performance across different conditions.\n\nAdditionally, future work was discussed, including the integration of the system with the OGI system. There were also suggestions to explore different training targets, such as articulatory targets or regression-based networks. The meeting also acknowledged the need to address CPU and memory issues and improve the overall performance of the system.\n\nIn summary, the discussion on latency in the system revealed the professor's concerns and the need to further investigate the impact of different configurations and training targets. The duration of the latency was not specifically mentioned in the meeting.",
        "In the meeting, there was a discussion about latency in the system. The professor expressed concern about the amount of time it takes to try different things and the need to cut down on the number of experiments. The duration of the latency was not specifically mentioned in the meeting. However, there was discussion about issues with the training set, training targets, and fitting in what they were doing with what the other party was doing. The professor also mentioned the potential for bringing in things with different temporal properties, but noted that there is limited time to explore all possibilities. Additionally, there was discussion about the difficulties with forced alignment and the challenges of accurately aligning speech segments in the system. It was mentioned that the alignment did not work well for lapel recordings and there was a need for a transcriber to time mark the boundaries of speech segments. Overall, it seems that latency in the system and alignment issues were major concerns in the discussion.",
        "During the meeting, the discussion on latency in the system was brought up. The professor had an issue with it because they needed to know the exact timing of the words in order to report accurate numbers. They discussed various ways to align the hypothesis files and improve the alignments, such as using non-lapels or aligning energy segmentations. However, they also acknowledged the problem of not knowing where the real words were due to the meetings being done before segmentation. The professor wanted to use forced alignment for the HLT paper to have actual numbers, but the issue of not knowing the timing of the words was a challenge. They also discussed the possibility of using Thilo's output to align the words, but it was mentioned that the meetings were hard to follow and transcribers were non-native speakers. They also discussed the idea of using more data and better alignments for illustrating the structure and nature of the meetings, as well as the feasibility of taking the existing meetings and aligning them with tightened boundaries. The discussion touched on the challenges of deleting segments, determining the semantics, and the potential use of reject models. They also discussed the idea of generating minutes based on the available data and the evaluation methods for summarization. The meeting also touched on the use of different learning machines and the importance of understanding their properties. The discussion highlighted the difference in approaches and the need to consider factors such as cost and specific task requirements. The meeting ended with a discussion on different papers and the need for a trip report to share the highlights of the conference."
    ],
    [
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not explicitly mentioned. However, there was a discussion about the use of construal in understanding and interpreting language. Grad C mentioned the example of the phrase \"Where is the castle?\" and how it can be construed in different ways, such as the location of the castle or the institution itself. They also discussed the use of metonymy and polysemy in language and how it can be relevant in understanding the tourist domain.\n\nGrad E's contribution to the discussion on storage disks was not mentioned in the meeting.\n\nThere were no updates provided by Grad B regarding the meeting on disk storage in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the process of giving feedback electronically. Grad D mentioned a scene from The Simpsons where the family uses buzzers to signal when they don't like what the other person is saying. This led to a discussion about the early episodes of The Simpsons and whether the mentioned scene was from the first episode. Grad E recorded the meeting and Grad G confirmed that the recording was successful.\n\nThe conversation then shifted to the topic of storage disks. Grad E contributed to the discussion by sharing their current working hypothesis about the crash that occurs when the computer tries to clear temporary files. They suggested that if the temporary files are too big, the computer crashes. Grad B mentioned a recent power outage that caused the computer to crash upon restarting. Grad E explained that the temporary files are not erased during a power failure and are stored in the scratch directory, not the temp directory.\n\nLater in the meeting, Grad B provided updates on the meeting regarding disk storage. They mentioned that the UW folks were coming the following weekend and asked if there was an agenda or any preparations that needed to be made. Grad E confirmed that the conference was the following weekend and mentioned that they had not sent out a reminder for an agenda. Grad B suggested hearing about how the conference went, to which Grad E confirmed that they would provide updates.\n\nOverall, the meeting covered various topics including feedback electronically, storage disks, and updates on the upcoming conference. The discussions provided insights into the roles of the computer and wizard, as well as Grad E's contribution to the discussion on storage disks. Grad B also provided updates regarding the meeting on disk storage.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not clearly mentioned. However, there was a mention of using a script to merge different types of things and the possibility of using tightened boundaries for better alignment in the future.\n\nRegarding Grad E's contribution to the discussion on storage disks, there was no specific mention of Grad E's contribution to this topic in the given meeting.\n\nAs for the updates provided by Grad B regarding the meeting on disk storage, there was no mention of Grad B providing any updates on this topic in the given meeting.\n\nOverall, the meeting seemed to cover various topics including speech recognition, machine learning, data availability, and the challenges of aligning schedules for meetings. However, specific details about the roles of the computer and wizard, Grad E's contribution on storage disks, and Grad B's updates on disk storage were not discussed in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that the computer would be equipped with a head-mounted cell phone to capture background noise during speech recognition tasks. The wizard would be responsible for reading lots of digits to train the system and provide real car noise for testing.\n\nGrad E's contribution to the discussion on storage disks was not mentioned in the meeting.\n\nRegarding the updates provided by Grad B, it was mentioned that the lapel microphone performed well in terms of breath noises and clothes rustling. It was noted that the lapel microphone is typically worse for clothes rustling but better for breath noises. Grad B also mentioned that the lapel microphone is suitable for reading digits as it is a different task than natural speech.\n\nIn terms of the discussion on alignments, Grad A mentioned that they were able to improve the forced alignments by adjusting the pruning and enforcing constraints on word locations. They also experimented with adapting the foreground and background speakers, but found that it produced some strange alignments. They discussed the possibility of incorporating the alignments into the Transcriber tool for better visualization.\n\nOverall, the meeting discussed the roles of the computer and wizard, updates on storage disks, and improvements made to the alignments. However, Grad E's contribution to the discussion on storage disks was not mentioned in the meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that there were some speaker labeling problems and speaker identifications which were changes. Grad E's contribution to the discussion on storage disks was not mentioned in the given meeting. Lastly, Grad B did not provide any updates regarding the meeting on disk storage in the given meeting.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not clearly stated. The conversation seemed to be more focused on groupings and synchronization of digits. Grad E did not contribute to the discussion on storage disks. Lastly, there were no updates provided by Grad B regarding the meeting on disk storage.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were not explicitly mentioned. However, there was a discussion about the information structure and focus of sentences. Grad E mentioned that even trained experts can't always tell where the focus exponent is in a sentence and that it is context-dependent. Grad B also mentioned that it is important to specify the information structure focus of a sentence before worrying about the intonation contour. \n\nRegarding the discussion on storage disks, Grad E made a contribution by stating that the stress in speech can indicate the focus exponent. Grad A and Grad F agreed with this statement and mentioned that stress is dependent on the context and can vary based on phrase breaks and restarts. \n\nIn terms of updates provided by Grad B, there were no specific updates mentioned in the meeting regarding the meeting on disk storage.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that they were trying to determine the middle layer of the belief-net. They were discussing the features that could be extracted from the communication, such as prosody, discourse, and verb choice. They also talked about the contribution of Grad E to the discussion on storage disks, but no specific details were mentioned. Grad B provided updates regarding the meeting on disk storage, but again, no specific details were given. Overall, the meeting focused on the construction and organization of the belief-net and the features that could be used to determine the mode of communication.",
        "During the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that they were trying to determine how to assign probabilities to different actions based on the context of the conversation. They discussed the idea of having a hidden middle layer that would be influenced by different cues in the discourse, such as discussing admission fees or other relevant topics. They also talked about the possibility of having separate regions in the network for different tasks, such as doing business or being a tourist. Grad E's contribution to the discussion on storage disks was not mentioned in the meeting. Grad B provided updates on the meeting on disk storage, but those updates were not mentioned in the meeting transcript.",
        "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were that they still needed a recording device for the wizard, such as a tape recorder running in a room. They also wanted to wait until they knew who the wizard was before specifying the scenario and defining the tasks. They discussed the idea of collecting data to elicit richer language and discover new phenomena. They also mentioned the possibility of including navigational tasks and tasks related to taking pictures. Grad E's contribution to the discussion on storage disks was not mentioned in the meeting. Finally, Grad B provided updates on the meeting regarding disk storage, mentioning that Fey's time with them was almost over and they found another student to play the role of the wizard. They also mentioned some problems with the synthesis, but they were expected to be resolved soon. They discussed the need to find an interpreter for the PRM and the progress made on constructing the dependency models. The meeting also briefly touched on the topic of adult literacy programs and the potential social impact of a system that combines the qualities of an individual tutor and a video game. Grad B mentioned their work on writing up the discussions and revising the construal proposal."
    ],
    [
        "SmartKom is an architecture and module system that is part of the German SmartKom project. It allows users to speak into the system and receive responses. The system uses a German synthesis module for English sentences, although there are still some issues with certain words and phrases. The system also includes a dialogue manager, a knowledge base, and a generation module. The architecture is designed to be language independent, with the ability to generate syntactic structures for different languages. The system currently has syntax trees for a few sentences, but more work needs to be done to expand the trees for different utterances. The importance of SmartKom lies in its potential to improve communication and interaction between humans and computers. It also has the potential to be integrated into other projects and research areas, such as spatial descriptions and reference frames.",
        "SmartKom is a project that involves collecting dialogues for the purpose of training and developing the SmartKom system. The dialogues consist of one person interacting with a computer or a human operator pretending to be a computer. The goal is to evaluate the performance of the speech generation system and gather training data for the SmartKom system. The recordings include both far-field and near-field channels, and the data is being collected by the SmartKom group. The question arose whether this data should be included in the Meeting Recorder corpus. While it was initially decided not to include it, it was later discussed that the data could be saved as long as there is enough disk space. The recordings could be useful for acoustic and language model training purposes. It was suggested that the data could be labeled as a separate corpus to differentiate it from the regular meeting data. It was also mentioned that the recordings could be used for experiments, but it was agreed that they should not be considered part of the official meeting corpus.",
        "SmartKom is an architecture that consists of various modules and is of great importance. The meeting discussed different aspects of organizing the system and how it can be folded in with other tools and conventions. The meeting also touched on issues such as consent and transcription. \n\nThe architecture of SmartKom involves different modules, including the Absinthe and Quicknet modules. The meeting mentioned that the Absinthe module has been ported to SmartKom and has shown promising results in terms of speed and performance. The Quicknet module is also being worked on, but there are some issues that need to be resolved. \n\nThe importance of SmartKom was emphasized in the meeting, with discussions on how it can be used in various applications such as speech recognition experiments. The meeting mentioned that the system has been successful in increasing the error rate in these experiments and is being further optimized. \n\nThe meeting also discussed the upcoming demo for the DARPA meeting in July. It was suggested that a sub-meeting should be held to discuss the details of the demo and involve relevant team members. \n\nOverall, the meeting covered various topics related to the architecture, modules, and importance of SmartKom. It provided updates on the progress of different modules and discussed future plans for the system.",
        "SmartKom is a system that utilizes various modules to improve speech recognition. One module discussed in the meeting is VTS (Vectorial Taylor Series), which is used to remove noise from the speech signal. The VTS module was tested with the Spanish database and showed some improvement when combined with VAD (Voice Activity Detection). However, the results were not better than using VTS alone.\n\nAnother topic discussed in the meeting was the Wiener filtering approach, which was being implemented for the Aurora task. The initial results showed worse performance than not using the filtering, and the team was working on identifying and fixing the issue.\n\nThe importance of noise estimation and codebook selection was also highlighted. Different methods were being tested for noise estimation, and it was suggested to standardize the process for more reliable results. The codebook for clean speech was used to estimate the expected values of the clean speech given the statistics of the noisy speech.\n\nOverall, the meeting focused on the architecture and modules of SmartKom, including VTS, Wiener filtering, noise estimation, and codebook selection. The team was working on improving the performance of these modules and investigating different approaches for better results.",
        "SmartKom is an architecture that consists of multiple modules designed to improve speech recognition performance. The system includes a VAD (Voice Activity Detection) module, a tandem network for noise estimation, and a dictionary for clean speech. The architecture is based on the VTS (Vector Taylor Series) approximation, which is a statistical method used to remove noise from speech signals.\n\nThe VAD module is used to detect speech and silence in the input signal. It helps in identifying the segments of the signal that contain speech and those that contain noise. The tandem network is responsible for estimating the noise in the speech signal. It uses a single Gaussian to model the noise and calculates the mean and variance of the noise for each frame of the speech signal.\n\nThe dictionary module is used to estimate the clean speech given the noisy speech signal. It uses a statistical approximation method to calculate the clean speech probability based on the noisy speech and noise statistics. The module calculates the mean and variance of the clean speech for each frame of the speech signal.\n\nSmartKom is important because it improves speech recognition performance by effectively removing noise from the input signal. The architecture and modules work together to estimate the clean speech and enhance the accuracy of the speech recognition system. The VAD module helps in identifying speech segments, while the tandem network estimates the noise in the speech signal. The dictionary module then uses these estimates to calculate the clean speech probability. Overall, SmartKom provides a robust and accurate speech recognition solution.",
        "SmartKom is an architecture that consists of various modules designed to improve speech recognition. One module focuses on reverberation and noise reduction, using techniques such as high-pass filtering and adaptive noise cancellation. Another module uses an auditory model to generate speech recognition features based on the human hearing system. These features are then used in a neural network to classify speech sounds. Additionally, the system incorporates a graphical model that treats intermediate speech categories as hidden variables, allowing for more accurate recognition. The importance of SmartKom lies in its ability to improve speech recognition performance in various environments, such as noisy rooms or reverberant spaces. Overall, SmartKom is a comprehensive system that combines multiple techniques to enhance speech recognition accuracy.",
        "During the meeting, the team discussed the architecture, modules, and importance of SmartKom. They mentioned that they were trying to fix certain values using the clean training part of the Wall Street Journal. They also discussed the possibility of modifying the features to account for the fact that they couldn't modify certain parameters. \n\nThe team also discussed the stability of the system under Solaris and Linux. They confirmed that it compiled fine under Solaris and discussed the potential issues with stability on Linux. \n\nThey then moved on to discuss the latency of the system and how it could be reduced. They mentioned that the latency of the VAD (voice activity detection) was currently 220 milliseconds and that it increased to 270 milliseconds when adding other components. They discussed potential ways to decrease the latency, such as modifying the delta window or changing the order of the components. \n\nThe team then shifted their discussion to the performance of the system. They mentioned that the current system had a 57.02% improvement over previous systems, with the best previous system achieving a 54.5% improvement. They also mentioned that the system had a 10% improvement in recognition accuracy on SpeechDat-Car, a hard task. \n\nThey then discussed the performance of the system with the neural network module. They mentioned that the system showed a 5% improvement in well-matched and medium mismatched conditions, but a 15% decrease in highly mismatched conditions. They discussed the possible reasons for this decrease and mentioned that the neural network module increased the number of deletions in the highly mismatched condition. They also mentioned that the overall improvement of the system was around 1-2%.\n\nThe team also discussed the possibility of using the Macrophone data to improve the training set. They mentioned that the Macrophone data had provided significant improvement in previous experiments and that it could be beneficial to explore its use in this system as well. They also discussed the possibility of using LDA (Linear Discriminant Analysis) on the features before training the models, but mentioned that the current system already used a form of non-linear discriminant analysis in the neural network module.\n\nOverall, the team discussed various aspects of the SmartKom system, including its architecture, modules, performance, and potential improvements. They identified areas for further exploration and improvement, such as reducing latency and incorporating additional training data.",
        "In summary, the SmartKom system is being tested using different architectures and modules. The experiments involve training the system with different languages and testing its performance in different conditions. The results show that using PLP features with on-line normalization and a neural network improves the accuracy compared to the baseline. However, adding multi-stream Gaussian (MSG) features does not provide any additional benefit. The experiments also include feature combination using MLP outputs and various feature streams, but the results are still being analyzed. Overall, the system performs better when trained on TIMIT data and tested on Italian digits, but there is still room for improvement, particularly in the combination of features and the use of delta and delta-delta features. The next steps involve training the system with PLP, delta, and delta-delta features and analyzing the impact on performance.",
        "SmartKom is an architecture that consists of different modules and is designed to improve speech recognition performance. The architecture includes modules such as PLP and MFCC for feature extraction, MLP for neural network training, and LDA and RASTA for feature transformation. The importance of SmartKom lies in its ability to improve recognition accuracy by training on data that is similar to the testing data. However, there are potential challenges when training on data that is different from the testing data. The meeting also discussed the importance of on-line normalization and the need to consider different noise conditions. The architecture and modules of SmartKom were discussed in detail, as well as the importance of training set, training targets, and noise dependency. The meeting also touched on the potential of combining multiple features and MLP, and the need to address CPU and memory issues. The meeting concluded with a discussion about future work, including plugging the system into the OGI system, exploring different training targets, and addressing language and noise dependencies. Overall, the meeting provided valuable insights into the architecture, modules, and importance of SmartKom."
    ],
    [
        "During the meeting, the options discussed regarding the location of the recording equipment were not mentioned. The meeting primarily focused on other topics such as the latency problem and system improvements. The decision regarding the location of the recording equipment was not made during the meeting.",
        "In the meeting, the options discussed regarding the location of the recording equipment were as follows:\n\n1. The possibility of using pitch and harmonics in the recording equipment to improve transcription accuracy was mentioned. The idea was to match the distribution of pitch and noise in the recordings.\n\n2. The potential use of an auditory model of human hearing to generate speech recognition features was discussed. This approach involved using filters with compressive nonlinearity and wavelet basis functions to analyze the input signal.\n\n3. The idea of using an optimization procedure to select an optimal set of basis functions for feature extraction was suggested. This method involved trying different subsets of basis functions and choosing the one that yielded the best results.\n\n4. The decision was made to have Guenter experiment with these options and potentially develop a better noise estimation module for the recording equipment.\n\nRegarding the decision made, it was suggested that the recording equipment be used in a multi-stream way, with different features being assigned to different streams. This would allow for a multi-scale approach to feature extraction.\n\nIn terms of the location of the recording equipment, it was suggested that regular meetings be recorded in order to have a consistent set of data for research purposes. The idea of recording meetings in different domains and with different types of participants was also discussed, in order to have a diverse range of data for analysis.\n\nThere was also a discussion about the possibility of using the equipment in a different location, such as the linguistics department or another building on campus. This would involve recording meetings that would otherwise happen anyway, and would allow for more convenient access to the equipment.\n\nOverall, the options discussed regarding the location of the recording equipment involved considering different features and approaches for improving transcription accuracy, as well as the need for diverse and consistent data for research purposes. The decision made was to experiment with these options and potentially use the equipment in different locations to record a variety of meetings.",
        "In the meeting, the options discussed regarding the location of the recording equipment were to either have a distant microphone or to have the equipment set up in the meeting room itself. The decision made was to prioritize having the equipment set up in the meeting room, as it would allow for better audio quality and the ability to capture all the necessary cues and information. The meeting participants also discussed the idea of inviting people from outside the linguistics and engineering fields to participate in the meetings in order to get a wider sampling and different perspectives. \n\nRegarding the disk resources, it was mentioned that there is currently enough space to record about four more meetings on the current disk. However, it was also mentioned that there are plans to acquire additional disks to expand the storage capacity. The process of archiving and clearing up space was also discussed, with the mention of moving data from the Aurora and other disks onto the Broadcast News disk. The meeting participants also talked about the time it takes to copy and clone the data, as well as the need to be cautious with the deletion of old files. \n\nIn terms of the research project on detecting overlapping speech, one participant shared their progress and ideas. They mentioned the need to mark and analyze the overlapping zones in the meeting recordings and their plan to use a supervised clustering process to classify the different speech and overlapping speech segments. They also discussed the use of features such as pitch and different algorithms like neural networks for classification. The importance of understanding the temporal properties of the data and visualizing the separation of classes was emphasized. The participant also mentioned the idea of building models to detect acoustic changes and classify different zones. The importance of starting with simpler features and analyzing their effectiveness before using more complex classifiers was highlighted. The participant also mentioned the need for a control set of pure silence for the analysis. The potential inclusion of transition information from silence to overlap and silence to speech was also discussed. The participant expressed their intention to continue working on the project and testing different approaches. The meeting participants provided suggestions and insights on the project, emphasizing the importance of understanding the features and building classifiers that can effectively detect and classify the different speech segments, especially the overlapping zones.",
        "In the meeting, the options discussed regarding the location of the recording equipment were:\n\n1. Using a PDA with two microphones: It was mentioned that using two microphones in the PDA could provide some location information, but it may not be sufficient for accurate speaker identification and tracking.\n\n2. Using a larger microphone array: It was suggested that using a larger microphone array, similar to what some researchers have done, could provide better selectivity and tracking of speakers. However, this option was considered more complex and expensive.\n\n3. Using the close-talking microphones: It was mentioned that the close-talking microphones could be used for recording the audio, as they would provide clearer and more focused sound. However, it was also noted that this option may not be ideal for tracking speakers and their interactions.\n\nThe decision regarding the location of the recording equipment was not explicitly mentioned in the meeting. However, it was discussed that further exploration and analysis would be needed to determine the best approach for speaker identification and tracking in the given context. It was also mentioned that the anonymization of the data would need to be considered, particularly in relation to discourse analysis and the use of names in the transcripts. The issue of privacy and how to balance it with the need for accurate speaker identification and tracking was acknowledged, but no definitive decision was made on this matter. It was suggested that further discussion and consideration would be needed to determine the best approach for anonymization and data release.",
        "During the meeting, the options discussed regarding the location of the recording equipment were not thoroughly addressed. However, it was mentioned that the new microphones were being assembled and that there was a possibility of replacing the wired mics with wireless ones. The decision on this was not made during the meeting. \n\nRegarding the transcription process, it was mentioned that there were about 35 hours of recorded data, including digits. Eleven hours of the data had been transcribed and was being reviewed for accuracy and consistency. The transcribers were also working on incorporating additional conventions for handling numbers and acronyms. The use of different features in the transcription process was mentioned, but no specific decision was made on this.\n\nThe discussion then shifted to the process of bleep editing. It was suggested that the transcripts be provided to each participant of the meeting and they would have the opportunity to bleep out sections they didn't want included. A web interface was proposed for this, where participants could access the transcripts, read through them, and indicate which sections they wanted to exclude. The issue of privacy and distribution of passwords for accessing the transcripts was raised, but a final decision was not reached.\n\nThere was some discussion on whether paper copies of the transcripts should also be provided, as some participants may prefer to review them offline. It was suggested that participants could request paper copies if they preferred. The idea of allowing participants to edit out sections of the meeting where they were not speaking was also discussed, but no consensus was reached on this.\n\nOverall, the meeting did not result in a clear decision on the options regarding the location of the recording equipment or the process of bleep editing. Further discussion and consideration may be needed to reach a final decision on these matters.",
        "During the meeting, the options discussed regarding the location of the recording equipment were whether to make it easy or difficult for people to bleep out parts of the recording. The concern was that if it was too easy, people might abuse the feature and start bleeping out things they didn't like. However, it was also important to allow participants to have control over what they wanted to remove from the transcript.\n\nIt was decided that the recording equipment would be set up in a way that made it easy for participants to bleep out parts of the recording if they wanted to. This would be done through a web interface where participants could indicate which parts they wanted to remove. However, access to this web interface would only be given to participants who specifically requested it or if it was necessary for their research.\n\nThe decision to make it easy for participants to bleep out parts of the recording was based on the understanding that some participants may have concerns about privacy or may want to remove parts that they feel are not relevant to their research. It was also acknowledged that researchers may need access to the full recording for their own analysis, so the option to bleep out parts would be made available but encouraged to be used sparingly.\n\nThe discussion also touched on the issue of distributing passwords for access to the web interface. It was agreed that passwords would be distributed through phone calls or in-person meetings, rather than through email, to ensure privacy and security.\n\nOverall, the decision was made to provide participants with the option to bleep out parts of the recording, but to make it clear that this should be done sparingly and only when necessary. The exact process for distributing passwords and accessing the web interface would be further discussed and finalized.",
        "During the meeting, the options discussed regarding the location of the recording equipment were sending an email to all participants and asking for their response, or calling participants who did not respond to the email. It was also mentioned that sending a follow-up email within a few days could be beneficial in getting more responses. The psychological effect of responding to an email was also discussed, as it was believed that people who responded to an email saying \"yes\" or acknowledging receipt were more likely to follow through with the requested action. It was also mentioned that sending a notification email would let participants know that they do not have to go to a web page to accept the recording. The importance of having a paper trail or electronic trail for legal purposes was emphasized. The decision made regarding the location of the recording equipment was to send the email as planned and follow up with non-responders through phone calls. It was also decided to send a notification email within a few days to remind participants to respond and indicate receipt of the email. It was noted that a small number of people were involved in this process, so it should not be too difficult to manage.",
        "During the meeting, the options discussed regarding the location of the recording equipment were not explicitly mentioned. However, there was a discussion about using close-talking microphones for better quality audio and uniformity. It was suggested that a field trip could be organized to purchase the same type of microphone for all participants. There was also a mention of the possibility of using microphone arrays, but it was noted that it would require a separate setup and may not be feasible for the current project's focus on impromptu situations. The issue of video recordings was also briefly mentioned, but it was acknowledged that it may present challenges in terms of human subjects' consent and privacy concerns. \n\nRegarding the decision made, it was mentioned that the transcribers had been assigned individual data sets and were making progress in transcribing the meetings. The use of pre-segmentation and the modified multi-trans system were mentioned as helpful tools in improving the transcription process. There was also discussion about providing the transcribed meetings to Jonathan Fiscus for experimentation with the ATLAS system, which is a software tool for manipulating transcription graphs. The focus on reliability and consistency in the encoding of the transcripts was also emphasized.",
        "During the meeting, several options were discussed regarding the location of the recording equipment. One option was to have IBM transcribe the recordings, as they have experience in transcription for their speech recognition products. The subcontracted transcribers were described as being more secretarial in nature rather than court reporters. The decision was made to explore the possibility of having IBM do an initial forced alignment to improve the accuracy of the transcriptions. Additionally, the idea of collecting more meeting data was discussed, including reaching out to other departments and groups outside of ICSI, such as student clubs or film-makers. The goal was to have a diverse range of meetings to improve the quality and variety of the data. The possibility of processing the waveforms to improve accuracy and reduce cross-talk was also mentioned, and it was suggested to collaborate with researchers who are working on acoustic event detection and visualization techniques. Overall, the decision was to further explore these options and continue improving the transcription process.",
        "During the meeting, the options discussed regarding the location of the recording equipment were not explicitly stated. However, there were discussions about the analysis and alignment of the recorded speech. The team mentioned the need for good signal-to-noise ratio and closer synchronization times for better alignment. They also discussed the possibility of using pre-processing techniques to improve the alignment. There was mention of the need for flexibility in alignment and the challenges of aligning short segments. The team also discussed the issue of overlap in the recordings and the difficulties in aligning speech from different speakers. The possibility of using forced alignment and cancellation techniques was mentioned, but it was acknowledged that it might not be a straightforward solution. The team also discussed the idea of using multiple channels and visual displays for better alignment. The decision regarding the location of the recording equipment was not explicitly made in the meeting.",
        "During the meeting, various options were discussed regarding the location of the recording equipment. One option was to use Thilo's output to determine the boundaries of the speech segments. Another option was to use a script to approximate the boundaries of the segments. The issue of slippage and the problem of not knowing the exact location of the words were also discussed. It was suggested that transcribers could correct the cases where the boundaries were unclear. The idea of using a reject model or marking the segments as \"not speech\" was also mentioned. The decision was made to try to use the existing meetings for purposes of illustrating the structure and nature of the meetings. It was also suggested to generate minutes based on the available data. The evaluation of the summaries and the importance of data and machine learning algorithms were discussed. The need for more data and the different properties of learning machines were highlighted. The conclusion was that more data is important, but the choice of learning machines and their properties also matter. The cost and availability of data were also mentioned. The meeting attendees also discussed various papers presented at the conference, including the topic of summarization and the use of machine learning algorithms. The issue of evaluating summaries and the different approaches to summarization were also discussed. The meeting concluded with a discussion on the importance of data and the use of different learning machines for different tasks. Overall, the meeting provided insights into the options and decisions made regarding the location of the recording equipment and highlighted the importance of data and machine learning in the field of speech recognition and summarization."
    ],
    [
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions started with the testing of the Meeting Recorder digits and the interesting findings that came out of it. The results showed a significant difference in performance between having a large amount of training data and not. The best results were achieved with a large amount of data, mostly not digits. The discussions then moved on to the SRI system and its use of allophone models. It was mentioned that the SRI system showed better results with adaptation and that without adaptation, the error rate was around fifty percent worse. The amount of training data was also discussed as a possible factor affecting the performance of the system. It was noted that commercial systems use a huge amount of training data, while the current system only had a modest amount. The differences in recording conditions were also mentioned as a possible factor affecting the performance of the system. It was suggested that further experiments be conducted to explore these differences. The discussions then shifted to the use of a new VAD (Voice Activity Detection) system and its impact on the performance of the system. It was noted that the new VAD system significantly improved the results and made a huge difference in the performance of the system. The discussions also touched on the use of different filters and the need for a better understanding of the time-varying reverberation response. The discussions concluded with a mention of upcoming meetings and the need for consent forms to be signed by participants. It was noted that the consent forms had been sent out and that no changes or objections had been received so far. The deadline for signing the consent forms was set for July 15th. The discussions also touched on the division of meetings and the importance of giving participants an opportunity to review and correct the transcriptions. It was mentioned that a follow-up reminder should be sent out two weeks prior to the deadline. Overall, the discussions covered a range of topics related to talk, neurons, transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about various topics including the talk, neurons, transcriber pool, and acoustic-phonetic analyses. Some of the discussions focused on the process of making research materials available to other researchers and the need for a specific timeline for responses. There was also a discussion about the importance of getting a response from participants and the potential risks of not receiving a response. The meeting also touched on the need for clear communication and agreement from participants, including the use of email and other contact information. Additionally, there was a discussion about the need to have legal guidance and the importance of having a paper trail or electronic trail indicating participants' awareness and agreement. The meeting also addressed the issue of transcribing meetings accurately and the challenges that can arise, such as capturing backchannels and jargon. There was a discussion about the use of headphones and the need for high-quality equipment for transcription purposes. Overall, the meeting covered various aspects related to the talk, neurons, transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about several topics, including the need for better quality close-talking microphones, the upcoming NIST visit, the modifications to the multitrans software, and the pre-segmentation of the audio data. \n\nRegarding the close-talking microphones, it was mentioned that there is a preference for having uniform microphones worn in a standardized way to capture the best signal. This would make it easier for transcribers and researchers to work with the data. It was suggested to get more head-mounted microphones, even beyond the number of radio channels available, as the microphone type is more important than the method of transmission. The idea was to have the microphone close to the speaker's mouth but not too close, and to wear it in a specific way to minimize breath sounds. It was agreed to replace the current lapel microphones with the recommended head-mounted ones.\n\nRegarding the NIST visit, it was mentioned that Jonathan Fiscus from NIST would be visiting and expressed interest in seeing the room, a demonstration of the modified multitrans software, the pre-segmentation process, and the transcription conventions. The modified multitrans software would allow for tighter time marking of overlapping segments, and the pre-segmentation process has been a valuable asset for transcribers. There was also a discussion about potentially involving John Canny, a CS professor interested in array microphones, in the visit.\n\nThere was also a brief discussion about the possibility of using microphone arrays in the recording setup. It was mentioned that other sites, such as SRI, are investing in recording meetings with video and microphones, and it would be beneficial to have access to the data collected by other sites as well. The idea of using microphone arrays was brought up, but it was noted that it would require additional infrastructure and increased disk space usage. There was also a mention of potential collaboration with researchers interested in microphone arrays.\n\nOverall, the discussions during the meeting focused on improving the recording setup, addressing the needs of transcribers and researchers, and exploring possibilities for future collaborations and research opportunities.",
        "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. \n\nRegarding the talk, there was a discussion about the level of processing and array processing. It was mentioned that a different setup would be needed for array processing, potentially with more channels. The idea of sharing resources was also brought up, but it was determined that it might be more useful for another group to have a separate setup rather than trying to sync with the current setup.\n\nIn terms of neurons, there was a discussion about the possibility of getting video recordings for the meetings. However, there were concerns raised about infrastructure problems, people not wanting to be recorded, and human subjects issues. It was mentioned that NIST or LDC might be better suited to handle video recordings in the future.\n\nThe transcriber pool was also discussed, with the mention of having eight transcribers who were given their own data set to transcribe. It was noted that two of the transcribers had already finished their data sets, and potentially up to ten could be finished by the end of the month. The issue of time markings for the transcriptions was raised, as it was mentioned that there was a need to know where each word belonged in the transcribed segment. It was suggested that forced alignment or pre-segmentation could help with this issue.\n\nThe possibility of using the transcribers for additional tasks was also brought up. It was suggested that they could be involved in dialogue act tagging, disfluency tagging, and other types of analysis. It was mentioned that the transcribers had been consistent and could potentially be utilized for more detailed analysis in the future.\n\nThere were also discussions about potential sources of additional meeting data. It was mentioned that there could be interest from other groups, such as Berkeley political groups or student groups, who might be willing to have their meetings recorded. The idea of reaching out to different departments and organizations to find interested groups was also discussed.\n\nOverall, the discussions during the meeting covered a range of topics related to talk, neurons, the transcriber pool, and acoustic-phonetic analyses. There were considerations for different types of processing, potential sources of data, and utilization of the transcribers for additional tasks.",
        "The discussions in the meeting were about several topics, including talk about neurons, the transcriber pool, and acoustic-phonetic analyses. The participants discussed the difficulty of the group and the lack of right or wrong answers in artistic endeavors. They also talked about the possibility of having discussions on various topics, such as politics and science. The meeting also covered the RASTA and PLP features, the possibility of getting Julia Child to visit, and the idea of using different departments for data collection. They discussed the issue of room acoustics and the need for better signal-to-noise ratio and closer time synchronization. They also talked about potential collaborations with other groups and student clubs. The meeting concluded with a discussion on wave form processing and the need for better alignment and transcription methods. Overall, the participants discussed various aspects related to talk, neurons, the transcriber pool, and acoustic-phonetic analyses.",
        "During the meeting, there were discussions about several topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions touched on various aspects such as the effects of highly-mismatched data, the availability of the recognizer, the amount of training and testing data, the training and testing conditions, the use of different noises in the data, the estimated release date of the system, the use of Gaussian mixture models, the availability of scripts for training and testing, the potential modifications to the system, the use of support vector machines, the ease of use of the system, the consideration of different features and their scaling characteristics, the involvement of Joe in the project, and the access to the mailing list archive. \n\nIn addition to these discussions, there was also a conversation about clustering of data and the discovery of intermediate categories for classification. The participants talked about the use of TRAPS for temporal patterns of phonemes, hierarchical clustering algorithms, the selection of categories based on discrimination, the potential for generalizing the clustering process, and the need for categories that can clarify confusions in recognition. They also discussed the potential integration of top-down and bottom-up approaches, the consideration of words as categories instead of phonemes, the challenges of dealing with spontaneous speech and robustness, and the importance of context and prediction in human speech processing.\n\nOverall, the discussions in the meeting covered a range of topics related to talk, neurons, transcriber pool, and acoustic-phonetic analyses. The participants shared insights, raised questions, and explored potential solutions and approaches to the challenges and issues discussed.",
        "During the meeting, the discussions about the talk focused on analyzing interruptions in speech and the location of these interruptions. They looked at pause boundaries and T-closures and considered interruptions to occur if they occurred in the middle of a word. They also discussed the tags used in the analysis, such as spurt tags, discourse markers, backchannels, and disfluencies. They looked at the distribution of these tags and found that interruptions were more likely to occur after discourse markers, backchannels, and filled pauses. They also discussed the possibility of using acoustic-phonetic analyses to detect interruptions based on changes in pitch. Additionally, they discussed the process of transcribing the meetings and the difficulties in determining the boundaries of speech and non-speech segments. They considered different approaches to transcribing the meetings, including focusing on the dominant speakers and merging segments to avoid interruptions. They also discussed the possibility of using automated methods to detect speech and non-speech segments and the need to fine-tune the alignment process. Overall, the discussions revolved around analyzing interruptions in speech, transcribing the meetings, and finding the most efficient and accurate methods for these tasks.",
        "In the meeting, there were discussions about the talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions mainly focused on the transcription effort and the segmentation of speech and nonspeech portions in the recordings. The transcribers expressed their satisfaction with the improvements made in the segmentation process using a new HMM-based system with Gaussian mixtures. They also discussed the need for a tool that can handle overlaps in the recordings more effectively, such as a musical score notation or the modification of the Transcriber tool. The possibility of using amplitude-based separation for overlaps was also mentioned. The participants mentioned the need for clear transcription standards and discussed the potential collaboration with NIST. The conversation also touched on the need for forced alignment and the possibility of sending the transcripts to Brian, who could help with the alignment process. Overall, there was a focus on improving the transcription process and finding efficient ways to handle overlaps in the recordings.",
        "During the meeting, there were discussions about various topics, including talk about microphones, the transcriber pool, and acoustic-phonetic analyses. The participants discussed the issue of finding a replacement for uncomfortable head-worn microphones and the difficulty in finding a model that fits the connector. They also talked about the importance of microphone placement and proper wearing techniques for better audio quality. The participants also discussed the challenges of transcribing and labeling breaths and laughter in the recordings. They mentioned the possibility of using DragonDictate's documentation for microphone placement guidance. They also discussed the challenges of accurately transcribing laughter and the importance of marking breaths and laughter in the transcripts. The participants also talked about the potential benefits of using the transcriber pool for more detailed analysis of overlaps and inter-annotator agreement. They also discussed the possibility of using the SRI recognizer to train models for breaths and laughter. The participants then discussed the limitations of using energy as an indicator for overlaps and the potential of using pitch-related and harmonicity-related features instead. They also discussed the possibility of using Markov models and the BIC criterion to distinguish between overlapping and non-overlapping speech. The participants mentioned the need for further experimentation and the possibility of using Javier's software for classification. They also discussed the possibility of hand-segmenting the recordings and feeding them into Javier's software to test its effectiveness. The meeting concluded with the decision to read some digits."
    ],
    [
        "In the meeting, the professor and the team discussed various topics related to echoes, reverberation, and acoustic events. They talked about spectral subtraction and Wiener filtering as methods for noise suppression and the results they achieved. They also discussed the use of VAD (Voice Activity Detection) for noise estimation and the challenges they faced in implementing it. The team mentioned the need for better VAD and noise estimation methods and discussed the possibility of using a neural net for these tasks. They also talked about the upcoming evaluation and the consent forms that need to be signed by participants. The professor mentioned the importance of finding a balance between reducing latency and improving performance. The team also discussed the possibility of using different features for speech recognition and the need to gather more data for training. Overall, the professor's opinion was that there is still room for improvement in echoes, reverberation, and acoustic events research, and the team should focus on refining their methods and techniques.",
        "During the meeting, the professor and other participants discussed the process of reviewing and releasing audio transcripts. They debated the best way to obtain consent from participants and ensure that they have the opportunity to review and make any necessary changes to the transcripts before they are released. The professor emphasized the importance of having a clear and defined timeline for participants to respond and give their approval. They also discussed the possibility of using email confirmations or other methods to ensure that participants have received and acknowledged the transcripts. The participants also discussed the challenges of accurately transcribing meetings, including the need to correctly interpret jargon and foreign language terms. They highlighted the importance of double-checking and verifying the accuracy of the transcripts before releasing them. Overall, the participants recognized the need for a thorough and efficient process to obtain consent and ensure the accuracy of the transcripts before their release.",
        "During the meeting, the professor's opinion on echoes, reverberation, and acoustic events was not discussed.",
        "In the meeting, the professor and the attendees discussed various topics related to echoes, reverberation, and acoustic events. The professor mentioned that it is not uncommon for performance to be worse on short words compared to long words due to accumulating more evidence for the longer word. The attendees discussed creating vocal sound models that are more closely matched to their expectations of word duration and analyzing transition probabilities in the models. They also discussed the use of silence models and the optionality of certain models. The professor mentioned the limitations of using large and complex models in real applications and the importance of simplicity in improving performance. The professor also mentioned the possibility of adjusting parameters such as the number of Gaussians in the models and the need to consider the limitations of computation. The attendees discussed the calculation of expected durations of hidden Markov models (HMMs) and the potential for comparing matched and unmatched cases based on model durations. The professor emphasized the importance of simplicity and encouraged the attendees to explore different approaches and see what improvements can be made. The attendees also discussed the next steps for their research and the need to continue working on their current tasks and experimenting with different techniques.",
        "In the meeting, the professor and the other attendees discussed various aspects of echoes, reverberation, and acoustic events. They mentioned testing different configurations of features, such as using two KLTs, a global KLT, and a KLT for a network. They also discussed the use of LDA and neural nets in the feature extraction process. The professor mentioned that combining discriminative and non-discriminative features could be beneficial. They also discussed the impact of noise compensation on the training and testing sets, as well as the potential mismatch between them. The professor suggested exploring the use of Macrophone data and improving the training set. They also talked about the possibility of using additional features, such as the VAD flag, in the neural net. The professor mentioned the importance of considering the correlation between features and the potential issue of high deletions in the highly mismatched condition. They also discussed the possibility of using context-dependent units instead of phonemes in the tandem net. The professor mentioned that he would be unavailable for the next few weeks due to travel. The meeting concluded with a discussion about the upcoming evaluation and the progress made so far.",
        "In the meeting, the professor and the students discussed various topics related to speech recognition and acoustic events. One topic that was discussed was the training process for the HTK back-end, which involves multiple rounds of training with different iterations. The professor and the students talked about the number of Gaussians in the model and how it affects the training time. They also discussed the possibility of reducing the number of iterations in the early rounds of training to speed up the process.\n\nAnother topic that was discussed was the weighting of error rates in different language and condition settings. The professor and the students talked about the current weighting system, which is based on improvement, and the possibility of changing it to combine error rates before computing improvement. They also discussed the need for consistency in the weighting system across different languages.\n\nThe professor and the students also discussed the use of a voice activity detector (VAD) in the speech recognition system. They talked about the potential benefits of using a VAD, such as improving the baseline performance and reducing latency. They also discussed the possibility of using a neural network for the VAD and the need for further testing and experimentation.\n\nIn addition, the professor and the students discussed the use of spectral subtraction and on-line normalization in the speech recognition system. They talked about the improvements that these techniques can bring and the need for further testing and evaluation.\n\nThe professor and the students also talked about the use of features for voicing detection. They discussed different statistical measures, such as variance of the spectrum of the excitation, and how they can be used to detect voiced sounds. They also talked about the need for further experimentation and testing to determine the effectiveness of these features.\n\nOverall, the professor and the students had a detailed discussion about echoes, reverberation, and acoustic events in the context of speech recognition. They discussed various techniques and approaches, as well as the need for further testing and evaluation to improve the performance of the system.",
        "In the meeting, the professor's opinion on echoes, reverberation, and acoustic events was not explicitly stated. However, there were discussions related to these topics. One discussion focused on the computation of differences in variance and the use of mel filter banks to remove reverberation and extract the excitation signal. The professor mentioned the importance of low frequencies and the trade-off between spectral details and smooth representations for speech recognition. The professor also mentioned the use of modulation spectrum in speech recognition and the importance of the spectral slice in analyzing the effects of reverberation. The professor also discussed the use of high-pass filters and the potential impact on dynamic range and quantization error. Additionally, there were discussions about the effects of transition probabilities and the number of mixtures per state on recognition performance. Overall, the professor's opinions on echoes, reverberation, and acoustic events were not explicitly stated but were discussed in relation to speech recognition and the development of new systems.",
        "In the meeting, the professor and the team discussed various topics related to echoes, reverberation, and acoustic events. They mentioned the degradation of the well-matched case and the effects of the new filter. The professor raised the question of whether the new filter makes things better or worse for other cases, to which the team responded that it doesn't hurt but doesn't necessarily improve things either. They also discussed the importance of looking at patterns across different cases to determine if there are any consistent improvements or degradations.\n\nThe team mentioned that they are exchanging emails with the OGI gang regarding the results and that they are working on integrating spectral subtraction from Ericsson. They also mentioned working on their own spectral subtraction method and the idea of having source code control.\n\nThe professor inquired about the level of communication with the OGI gang and the progress of the integration of the new methods. The team mentioned that they are exchanging emails and that they will fix the system as soon as they have significant results. They also discussed the upcoming Eurospeech deadline and their plans for submitting a paper. They mentioned that they are working on the Meeting Recorder digits and the special session on Aurora.\n\nThe team also discussed the idea of having a second stream and using different voice activity detection methods. They mentioned the possibility of using spectral subtraction and on-line normalization and the challenges that come with it. They also discussed the use of pitch and harmonic structure in improving the system's performance.\n\nThe professor shared his past experience with voicing detection and the use of independent information in reducing noise. He mentioned the possibility of using a tandem system and multiplying probabilities to improve the system's performance. The team discussed the challenges of labeling and aligning data for experiments and the limitations of the current language model in the HTK recognizer.\n\nThe team also discussed the idea of having different digit strings in the training data and the impact it may have on the system's performance. They experimented with different grammar models but didn't see significant improvements.\n\nOverall, the professor and the team had a thorough discussion on various aspects of echoes, reverberation, and acoustic events, and shared their ideas and progress on improving the system's performance."
    ],
    [
        "In the meeting, PhD D and PhD F discussed their opinions on a paper and Eurospeech. PhD D mentioned that the paper on the system proposed for Aurora was accepted and the comments from the reviewers were good. PhD F asked about the location of Eurospeech and PhD D mentioned that it will be held in Aalborg, Denmark in September. \n\nPhD C gave updates on their work on online normalization. They mentioned that they have been trying different approaches, including playing with the time constant and training the normalization with two different means for silence and speech. They also mentioned that they have been experimenting with thresholding and found that adding noise to the mel filter bank coefficients improved the smoothness of the trajectory. However, they noted that both online normalization approaches seemed equivalent in terms of speech recognition performance. \n\nProfessor B suggested that PhD C should investigate the types of errors made with different approaches and look at how they vary depending on the frequency. PhD C agreed and mentioned that they were also planning to experiment with different tunings for the different MFCCs. \n\nPhD A discussed their work on cheating experiments to determine the relative effectiveness of intermediate categories in phone recognition. They mentioned that they were using the TIMIT database and planning to feed the outputs of the net into a standard recognizer. \n\nPhD G mentioned that they had tried implementing phase normalization using the Vectorial Taylor Series (VTS) approach. They initially had some issues but found a bug in their code and were able to get intelligible speech. However, the results were still not as good as not using VTS. \n\nPhD E shared their work on VTS and mentioned that they experimented with VTS alone and found that when combined with VAD, the results were better. However, when they added more components like LDA, the results were worse than not using VTS. They also mentioned that they were considering using Carlos' filters for noise estimation. \n\nPhD D mentioned that there might be a bug in their code and PhD C suggested standardizing the noise estimation process. \n\nProfessor B suggested using known sections of nonspeech for noise estimation in order to have more reliable estimates. \n\nPhD E also discussed the VTS method and explained that it involves removing some noise but not too much. They mentioned that they had performed experiments with VTS alone and found that when combined with VAD, the results were better. However, when they added more components, the results were worse than not using VTS. \n\nPhD C mentioned that the codebook used for VTS might be too clean and suggested exploring Carlos' filters for noise estimation. \n\nPhD D discussed their work on Wiener filtering for the Aurora task. They initially thought it was doing well but then found a bug in their code and the results were worse than not using Wiener filtering. They mentioned that they were also considering using Carlos' filters in their implementation. \n\nPhD E mentioned that they had been working with VTS and performed experiments with the Spanish",
        "During the meeting, PhD D and PhD F discussed their opinions on a paper and Eurospeech. PhD E explained their approach to estimating the PDF for noisy speech using a technique called minimum mean-square estimation. They discussed using a codebook with different density Gaussian models for clean speech and the idea of obtaining the expected value of clean speech given the statistic of the noisy speech. PhD C mentioned the use of a model of clean speech as a codebook. PhD F talked about the complexity of the problem and the need to estimate the noise. PhD E mentioned their experiments on calculating the compensation of the dictionary and the estimation of the mean and variance of the noisy speech. They also discussed the use of the VTS method and the calculation of the mean and variance for each Gaussian of the codebook. PhD F asked about the amount of noisy speech needed for good statistics and the use of more parameters to characterize the noise. PhD E explained the process of obtaining the clean speech estimation using the VTS method and the calculation of the mean and variance. PhD E also mentioned the use of different lengths of time for training and testing the models and the possibility of using multiple passes for better results. PhD D and PhD F discussed the use of different lengths of time for training and testing and the potential benefits of using more parameters to characterize the noise. They also discussed the use of a second term in the vector Taylor series and the complexity of the problem. PhD A mentioned the idea of introducing oneself verbally in an interactive system to improve the accuracy. PhD D and PhD F talked about the results of their experiments and the improvements achieved with the Wiener filtering technique. They discussed the use of Wiener filtering in combination with other techniques such as spectral subtraction and the importance of the VAD in estimating the noise. PhD B explained the principles of Wiener filtering and the process of estimating the clean power spectrum from the noisy spectrum. They also discussed the use of different techniques such as spectral subtraction and the sub-space approach. PhD B mentioned the smoothing of the filter to remove zeros and the results of their experiments. Overall, the meeting focused on the different techniques used for estimating the PDF for noisy speech and the improvements achieved with the Wiener filtering technique.",
        "In the meeting, PhD D and PhD F discussed their opinions on the paper and Eurospeech. PhD D talked about his experiments with spectral subtraction and how he achieved improvements in SpeechDat-Car by using a proper voice activity detector (VAD). He mentioned that his best-case performance so far was 67% and that he still needed to try his techniques on TI-digits to investigate why it was not improving much on that dataset. PhD F shared his work on spectral subtraction and spectral whitening. He mentioned that he used a technique to estimate noise based on the minima of energy in frequency bands and achieved slight improvements compared to the VAD-based noise estimate. He also mentioned that he was working on developing a better voice activity detector and was planning to train a neural network on all the data, including SpeechDat-Car, to improve the VAD performance. Overall, both PhD D and PhD F expressed the need for further experimentation and parameter tuning to optimize their techniques.",
        "In the meeting, PhD D and PhD F discussed their opinions on the paper and Eurospeech. PhD D mentioned that they focused on four types of features for their testing, which included PLP, PLP with JRASTA, MSG, and MFCC from the baseline Aurora. They trained several neural networks on the TI-digits English and Italian data, as well as on the broad English, French, and Spanish databases. They found that when the network was trained on the task data, it performed well. However, when they trained the network on broad data, the performance decreased. PhD D also mentioned that they tested the networks on different languages, including Italian, and found that the results were worse when the network was trained on Spanish. They also discussed the idea of using multi-band features and combining features and network outputs to improve the performance. They planned to work on these ideas and retrain the networks with revised on-line normalization. PhD E mentioned that they were currently working on combining the PLP twelve on-line delta-delta and MSG filter features using HTK. PhD D mentioned that they were planning to work on multi-band features and using both features and network outputs to reduce the number of outputs of the neural network. They also discussed the possibility of transforming the features with KL. Overall, the meeting focused on the different features and training methods used and the potential improvements that could be made to the networks.",
        "In the meeting, it was discussed that both PhD D and PhD F had opinions on the paper and Eurospeech. PhD D mentioned that the results of the paper looked good overall, although there were a few examples where it made things slightly worse. PhD F had a question about how the LDA filter was trained and obtained. Professor B mentioned that he wasn't sure about the specifics of the LDA filter training, but it was done during the training process. PhD E also had questions about the difference between ASP and baseline and how the voice activity detection was being used. Professor B explained that ASP stood for \"baseline ASP\" and that it was mostly better than the baseline, although there were a few cases where it was slightly worse. The discussion then shifted to the topic of resources and computational limits. Professor B mentioned that they were doing alright in terms of resources and computation, but there were some delays in processing the data. They also discussed the possibility of using the new IBM machine and the potential benefits of running things on Linux. The conversation then moved on to the topic of the evaluation criteria for Aurora. It was mentioned that there were discussions about changing the criteria and requiring a lower improvement percentage for the mismatched conditions. However, some participants, including Nokia and QualComm, expressed their concerns and suggested giving it another round with the current criteria. Professor B also mentioned that there were concerns about the weights assigned to the different systems and how they could be manipulated. The meeting concluded with a discussion about the TRAP recognition technique, which involves recognizing speech based on temporal patterns. Professor B mentioned that they were working on improving the initial estimates of the mel spectrum and exploring different techniques for noise separation. Sunil, one of the team members, had requested a one-month vacation and was currently in India.",
        "In the meeting, Professor B mentioned that there was a discussion about the opinions of PhD D and PhD F on a paper and Eurospeech. He mentioned that PhD D had a plan to get engaged and get a PhD, while PhD F needed to finish first. Professor B also mentioned that PhD E and PhD F had known other friends who had gone back to India for a month and come back married. The discussion then shifted to the next evaluation and the possibility of rerunning systems. Professor B mentioned that there was no set date for delivering endpointed data and that it would be useful to show a 50% improvement in the next meeting. They also discussed the new baseline, which was 22% better than the old one using the voice activity detector. They then discussed the idea of modifying coefficients in the model to change their importance and the potential for using a genetic algorithm to find the best combinations. They also discussed the possibility of modifying the variance of the coefficients to change their importance. PhD D mentioned that they had been working on documentation and were almost finished. They also discussed the possibility of creating a mailing list to improve communication between the different parts of the distributed center. Finally, they discussed the availability of software from Intel and the potential for using it in their work.",
        "In the meeting, PhD D and PhD F discussed their opinions on the paper and Eurospeech. They talked about the progress they have made in their research and the areas they still need to work on. PhD D mentioned that they have been training a new VAD and a new feature net. PhD A explained the details of their noise compensation technique using Wiener filtering on FFT bins. They also discussed the idea of adding a second stream to the system and improving the VAD. They mentioned that their system is currently ranked second in the evaluation. They also talked about the upcoming Wall Street Journal evaluation and the system that will be provided for download. PhD E mentioned that he will be handling the large vocabulary part of the evaluation and will be in contact with Joe, who will provide the system. They also discussed the possibility of modifying their features to work better with the system. In addition, PhD C shared his research on clustering data and discovering intermediate categories. He explained his approach of using agglomerative hierarchical clustering and his goal of finding categories that can better distinguish between similar sounds. Professor B provided some insights and suggestions, highlighting the importance of discriminative aspects and considering the confusions made in recognition. Overall, the meeting covered various topics related to the progress and future plans of the research.",
        "In the meeting, PhD D and PhD F discussed their opinions on the paper and Eurospeech. They talked about the importance of having top-down feedback in learning systems and the need for rewards or reinforcement in the learning process. They also discussed the difficulty of dealing with phonemes and the potential benefits of focusing on words instead. They mentioned that in some applications, going beyond words to concepts and actions could be beneficial. They also discussed the limitations of current word models and the challenges of dealing with conversational speech. PhD D and PhD F agreed that words would be a good intermediate category for word recognition. They also discussed the importance of context and our brain's ability to fill in gaps in conversational speech. They mentioned the need for better noise estimation and the potential use of a neural net for noise reduction. They also discussed the issue of latency and the potential use of a neural net for processing. They agreed that further work needs to be done on the VAD and noise estimation. PhD D and PhD F also mentioned their plans to work on features for the project and the importance of data-driven approaches. Overall, the meeting provided insights into the opinions and discussions of PhD D and PhD F on the paper and Eurospeech."
    ],
    [
        "Based on the meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is as follows:\n\n1. Transcription: The transcribers have been working on transcribing the recordings. They have been marking breaths and laughter in the transcripts, which are important for modeling purposes. The transcriptions are being done with the goal of training models for speech and nonspeech segments.\n\n2. Recordings: The recordings are being made using head-worn microphones. There is a need to find a replacement for the current microphones due to discomfort. The connector for the microphones is unique, and it has been difficult to find alternative models with the same connector. The position and placement of the microphones on the head have been discussed, and it is important to have them placed correctly to capture good quality audio.\n\n3. Intermediate Categories: The transcribers have been marking breaths and laughter in the transcripts. These categories are being treated as separate words in the language model and are assigned dedicated phones. The laughter category is further divided into laughter between words and laughter during speech. The transcribers are also marking overlaps in the transcripts, although the current interface does not allow for detailed encoding of overlaps. There is a need to find tools or modify existing ones to handle overlaps more effectively, potentially using a musical score notation.\n\nOverall, progress is being made in transcription and recording efforts, with a focus on improving the quality and accuracy of the transcriptions. The need for proper microphone placement and finding suitable replacements is also being addressed. There is ongoing discussion about the best way to handle intermediate categories such as breaths, laughter, and overlaps in the transcriptions.",
        "Based on the given meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is as follows:\n\n1. Transcription Status: The transcription process is ongoing. The data collected from the IBM side has been sent to transcribers and is expected to be completed next week. On the ICSI side, Jane has assigned transcribers to work on transcribing the meetings, and they are currently in progress. Some meetings have been transcribed, and others are still being worked on.\n\n2. Participant Approval: The process of obtaining participant approval for the transcripts is underway. The plan is to send the participants links to web pages containing the transcripts and audio recordings, allowing them to suggest edits. The participants will have access to both the transcripts and the audio to ensure accuracy.\n\n3. DARPA Demo Status: The back-end of the demo is working well and is ready to go. The front-end development is progressing, but at a slower pace. The team is exploring the possibility of adding additional features, such as displaying stylized pitches and signals, to enhance the demo.\n\n4. Disk Issues: There are concerns regarding disk space, particularly for the expanded meetings and the scratch disks. The scratch disks are almost full, and the expanded meetings require additional space for transcriptions and other data. One solution being considered is using the newly acquired SUN-Blade machines to add more disk space by installing additional hard drives.\n\nOverall, the transcription process is ongoing, and efforts are being made to address disk space issues and improve the demo capabilities.",
        "In the meeting, it was discussed that there is a need for more disk space for the transcription, recordings, and intermediate categories in relation to the SPG schema. It was mentioned that Abbott could be used as a disk server, but a second disk rack or file server may be needed. It was also mentioned that a second file server may be purchased. The amount of space needed for each meeting was estimated to be about a gigabyte. It was discussed that Dave Johnson, who usually sets up the disk space, will be gone for ten days, so alternative solutions for the space issue were considered. It was suggested that external drives be added to each machine and that some disks be placed in the back room. The possibility of running wires to the back room to connect it to the ICSI network was also mentioned. The meeting also discussed the current status of transcription. It was mentioned that more transcribers have been hired and they are making progress. The transcriptions are in a sub-directory called \"transcripts\" and the data is available for use. It was mentioned that the transcription for the first five EDU meetings has been processed and can be sent to IBM. It was also mentioned that a new MLP (Multilayer Perceptron) has been trained and that a hybrid system using this MLP and the dictionary from the Hub-five system will be tested. It was mentioned that the size of the MLP will depend on the amount of training data, with a suggestion of using a couple of thousand hidden units. The transcription status and the progress of the DARPA demos were also discussed. It was mentioned that the THISL tools for information retrieval on meeting data are being used and that a command line version of the indexing and querying is working. It was mentioned that a user interface for the information retrieval tools is being developed and that two options, a web-based tool and a tool that uses the SoftSound system, are being considered.",
        "Based on the given meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is as follows:\n\n- The Channeltrans interface allows users to do a find and play function, where they can search for specific strings and listen to the corresponding audio.\n- The search function in Channeltrans is based on text-retrieval and uses term frequency-inverse document frequency scoring.\n- The interface also includes metrics for spacing and requires pre-indexing of documents.\n- The THISL GUI tool, which is based on Tcl-TK, allows users to type in a query and receive a list of hits that they can click on to listen to the audio.\n- The tool can handle fuzzy matches and allows users to search for specific phrases or words.\n- The current status of transcription in relation to the SPG schema is that the transcription files are being converted to XML format to make it easier to extract information from them.\n- The process of converting the transcription files to XML is ongoing and is being done using Java and Perl.\n- The goal is to have all the transcription files in XML format so that they can be easily processed and analyzed.\n- The meeting also discussed the possibility of using CrossPads, which are digital pads that allow users to take notes and record time-stamped information.\n- There was some interest in using CrossPads to mark important points in the meetings and create a summary of the discussions.\n- However, it was decided that using CrossPads would require additional infrastructure and coordination, and it was not clear if it would be widely adopted.\n- The meeting also mentioned the possibility of using PDAs with wireless cards as an alternative to CrossPads for marking time periods and taking notes.\n- It was suggested that having PDAs with buttons to mark important points or actions could be more convenient and less cumbersome than using CrossPads.\n- The equipment status was discussed, and it was mentioned that more wireless devices were ordered and would be coming soon.\n- The meeting also touched on the reorganization of files and directories, which was still in progress.\n- It was mentioned that a plan had been made for the reorganization, but it had not been implemented yet.\n- The plan was to reorganize the files and directories before the next level zero backup to avoid any issues with missing or misplaced files.\n- The meeting also briefly discussed the IBM transcription status, which involved separating the beeps in the recordings with spoken digits to make it easier to keep track of the audio.\n- The automatic segmentations were also updated to include the spoken digits before each phrase.\n\nOverall, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is a work in progress with ongoing efforts to improve and optimize the tools and processes used for transcription and analysis.",
        "Based on the given meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is as follows:\n\n- The transcription for the recordings discussed in the meeting is being done in Munich, so there is no need to worry about transcribing it separately.\n- The recordings discussed in the meeting are part of an experimental setup for the SmartKom project and involve two people conversing with each other, with one person pretending to be a computer initially and then revealing themselves as a human.\n- It was discussed whether these recordings should be folded into the existing meeting corpus or treated as a separate category. The general consensus was to handle it with the same infrastructure but label it separately, as it is a different type of interaction.\n- The issue of disk space and backup was also raised. It was mentioned that the current backup system is becoming saturated, and it was suggested to use tape drives for archiving the data, as they are more reliable. It was also suggested to consider getting more disk space to accommodate the growing data.\n- The question of consent issues was briefly mentioned, but no specific details were discussed in the meeting.\n- It was suggested that a high-density tape drive could be purchased to backup the data and avoid burdening the existing backup system. However, it was also mentioned that the current tape system is reliable and can be used for archiving.\n- The idea of putting the data on non-backed-up disks and doing a one-time backup onto tape was discussed as a possible solution to the backup capacity issue.\n- It was mentioned that the current tape backup system is automated, and a script could be developed to automate the backup process further.\n- It was also mentioned that the data from the experimental setup could be marked separately to distinguish it from the regular meeting corpus.\n\nOverall, the current status is that the transcription is being done in Munich, the recordings from the experimental setup are being considered separately from the regular meeting corpus, and there are discussions about backup capacity and potential solutions.",
        "Based on the given meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is as follows:\n\n- The meeting discussed the use of a tape robot for backing up recordings. It was mentioned that using the tape robot may disrupt the backup operation, but it was agreed that it should not be a problem as long as the recordings are backed up in some form.\n- Dave, who has promoted this idea in the past, is not against using the tape robot for backing up recordings.\n- It was suggested that the tape robot could queue up the recordings and copy them when available, and then they can be removed from the disk after confirming that they have been backed up.\n- It was mentioned that using non-backed up disks for storing recordings could prevent them from showing up in nightly backups, which would reduce the load on the system.\n- It was also discussed that the current models for speech recognition are being experimented with, and different features and training techniques are being explored. There are differences in error rates between males and females, and various factors such as filter shapes and vocal tract length normalization are being tested to improve the results.\n- The possibility of using Absinthe for net training and forward passes was discussed, and it was mentioned that it could provide a speedup proportional to the number of processors and clock cycle.\n- The consent form for the release of transcripts was mentioned, and it was agreed that people would have until July 15th to review and request any changes to the transcripts. It was also suggested to send a reminder two weeks prior to the deadline.\n- The process of obtaining signatures for the consent form was discussed, and it was mentioned that people would not need to sign multiple times and that the agreement they already signed covers the release of transcripts.\n- The need for a clear deadline and communication with participants was emphasized to ensure that they have enough time to review and request changes to the transcripts.\n- The possibility of contacting participants via email and/or mail was discussed, and the importance of having a record of their awareness and agreement was emphasized.\n- The need to consult with a legal expert to ensure compliance and clarity in the consent process was suggested.\n\nOverall, the current status is that the consent form has been sent out, participants have until July 15th to review and request changes to the transcripts, and efforts are being made to ensure clear communication and a record of participants' awareness and agreement. The use of Absinthe for net training and forward passes is being explored, and various factors are being tested to improve speech recognition results.",
        "In the meeting, there was a discussion about the current status of transcription, recordings, and intermediate categories in relation to the SPG schema. The discussion involved various participants, including PhD students, postdocs, and professors. \n\nThe meeting started with PhD E mentioning that they can use a ploy similar to what is used for serving legal documents to get people to respond to emails. The group then discussed the different approaches they had taken in the past, from not doing anything to following up with each person and getting a signature. PhD H mentioned that they should seek expert opinion on the matter before assuming consent if there is no response. \n\nThe conversation then shifted to the number of people they needed to contact and the likelihood of getting a response. PhD H suggested sending a follow-up email within a few days to remind people to respond. Postdoc A added that this would also give participants the opportunity to say that they are not going to respond. \n\nThe group also discussed the possibility of using a return receipt option in emails or a button for recipients to click to confirm receipt. They considered the psychological effect of people being more likely to respond if they have already acknowledged receipt of the email. \n\nThe discussion then turned to the transcription process and the issues that had been identified during the checking procedure. Postdoc A shared examples of corrections that had been made to transcriptions, such as clarifying terminology and correcting misinterpretations. They mentioned that some speakers had inserted foreign language terms, which had caused uncertainty in the transcriptions. \n\nThere was also a brief discussion about the need for additional disk space. It was mentioned that they had ordered three 36-gigabyte disks to be added to the file server. \n\nThe meeting concluded with a discussion about an upcoming phone call with Mari and the preparation of an annual report. The participants discussed the timing of the report and the need to gather information from various sources. \n\nOverall, the meeting provided insights into the current status of transcription, recordings, and intermediate categories, as well as the plans for future actions.",
        "Based on the given meeting, the current status of transcription, recordings, and intermediate categories in relation to the SPG schema is not explicitly discussed. The meeting primarily focuses on the discussion of a belief-net or Bayes-net model and how it can be used to interpret and make decisions based on input data. The participants discuss the different nodes and values in the model, such as Go-there, Info-on, Location, and others. They also talk about the possibility of combining nodes into a smaller subnet for specific questions, as well as the need to weight and interpret the values based on the question being asked. The participants also mention their plans for future meetings and the absence of some team members due to vacation or other commitments. Overall, there is no direct mention of the current status of transcription, recordings, and intermediate categories in relation to the SPG schema in the given meeting."
    ],
    [
        "In the meeting, Grad F expresses frustration about a previous meeting. Grad E reminds everyone that they are being recorded. Grad F and Grad A thank Professor E for avoiding a certain topic. Grad D asks Grad F about a story related to anti-lock brakes. Grad A and Grad C discuss starting meetings with synchronized activities. Professor E suggests using the metaphor of a DNA building for the thesis proposal. Grad C discusses the future experiments and proposals related to the thesis. Grad D asks about obtaining consent and Grad F suggests double-checking the spellings in the presentation. Grad C mentions the need for examples related to construal and metonymy in the tourist domain. Professor E suggests examples like \"where is the castle\" and \"I'm in a hurry\" to illustrate construal. The team discusses the use of \"where\" in different contexts and the possibility of incorporating mental space examples in the data. The meeting concludes with Grad C suggesting providing feedback electronically and Grad D mentioning a scene from The Simpsons.",
        "In the meeting, Grad B discusses the idea of adding a middle layer to the belief net. The middle layer would consist of hidden variables that represent concepts such as whether someone is a tourist, running an errand, or in a hurry. Grad B explains that the middle layer would help capture the abstract ideas that the person at the screen is trying to communicate. The middle layer would also help in determining the mode of communication, whether it is entering, vista-ing, or tango-ing.\n\nGrad C suggests adding more hidden nodes to the middle layer, such as whether an object can be entered or not. Grad A also suggests adding nodes for specific discourse phenomena, such as the discussion of admission fees or opening hours, which could influence the hidden nodes in the middle layer.\n\nThe group discusses the possibility of learning the probabilities for the belief net, but acknowledges that it is a future work. They also mention the need for a user-friendly interface for entering probability distributions.\n\nOverall, the meeting focused on the idea of adding a middle layer to the belief net and discussing potential hidden variables and their relationships to the observed nodes. They also mentioned future work and the need for further exploration and development.",
        "In the meeting, Grad F presented a revised semantic specification and construction formalism. The top block of the notation includes the name and type of each construction, while the middle block includes the constituents and their types. The bottom block includes the relations, such as before, ends, and semantic constraints. Grad F mentioned that the notation is still subject to change and that there may be additional linguistic considerations to discuss. Grad E pointed out that the notation now allows for form-meaning pairs for a type, and Grad F explained that this is useful for specifying both constructional and meaning types. The group also discussed the use of the term \"constraints\" and whether it should be changed, but ultimately decided to keep it. Grad F mentioned that the notation now includes the use of \"designates\" to indicate the head of a phrase and that this can be useful for syntactic constraints. Grad E explained that this was done to address issues with verb subcategorization and the need to specify the form of certain phrases. The group agreed that this change was necessary and that it did not revert to the X-bar theory of phrase structure. Overall, the notation provides a way to specify constructions, their constituents, and their relations in a flexible and adaptable manner.",
        "In the meeting, the future experiments, Grad F's proposal, the outcome after the demo, Grad E's opinion on the Go-there decision, and Grad F's thoughts on obtaining consent were discussed. The future experiments were mentioned but not detailed. Grad F proposed the idea of introducing mental spaces and semantic constraints. The outcome after the demo was not explicitly discussed. Grad E expressed agreement with the Go-there decision. Grad F mentioned the need for consent in obtaining data for the experiments. The meeting also touched on the topics of focus, stress, and topic-comment structure, as well as the role of information structure in determining focus. The discussion also included considerations of image schemas and X-schemas and their relationship to static and dynamic aspects. The meeting concluded with a brief mention of the discourse situation context record and the inclusion of polarity in the scenario. The exact details and examples for each of these topics were not provided in the meeting.",
        "In the meeting, the future experiments, Grad F's proposal, the outcome after the demo, Grad E's opinion on the Go-there decision, and Grad F's thoughts on obtaining consent were discussed. The discussion revolved around the binding of values in different slots, the use of semantic side of constructions, and the inclusion of causal structures and speaker attitudes in the semantic specification. The idea of using mental spaces to handle context and speaker-hearer roles was also brought up. The meeting concluded with a suggestion to focus on specific tasks and to separate the problem of inheritance for later consideration. Additionally, there was a mention of a modified GUI for JavaBayes and the possibility of using probabilistic relational models to determine how things are construed in an utterance. The next meeting was scheduled for Thursday at 4 PM.",
        "In the meeting, the discussion revolved around future experiments, Grad F's proposal, the outcome after the demo, Grad E's opinion on the Go-there decision, and Grad F's thoughts on obtaining consent.\n\nRegarding future experiments, the team discussed the need to collect data for their project called Meeting Recorder. The project involves recording impromptu meetings using both table top microphones and close talking microphones. The purpose of this data collection is to create a corpus that can be used for research on discourse and language in meetings. The team plans to release this data to the public through a body like the LDC.\n\nGrad F proposed a task for deeper understanding in the tourist domain. The task involves differentiating between three intentions: viewing an object, entering an object, and getting as close as possible to an object. The team discussed the need to build a belief-net that can accurately classify these intentions based on linguistic and contextual factors.\n\nAfter the demo, Grad E expressed their opinion on the Go-there decision. They suggested that the system should be able to differentiate between different intentions based on the phrasing used by the user. Grad F agreed with this suggestion and emphasized the importance of capturing the natural flow of conversation in meetings.\n\nIn terms of obtaining consent, the team discussed the need for participants to fill out a consent form and a speaker form. The consent form allows participants to edit any portions of the transcripts that they do not want to be released to the public. The team also discussed the need to anonymize the transcripts but not the audio.\n\nOverall, the meeting focused on the future experiments, Grad F's proposal, the outcome after the demo, Grad E's opinion on the Go-there decision, and Grad F's thoughts on obtaining consent. The team discussed the importance of collecting data for their project, differentiating between intentions in the tourist domain, and ensuring participant privacy and consent.",
        "During the meeting, Grad F discussed the topic of extracting features from conversations, such as the presence of certain words or constructions. The professor suggested using a belief-net package to analyze the data and determine the discriminatory power of different features. Grad F and Grad E were assigned the task of selecting a belief-net package and presenting their findings in the next meeting. \n\nGrad F also mentioned the possibility of obtaining consent from participants in the conversation data. The professor suggested creating a data file with different scenarios and using the belief-net package to analyze the data and set probabilities. They discussed the potential use of XML format for storing and exchanging data.\n\nIn regards to future experiments, Grad F proposed dividing the conversations into individual minutes and analyzing the number and types of overlaps between speakers. They found that overlaps were not evenly distributed throughout the conversations and that there were bursts of overlaps. They also discussed the possibility of individual differences in overlap tendencies and the need for further analysis.\n\nAfter the demo, Grad E expressed their opinion on the decision to use the Go-there system for the project. They believed that it was a good choice, considering the existing infrastructure and resources available. They also mentioned the possibility of collaborating with the FrameNet group for linguistic analysis.\n\nFinally, Grad F and Grad H discussed the time frame for the project and the need to select a belief-net package as soon as possible. They agreed to present their findings in the next meeting. The professor mentioned the upcoming conference call for a possible proposal and the need to anonymize the data before sharing it with others.",
        "In the meeting, the participants discussed the issue of studying meetings over different phone lines and the possibility of overlaps in conversations. Grad F proposed conducting future experiments to explore the differences in overlaps when more people are present in a meeting. They also discussed the idea of obtaining consent for recording meetings and the challenges of measuring overlaps accurately. Grad E expressed their opinion that using energy levels to detect overlaps may be more difficult in mixed signals, but there may be other information that can be gained from analyzing all the microphones in a meeting. The participants also discussed the idea of using a neural network or acoustic change detection to identify speaker changes in the conversation. Overall, the meeting highlighted the need for further research and experimentation to better understand overlaps and improve the accuracy of their detection.",
        "During the meeting, the following topics were discussed: future experiments, Grad F's proposal, the outcome after the demo, Grad E's opinion on the Go-there decision, and Grad F's thoughts on obtaining consent.\n\nIn terms of future experiments, there was a suggestion to wear bells on their heads to track nodding during meetings. There was also discussion about blindfolding participants during meetings to observe their nonverbal communication.\n\nGrad F proposed the idea of using blindfolds during meetings, and there was a general agreement that it could be an interesting experiment. The idea was to see how blindfolding participants would affect their communication and nonverbal cues.\n\nThe outcome after the demo was not discussed in detail during the meeting, but it was mentioned that there was some information about the distribution of responses to the demo.\n\nGrad E expressed their opinion on the Go-there decision, but the details of their opinion were not discussed in the meeting.\n\nGrad F had thoughts on obtaining consent, but it was not discussed in detail during the meeting.\n\nOverall, the meeting focused on various topics related to future experiments, the demo, and the opinions of Grad F and Grad E.",
        "In the meeting, there was a discussion about saving meeting data and how to handle it. The decision was made to save the data because it could potentially be useful for future experiments. The question arose about whether to include non-meeting data, such as hallway conversations, in the meeting corpus. It was agreed that as long as the conversations involved two or more people conversing, they could be considered part of the meeting corpus. \n\nThe future experiments were mentioned, but there wasn't much detail given about them. Grad F mentioned their proposal and there was a discussion about obtaining consent for the experiments. Grad E expressed their opinion on the decision to use Go-there, stating that it had a different purpose and was more of an experimental setup. Grad F also shared their thoughts on obtaining consent and whether to handle the data as a special case or fold it in with the rest of the meeting data. \n\nIn regards to the experiments, Grad F mentioned porting a Blass library to Absinthe and getting it to work with fast-forward, resulting in a speedup proportional to the number of processors. They were also working on doing the same for Quicknet, but were experiencing some issues. \n\nThe meeting concluded with a discussion about the upcoming demo in July and the need to put together a demo for it. It was suggested to have a sub-meeting to plan the demo with Adam, Chuck, and Dan Ellis possibly involved. The meeting ended with a unison reading of digits for transcription purposes."
    ],
    [
        "During the meeting, the team discussed various topics related to the cheating experiment and the most noisy cases. They mentioned that they had made progress in the transcription effort and discussed microphone issues and the cleanliness of the recordings. They also talked about the steps they had taken to improve speech-nonspeech segmentation and the use of different features for this purpose. They mentioned the possibility of using a musical score notation for overlaps and discussed the need for a good tool for transcription. They also mentioned the need to train models for breath and laughter and how they were handling these in the language model. Overall, the team had productive discussions and made plans for further improvements in their experiments.",
        "In the meeting, the team discussed the cheating experiment and the most noisy cases. They mentioned that they were not claiming to have a representation of mankind in the recordings and that they had a small sample size. They also discussed the transcriptions and the training process for the transcribers. They mentioned that the transcribers were perceptive and quick in their work. They also discussed the possibility of using the transcriptions for a more detailed analysis of the overlaps in the meetings. They mentioned the challenges of normalizing the energy levels in the recordings and the possibility of using pitch and harmonicity-related features to detect overlaps. They also discussed the idea of using Markov models and the potential use of Javier's software for speech segmentation. The team also discussed the need for more data and the importance of having meetings of different types and from different domains for research purposes. They mentioned the possibility of doing summarization of the meetings and the need for meetings with consistent participants for that purpose. They also discussed the idea of having random scattered meetings with different speakers for acoustic-oriented research. They mentioned the importance of having fluent speakers for language modeling purposes. Overall, the team had a thorough discussion about the cheating experiment, the noisy cases, and the experiments in general.",
        "In the meeting, the team discussed the issue of overlapping speech and the need to classify and analyze it. The postdoc suggested using a language model or grammar to help with this task. The team also discussed the need to have a corpus that is useful for a wide range of applications in computational linguistics. They talked about the challenges of setting up a recording system and the possibility of using portable equipment. The team also discussed the idea of giving participants a CD of their meeting recording and the possibility of setting up a room in the linguistics department for recording meetings. They also discussed the need for a motivated partner to help with this. The team discussed the progress of archiving and clearing up disk space for recording meetings. They mentioned the need to move the Aurora data off the Meeting Recorder disk and onto the Broadcast News disk. They also mentioned the plan to get a new disk rack with more space. Finally, one team member gave an update on their work on classifying overlapping speech. They discussed the need for a control set and the challenges of labeling and analyzing the different types of speech. The team member mentioned using a pitch extractor and the possibility of using a cluster algorithm or neural network for classification. They also discussed the limitations of using a neural network and the importance of understanding the internal workings of the classifier.",
        "During the meeting, the team discussed the cheating experiment and the most noisy cases. They talked about the need to visualize the data and analyze it in two dimensions before using more complicated classifiers. They also discussed the importance of considering the temporal properties of the data and using features that are based on a larger chunk of time. They mentioned the use of a Markov model or a context window for this purpose.\n\nIn terms of the experiments in general, they talked about the need to start with a simpler signal, such as equalized speech or mixed speech, to understand the spectral distortion and detect changes in the acoustic signal. They also discussed the importance of classifying different zones, such as overlap zones, and the challenges of processing these zones with regular speech recognition algorithms. They mentioned the use of different models and classifiers to handle these different zones.\n\nThe team also discussed the issue of anonymizing the data and the challenges it presents, especially in terms of discourse analysis and tracking speakers. They debated whether to change the names in the transcript or use anonymized names, and the potential confusion it could cause. They also discussed the importance of keeping the transcript consistent with the audio and avoiding mapping between the anonymized names and the real names.\n\nOverall, the team had a thorough discussion about the cheating experiment, the noisy cases, and the experiments in general. They addressed various aspects of data analysis, classification, and anonymization, and highlighted the need for further discussion and decision-making on these topics.",
        "During the meeting, the team discussed the cheating experiment and the most noisy cases. They talked about the need for discourse tracking and the challenges of identifying speakers in audio recordings. They also discussed the idea of anonymizing the recordings by not using names or bleeping out names, but acknowledged that this could affect the analysis of the discourse. The team also discussed the use of mean subtraction in the SmartKom system and the challenges of determining the optimal amount of data to use for training. They also discussed the use of LDA filtering and the potential benefits of using multi-band approaches in speech recognition. Finally, they discussed the results of the experiments, including the differences in performance between clean training and noisy testing conditions, and the need for further investigation into the noise estimation techniques. Overall, the discussions provided insights into the team's thoughts and plans for future research and development.",
        "In the meeting, the team discussed the results of the cheating experiment and the most noisy cases. They mentioned that the cheating experiment involved using channel zero for both dropping and estimating the noise, which resulted in a 56% improvement in the SpeechDat-Car data. They also discussed the experiments in general and mentioned that the performance for Italian and Spanish was good, but for Finnish, it was not as good. They noted that Finnish had a lower mean energy, which may have affected the performance. They also discussed the use of spectral subtraction with different thresholds and observed that adding too much noise or not adding enough noise had a negative impact on the performance. They also mentioned the possibility of using a different smoothing method to improve the VAD and reducing the latency. Overall, the team acknowledged that there is room for improvement and that further experimentation and adjustments are needed.",
        "During the meeting, the team discussed the cheating experiment and the most noisy cases. They mentioned that they were close to the noise estimate and that they needed a stronger smoothing. They also discussed the use of the VAD (Voice Activity Detector) and expressed their distrust in the current VAD. They mentioned that the VAD would be improved in the future. \n\nIn terms of the experiments in general, they discussed the performance of the SpeechDat-Car results and compared them to their own results. They mentioned that the results were similar, with a slight advantage for their approach in certain conditions. They also discussed the weighting of different conditions and how it affected the performance of their approach. They mentioned that their approach was better for high mismatch but slightly worse for well-matched conditions. \n\nThey also discussed the need to combine their approach with the French Telecom system, which was optimized for well-matched conditions. They mentioned that they had traditionally focused on mismatched conditions, but that it might be beneficial to also consider well-matched conditions. \n\nIn terms of the cheating experiment, they mentioned that they were working on improving the latencies and mentioned the use of recursive filters to reduce delays. They also discussed the use of downsampling and the need for a better on-line normalization technique. They mentioned that they were considering using clean LDA filters instead of noisy ones, as it had shown better results in some cases. \n\nOverall, the team had in-depth discussions about the cheating experiment, the most noisy cases, and the experiments in general. They discussed various techniques and approaches to improve the performance and reduce latencies.",
        "In the meeting, the team discussed various topics related to the cheating experiment and the most noisy cases. They talked about the neural network used in the experiment and how it was trained using gradient descent. They also discussed the use of EM algorithm to train the parameters for logistic regression. The team mentioned that the experiments in general showed that using this method to detect sonorance is very robust compared to other methods. They also discussed the possibility of building other detectors on different features, such as frication, abrupt closure, R-coloring, nasality, and voicing. The team also talked about the performance of the detector and the challenges of labeling the targets for the low-level detectors. They mentioned that one of the concerns was the comparison of the detector with other methods, such as Gaussian mixtures, and how it performed in noisy conditions. The team also discussed the possibility of using multiple microphones and echo cancellation to improve the performance of the detector. They also talked about the upcoming visit from the UW folks and the need to prepare an agenda for their meeting. They discussed the process of transcribing the meetings and the use of automatic segmentation and manual adjustment of boundaries. They mentioned the possibility of using X Waves instead of Transcriber for faster loading of waveforms. Overall, the team had a thorough discussion about the cheating experiment and the experiments in general.",
        "During the meeting, the team discussed the cheating experiment and the most noisy cases. They also discussed the experiments in general. They mentioned using their ears to mark the switching of audio channels and suggested a change in the software to make it easier to switch between channels. They also discussed the possibility of using forced alignment to improve the accuracy of the transcriptions and talked about the challenges and potential solutions for aligning speech and non-speech segments. The team also discussed the possibility of using the current meetings for future research or papers, and the need for better microphone options. They mentioned NIST's plans for a room with different microphone options, including close-mounted mics, lapel mics, and microphone arrays. They also discussed the use of a KEMAR head for calibration. Overall, the team had a thorough discussion about the cheating experiment, noisy cases, and experiments in general, addressing various technical and practical considerations.",
        "During the meeting, the team discussed the cheating experiment and the most noisy cases. They mentioned that the cheating experiment started with the Broadcast News system and then moved on to simpler tasks like command and control. They also mentioned that the experiments in general showed that the Wall Street Journal data worked well, even better in some cases. However, they noted that the experiments did not control for parameters and that the simpler tasks may not have all the necessary data. They also discussed the idea of going from simpler tasks to more complex tasks and the importance of machine learning algorithms in speech recognition. They mentioned that more data can improve performance, but different learning machines have different properties and it is important to understand those properties. They also discussed the challenges of evaluating the quality of summaries and the need for more research in the field. Overall, the team had positive opinions about the experiments and the potential for future work.",
        "During the meeting, the team discussed various topics including the cheating experiment, the most noisy cases, and the experiments in general. They talked about the possibility of some participants not receiving the experiment materials and the need for proper communication and confirmation. They also discussed the importance of tracking when people log in to view the materials and the need for a follow-up email to ensure receipt and response. The team also talked about the challenges of transcription, including the need for better tools and the difficulties in capturing backchannels and jargon. They also discussed the need for additional disk space and the plans to order more. The team briefly mentioned the upcoming annual report and the need for status updates. They also mentioned upcoming meetings and the need for automatic transcription status updates. The team discussed their plans for a conference and the acceptance of their abstract. Finally, the team briefly mentioned the need for a car wash and dry cleaning. Overall, the team had a productive meeting discussing various important topics."
    ],
    [
        "During the meeting, PhD C discussed the signal-to-noise ratio and patterns of noise in the recordings. They mentioned that the technique being used works well for pure reverberation, with a signal-to-noise ratio of about 9 dB. However, there were concerns about the filters being used and the possibility of adding more noise. PhD C also mentioned experimenting with a VAD neural network that uses noise-compensated features and an LDA filter. This VAD showed improvement in recognition, but had a latency issue of 220 milliseconds. PhD C also mentioned trying a tandem neural network with straight MFCC features and features from the VAD neural network. This tandem network showed improvement in well-matched and medium mismatched conditions, but a decrease in performance in highly mismatched conditions. PhD C is planning to experiment with different configurations and explore the use of a KLT to reduce the number of features. They also discussed the possibility of adding Macrophone data to the training of the neural net to improve performance. Overall, the meeting highlighted the ongoing efforts to improve the recognition system and address issues related to noise and signal-to-noise ratio.",
        "In the meeting, PhD C, PhD E, and PhD B discussed the signal to noise ratio and patterns of noise in the recordings. PhD C mentioned that after noise compensation, the neural net is seeing a different set of signal to noise ratios (SNRs) than the original training set. PhD D agreed and added that the SNR in the training set may not cover the whole set of SNRs in the SpeechDat-Car dataset. PhD B also mentioned that the noise compensation in the SpeechDat-Car data may not be equally reducing the noise on the test set and the training set.\n\nPhD C observed that the number of deletions dramatically increased when the neural network was added, but the number of insertions and substitutions stayed the same or improved slightly. PhD B suggested that the neural network may not be equally reducing the noise on different SNRs. PhD C also mentioned that the neural network had a negative impact on the number of deletions. PhD A asked if the number of deletions increased even for the cases that improved, and PhD C confirmed that it did not.\n\nPhD C and PhD B discussed the idea of incorporating additional features, such as the Voice Activity Detection (VAD) flag, into the neural net to provide additional discriminating information. PhD D mentioned that he has been exploring a parallel VAD without a neural network to reduce latency. He found that it gave a slightly better performance with lower delay.\n\nPhD B suggested considering the correlation between the noise compensation and the performance of the neural net. PhD C mentioned the possibility of using Linear Discriminant Analysis (LDA) on the features before training the models. PhD B agreed that discriminative methods like LDA and neural nets are good because they learn to distinguish between categories, while Principal Component Analysis (PCA) does not. PhD A suggested trying LDA on the features before training the models to see if it improves the results.\n\nPhD D mentioned the idea of using the \"before and after clean\" feature, which is the ratio of energies before and after noise compensation, in the neural net. PhD B suggested modifying the output probabilities of the neural net based on the silence probability from the VAD. PhD C mentioned the challenge of finding a consistent threshold that works well across different databases and suggested using additional features like autocorrelation to improve the VAD.\n\nPhD E presented the results of using spectral subtraction and Wiener filtering for noise suppression. The results showed that both methods performed similarly, but the Wiener filter without noise addition gave slightly better results. The team discussed the possibility of using the VAD information as an additional feature in the neural net. PhD B suggested multiplying the output probabilities of the neural net by the silence probability from the VAD and renormalizing them.\n\nIn conclusion, the team is working on developing a unified software for noise suppression and exploring different techniques, such as LDA and additional features, to improve the performance of the neural net. The results of using spectral subtraction and Wiener",
        "In the meeting, PhD C, PhD E, and PhD B discussed the signal to noise ratio and patterns of noise in the recordings. PhD B mentioned that there are many factors to consider when adjusting the signal, such as vocalsound, subtraction, and choice of operating on mel bands or FFT. PhD E mentioned that the Bayes-net deals with inputs by parsing command-line arguments and can be either spectral subtraction or Wiener filtering. PhD C and PhD E also discussed the incorporation of EVA into the Bayes-net and how it can be used to optimize different parameters. PhD A asked about the performance of the Bayes-net and PhD E explained that it is just one percent off the best proposal and that it will be even better once the neural net is added. PhD B mentioned that the Bayes-net did not have explicit noise handling before but now it does. PhD A asked about the neural net and where it would operate, and PhD B explained that it could operate on the output of either the Wiener filtering or the spectral subtraction. They also discussed the latency of the neural net and the importance of having a firm plan before Hynek returns. PhD C mentioned that they are considering improving the noise estimation and the VAD, and PhD E explained that they have been experimenting with different features and training methods for the neural net. PhD D shared their work on using MLPs to detect voice-unvoice and mentioned that the results are similar to the previous system. PhD C suggested trying different inputs for the neural net, such as the log magnitude spectrum. Overall, they discussed various aspects of the signal to noise ratio and noise patterns in the recordings and explored different approaches to improve the system.",
        "In the meeting, PhD C, PhD E, and PhD B discussed the signal to noise ratio and patterns of noise in the recordings. PhD D explained that the neural net targets do not come from forced alignments, but rather from TIMIT canonical mappings and noisy TIMIT data. The discussion also touched on the use of noisy TIMIT data with Italian database noise, as well as the potential incorporation of EVA into the Bayes-net.\n\nPhD D mentioned that they were working on a project for France Telecom and were trying to understand the meaning of certain parameters in the code. PhD E questioned the use of a constant in the expression of lower energy in the code and PhD D expressed confusion about its purpose. PhD C speculated that the constant may have to do with base conversion or hardware limitations.\n\nThe conversation then shifted to the upcoming ICASSP conference and PhD E asked if people were still attending it. PhD C explained that ICASSP is still a relevant conference, especially for engineering students, but that ICSLP and Eurospeech are more targeted for speech processing. PhD E inquired about the timing of the conference and PhD C mentioned that it would take place in the summer.\n\nPhD D shared that they had been working on the France Telecom project and mentioned that Stephane would be arriving soon. PhD C and PhD D discussed the importance of someone from the lab attending ICASSP. PhD E asked if people had stopped attending ICASSP in recent years, to which PhD C responded that people are less consistent about attending, but it is still a valuable conference for students.\n\nThe conversation then shifted to Grad A discussing their progress in getting committee members for their quals and their project on dynamic acoustic events. They explained their plan to test the completeness of a set of dynamic events by training a hybrid system on TIMIT data and evaluating its performance. PhD E asked about the advantage of support vector machines (SVM) for classification, and Grad A explained that SVM can handle less data and still produce good results. They also mentioned their plan to compare SVM with the results from a previous study that used recurrent neural nets.\n\nPhD E asked about the output of Grad A's system and whether it produces a vector of ones and zeros for each phone. Grad A clarified that they are only detecting phonological features and not doing phone recognition. They explained that the SVM system outputs a distance measure, which is then translated into a zero or one for classification.\n\nThe conversation then turned to the differences between PLP and mel cepstrum features and the potential issues with the normalization in the SRI system. PhD E mentioned that they had not had a chance to explore the issue yet, but were checking for bugs in the code and investigating the possibility of differences in the pruning thresholds. They also mentioned the possibility of producing mel cepstrum features with the PLP code to compare directly.\n\nPhD E also mentioned that they had noticed differences in the log likelihoods and pruning rates between the PLP and mel cep",
        "In the meeting, PhD C, PhD E, and PhD B discussed the signal to noise ratio and patterns of noise in the recordings. PhD C mentioned that the error rate for the PZM channel was around 5%, while PhD B mentioned that the error rate for the near field was around 1%. PhD E agreed with these numbers. They also discussed the possibility of using clean training data to improve the error rate.\n\nRegarding the Bayes-net, PhD C suggested incorporating EVA into the Bayes-net to see if it would improve the error rate. PhD B mentioned that they could use the mean subtraction method to deal with additive noise, but they were unsure of how it would affect the log magnitude spectral subtraction.\n\nIn terms of the experiments, PhD A talked about their work on combining LDA with the baseline system and adding on-line normalization. They found that the time constant for on-line normalization needed to be adjusted for better results. PhD D and PhD B discussed their experiments with spectral subtraction from the French Telecom system. They found that it improved the results, but the on-line normalization time constants needed to be retuned. They also mentioned the possibility of combining their approaches.\n\nOverall, the meeting discussed various techniques for improving the signal to noise ratio and patterns of noise in the recordings, as well as the potential incorporation of EVA into the Bayes-net. The experiments showed the potential benefits of combining different speech enhancement techniques.",
        "In the meeting, PhD C, PhD E, and PhD B discussed the signal to noise ratio and patterns of noise in the recordings. They also talked about the implementation of VTS techniques for modeling the transformation between clean and noisy cepstra. PhD C mentioned the issue of downsampling and the need for low-pass filtering before downsampling. They also discussed the length of the filters and the on-line normalization process. The Bayes-net and the suggested incorporation of EVA into the Bayes-net were also mentioned. PhD C mentioned that they would try to coordinate better with the other team and that they were working on implementing the Ericsson code and modifying it for their experiments. PhD D mentioned that they were working on spectral subtraction and would try other types of spectral subtraction. PhD F mentioned that they were meeting with Adam to discuss running recognition on Meeting Recorder digits and that they still needed to get the code from Hynek. They also mentioned the echo cancellation experiment and hoped that Espen would do it. Professor A mentioned the importance of coordinating between the teams and the need for better communication. They also discussed the desire for cleaner close-miked recordings and the use of echo cancellation techniques to remove background speech.",
        "During the meeting, the opinions of PhD C, PhD E, and PhD B on the signal to noise ratio and patterns of noise in the recordings were not explicitly mentioned. However, there was discussion about different experiments and their results related to training and testing on different languages, using different features, and incorporating neural networks.\n\nPhD B mentioned that Mirjam and Shawn were working on training nets to recognize acoustic features and that they were using canonical mappings of phones to acoustic features. PhD A summarized the experiments conducted since the previous week, including training nets with different features and evaluating their performance. The results showed that using delta in the features improved the accuracy, and combining different features did not significantly improve the results. PhD B also mentioned experiments combining different features and MLP outputs, but the results were not mentioned in detail.\n\nThe discussion also touched on the use of on-line normalization and the effect of adding a neural network. It was noted that adding a neural network improved the accuracy, but combining features with MLP outputs did not have a significant impact.\n\nOverall, the meeting provided some insights into the experiments conducted and their results, but did not specifically address the opinions of PhD C, PhD E, and PhD B on the signal to noise ratio and patterns of noise in the recordings. The Bayes-net and the suggested incorporation of EVA into the Bayes-net were not discussed during the meeting.",
        "In the meeting, PhD C, PhD E, and PhD B discussed their opinions on the signal to noise ratio and patterns of noise in the recordings. PhD B stated that they found slightly better results with the new neural net configuration. PhD A agreed and mentioned that using the silence output also improved the results. However, PhD A also mentioned that they had not yet tested the same combination on digits and were unsure of the range of tests that would yield better results. PhD E mentioned that the TIMIT network was the best for the target task, but there were still questions about the language and noise dependencies. PhD A suggested incorporating articulatory targets and using networks that do regression instead of classification. PhD D mentioned the possibility of scaling the variances associated with the streams to effectively change their strength in the Bayes-net. The discussion then shifted to the incorporation of EVA into the Bayes-net, with PhD A suggesting using VAD labels and combining the MLP features with the OGI features. PhD D emphasized the importance of double-checking the results with the OGI features before adding in the MLP features. They also discussed the potential benefits of using LogRASTA filtered features and combining multiple features. PhD A mentioned the need to address CPU and memory issues. The meeting concluded with PhD E mentioning the availability of the Linux machine \"Swede\" for running jobs. Overall, the main focus was on improving the training set and targets, as well as fitting in with the OGI system. There were also discussions about different approaches to handling noise and scaling the variances in the Bayes-net."
    ],
    [
        "During the meeting, the team discussed various topics including politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They mentioned the possibility of having more regular meetings to collect data, as well as the challenges of finding the right participants and ensuring the quality of the data. They also discussed the need for more diverse types of meetings to work with, as well as the potential for summarization and language modeling based on the collected data. The team talked about the difficulties of the current recording setup and the potential for using alternative locations for recording. They also discussed the need for more disk space and the ongoing archiving process. Finally, one team member shared their plans to classify and analyze overlapping speech in the recordings.",
        "In the meeting, the team discussed several topics related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. One topic of discussion was the categorization of instances where one person is speaking and there are other sounds that are not speech. The team debated which category these instances should be placed in and whether they should be included in the data set. The team also discussed the use of different classifiers and models to analyze the collected data, such as neural networks and decision trees. They talked about the importance of selecting the right features and parameters for these models to accurately classify different frames of speech. The team also discussed the potential use of binaural cues and microphone arrays to improve the detection of overlaps and separation of speakers. They considered the limitations and advantages of using different types of microphones and arrays in the data collection process. Finally, the team briefly mentioned the need to sign new forms and discussed the issue of anonymizing the data, including the use of anonymized names in the transcript to maintain privacy and avoid mapping between real names and the anonymized tags. Overall, the meeting covered a range of topics related to data collection, analysis, and privacy considerations.",
        "During the meeting, the team discussed various aspects related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They debated the issue of privacy and the use of real names in the data, as well as the need for anonymization in published reports. The team also discussed the process of data collection and the challenges of tracking discourse and identifying speakers in the transcripts. They considered different approaches to labeling the speakers and discussed the possibility of bleeping out names or using speaker identifiers in the transcript. The team also talked about the need for a consistent licensing policy for the data and the importance of making the data useful for discourse analysis. They touched upon the progress of the digits project and the potential for training a recognizer on the data. Additionally, there was a discussion about the possibility of incorporating articulatory features into the transcription process and the challenges associated with it. The team considered the differences between reading digits and conversational speech in terms of prosody and phonetic variations. They also discussed the importance of having accurate transcriptions that capture reduced pronunciations and the need for intermediate representations between dictionary pronunciations and gestural features. Overall, the meeting covered a wide range of topics related to politics around data collection, transcription, and analysis.",
        "During the meeting, the team discussed several topics related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. One of the topics discussed was the need for better quality close-talking microphones for each speaker. The team agreed that having uniform and high-quality microphones would improve the quality of the recordings and make it easier for transcribers and researchers to work with the data. They also discussed the upcoming NIST visit, where Jonathan Fiscus would be visiting to see the room, the modified multitrans software, the pre-segmentation process, and the transcription conventions. The team also mentioned the ongoing work on improving the pre-segmentation process and the need for better time alignment of overlapping segments. Overall, the team had productive discussions and made plans for future improvements in data collection and analysis.",
        "In the meeting, the team discussed several topics related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They mentioned the use of speech and nonspeech detection on mixed files and the segmentation of speech portions into different channels. They also discussed the potential use of speaker identification and the interest in array microphones for better data collection. The team discussed the possibility of collaborating with John Canny, a CS professor, who is interested in array microphones. They also mentioned a discussion with Birger Kollmeier, a German scientist, who is interested in auditory models and directionality in microphone technology. \n\nThe team also discussed the transcription process and mentioned that they have eight transcribers, with each transcriber assigned their own data set. They mentioned that the transcribers have been able to transcribe about 12 minutes of speech for every 1 minute of real time, and that the pre-segmentation of the data has been helpful in improving the accuracy of the transcriptions. They mentioned a teleconference with Jonathan Fiscus, who expressed interest in the team's data and the ATLAS system for annotated transcription graphs. They discussed the possibility of providing their transcribed meetings to Jonathan for experimentation with the ATLAS system.\n\nThe team also mentioned their collaboration with IBM for transcription services. They mentioned that IBM has a pool of transcribers who are transcribing the data, and that the transcriptions are being done based on chunks of speech rather than fine-grained time markings. They discussed the potential challenges of aligning the transcriptions with the audio data and the need for further discussions with IBM to address these issues. They also mentioned the possibility of using the transcribers for other tasks, such as fine-grained encoding of overlaps in the data.\n\nIn summary, the team discussed various aspects of data collection, transcription, and potential collaborations with other researchers. They mentioned the use of speech and nonspeech detection, the segmentation of speech portions, the interest in array microphones, and the potential use of the ATLAS system for annotated transcription graphs. They also discussed the challenges and potential solutions related to transcription services and the alignment of transcriptions with the audio data.",
        "During the meeting, the team discussed various aspects related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They talked about high level labelings, types of overlaps, and the possibility of doing fine-grained analysis of speech by marking articulatory features. They also discussed the challenges of differentiating between consonants and vowels and the difficulty of classifying certain speech sounds. The team also explored the idea of collecting more meeting data from different sources, such as other departments or external groups, and the potential challenges and benefits of doing so. They discussed the possibility of using pre-processing techniques to improve the signal-to-noise ratio and the need for closer time synchronization in the data. The team also considered the idea of combining different nodes in the Bayes-net to make the decision-making process more efficient and accurate. Overall, the meeting focused on finding ways to improve the data collection and analysis process and enhance the accuracy and usefulness of the Bayes-net.",
        "During the meeting, the team discussed several topics related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They discussed the weighting of decision nodes and how the Bayes-net would be structured to make decisions based on different questions. They also discussed the limitations of having a finite set of constructions and the need for a construction parser to map language onto specific nodes in the Bayes-net. The team also discussed the idea of having a decision tree query to determine the appropriate nodes to look at based on the question being asked. They talked about the importance of communication and coordination within the team and the need to discuss their work with other team members to avoid duplication of efforts. They also discussed potential improvements to the system, such as using recursive filters to reduce latency and implementing spectral subtraction for noise reduction. Overall, the team is focused on improving the system's performance and making it more efficient.",
        "During the meeting, the team discussed several topics including politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. \n\nIn regards to the politics around collected data, there was a discussion about the estimate of noise spectrum and how it can vary depending on the signal level and noise level. The team talked about different methods for estimating the noise spectrum, such as using a histogram of energy levels or determining the spectrum during silence portions. They also discussed the challenges of estimating noise spectrum for non-stationary noise.\n\nIn terms of the routine for data collection, the team discussed the use of running estimates for noise spectrum and the use of different windows and forgetting factors. They also talked about the importance of having long windows to get a decent estimate of the noise spectrum.\n\nRegarding the structure of the Bayes-net, the team discussed the use of logistic regressions as low-level detectors and the use of EM algorithm to train the parameters. They also talked about the idea of having different means for silence and speech portions and using on-line normalization with different time constants.\n\nLastly, the team discussed the interaction of data participants with their data, specifically in the context of speech recognition. They discussed the use of on-line normalization techniques and the effect of adding white noise to the signal to improve the smoothness of the cepstral coefficients.\n\nOverall, the team had a thorough discussion about these topics and explored different approaches and techniques to address them.",
        "During the meeting, the team discussed various topics related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. \n\nOne of the discussions focused on combining two different streams of features to gain something. They also talked about the adaptability of the data collection routine and the threshold for adding noise to the data. They discussed how the noise level is determined and the impact of adding noise to the mel filter bank. \n\nThe team also discussed the structure of the Bayes-net and the differences between the LDA filters used in the system. They found that using clean speech-derived LDA filters improved the recognition rate on noisy speech. \n\nThey also discussed the standardization of the system and the need to pick one method for noise suppression. They considered using the same system as proposed to Aurora and standardizing the number of cepstral coefficients used. \n\nThe team also discussed the use of VTS (Vectorial Taylor Series) for noise removal and the challenges in estimating the noise PDF. They talked about using a codebook for clean speech and the need to calculate the mean and variance for each Gaussian in the codebook. \n\nOverall, the team discussed various aspects related to politics around collected data, the routine for data collection, the structure of the Bayes-net, and the interaction of data participants with their data. They explored different methods for noise suppression and discussed the challenges and potential improvements in the system."
    ],
    [
        "During the meeting, the group discussed various topics related to the use of English in the discussion about IBM computers and data collection participants. They talked about the agenda items, including the ARPA demo, IBM transcription status, SmartKom data, reorganization status, Absinthe, segmentation and recognition, and the collection of digits. \n\nThe group agreed that the IBM transcription should be included in the corpus, but they also discussed the possibility of using automated methods for finding where the participants read the digits. They considered letting IBM transcribe the data, hiring transcribers, or using the tools developed by the group. The professor raised the question of whether forced alignment or recognition should be used, and they discussed the potential issues with both options. \n\nThe group also discussed the SmartKom data and whether it should be included in the corpus. They debated whether it should be treated as a separate type of interaction or folded into the existing procedures. The issue of disk space and backup capacity was also raised, and they talked about the possibility of using CD-ROMs or DVDs for archiving data. They agreed that the tape system was more reliable for archiving, but the CD-ROMs could be used for normal access. \n\nOverall, the group had a thorough discussion about the changes needed in the use of English in the discussion about IBM computers and data collection participants. They considered different options, raised concerns, and made decisions based on the information presented.",
        "During the meeting, the group discussed the need for changes regarding the use of English in the discussion about IBM computers and data collection participants. The group and the professor agreed that there should be improvements in the use of English during the discussions. They discussed the issue of long backup times for the nightly backups and proposed a solution of buying high-density tape drives and doing their own backups. They also discussed the possibility of using non-backed-up disks for data storage and using an automatic robot tape drive for restoring the data. The group also discussed the need for better communication between the team members and the backup system team to avoid interfering with the backup schedule. They also discussed the possibility of automating the backup process using scripts. The group also discussed the issues with the SRI recognition experiments, including differences in error rates between males and females and the impact of vocal tract length normalization. They discussed the need for further experimentation and cross-validation to determine the best approach. They also discussed the issue of pruning and the determination of when to stop iterating during training. The group also discussed the upcoming NIST visit and the topics that will be covered, including the demonstration of the modified multitrans system and the pre-segmentation process. They also discussed the possibility of getting better quality close-talking microphones for improved speech recognition. The group agreed that uniformity in microphone usage would be beneficial. They also discussed the possibility of using array microphones and the interest of a German scientist in directionality and location in speech recognition. The group also mentioned the possibility of constructing a map of where people were sitting during the discussions based on the microphone signals.",
        "In the meeting, the group discussed the use of English in the discussion about IBM computers and data collection participants. There were several changes needed according to the group and the Professor's opinion. One change discussed was the need for better microphone placement and normalization in order to accurately determine who is speaking and their proximity to others. This would help in analyzing the discussion and understanding the dynamics between participants. Another change suggested was the use of microphone arrays, which can cut out background noise and improve the quality of the recordings. However, the Professor mentioned that the focus of their research was on impromptu situations, so using microphone arrays might not be practical for their purposes. \n\nThe group also discussed the interest expressed by Jonathan Fiscus in using microphone arrays for his research. The Professor mentioned that they could potentially collaborate with him and provide their data for his experiments. However, it was noted that there might be some challenges in aligning the data and ensuring consistency in the encoding. \n\nIn terms of transcription, the group mentioned that they have a team of transcribers working on the data. The transcribers were given individual data sets and have already finished transcribing some of the meetings. The transcriptions are being edited for word level accuracy and speaker changes. The transcriptions are also being used for forced alignment and analysis. It was noted that the transcribers are currently using the mixed signal for their transcriptions, but there might be some issues with accurately determining the timing of words in the absence of time marks. \n\nThe group also discussed the involvement of IBM in the transcription process. It was mentioned that IBM has hired a team of transcribers to work on the data for their speech recognition products. The transcribers are not court reporters but are more like secretarial staff. It was noted that IBM's transcriptions might not have as fine-grained time information as desired, and further discussions with IBM are needed to clarify this. \n\nThe group also discussed the possibility of using the transcribers for other tasks, such as encoding overlaps and fine-grained analysis of speech. It was suggested that the transcribers could be trained to mark specific articulatory features or gestures in the speech. This would provide additional data for statistical modeling and allow for a more detailed analysis of the discussion. \n\nOverall, the group recognized the importance of accurate transcriptions and the need for further collaboration and discussions with IBM and other researchers. They also discussed the challenges and potential solutions for improving the use of English in the discussion about IBM computers and data collection participants.",
        "According to the group and the professor's opinion, the changes needed in the discussion about IBM computers and data collection participants include: \n1. The use of English in the discussion needs to be considered, and the group suggests bringing in John Ohala to get his views on it.\n2. The purpose of using English in the discussion should be clarified, whether it is for post-meeting data analysis or for studying natural language production in meetings.\n3. The group and the professor believe that meetings are a valuable source of natural language data, and expanding the annotation choices in the corpus could make it even more useful.\n4. The group discusses the possibility of collecting more meetings, including those from different departments or non-academic groups, to increase the variety of data.\n5. The professor suggests reaching out to Chuck Fillmore and other departments in the building to find groups that might be willing to participate in the discussion.\n6. The group also discusses the need for improvements in signal processing techniques, such as separating speakers and improving signal-to-noise ratio, to enhance the accuracy of transcription and analysis.\n7. The group mentions the possibility of using the Transcriber program to mark different situations during transcription and the need for flexibility in alignment to handle variations in speech.\n8. The professor suggests exploring the possibility of showing additional signals, such as prosodic features, in the Transcriber interface to enhance the analysis and understanding of the discussions.\n9. The group discusses the current status of transcription, including the progress made by Jane in transcribing ICSI meetings and the upcoming transcription from IBM.\n10. The group also discusses the need for participant approval and the plan to send transcripts and audio recordings to participants for review and feedback.\n11. The group mentions the status of the DARPA demo and the progress made in the back-end system, but acknowledges the need for further development in the front-end system.\n12. The group discusses the disk issues and the need for additional storage space for expanded meetings and transcriptions. Suggestions include using the recently acquired SUN-Blades and other available resources to increase storage capacity.\n13. The group acknowledges the need for a long-term solution, such as a second file server or additional disk racks, to address the ongoing storage requirements.",
        "According to the group and the professor's opinion, there were several changes needed in the use of English in the discussion about IBM computers and data collection participants. First, the group discussed the need for more disk space as they were running out of storage for the data they were collecting. They discussed the possibility of adding more disks to the machine room and finding a solution to the limited space issue.\n\nIn terms of the data collection itself, there was a discussion about the type of meetings they should focus on. The group agreed that it would be beneficial to have a variety of meetings from different domains, as it would allow for more diverse research and analysis. They discussed the idea of regular meetings, such as the front-end meeting and networking group meeting, where they could collect data consistently and analyze the patterns and interactions within those meetings. They also mentioned the importance of having a sufficient number of meetings from the same group to be able to compare and analyze the data effectively.\n\nThe group also discussed the possibility of conducting research on the collected data, particularly in the area of summarization and identifying key points in the meetings. They mentioned the need for data with similar parameters, such as meetings with similar participants or meetings focused on similar topics, to be able to draw meaningful conclusions and insights from the analysis.\n\nAdditionally, the professor mentioned the need for more diverse speakers in the data collection. While having consistent meetings with the same group was important for certain research purposes, the professor emphasized the value of having random and scattered meetings with different speakers to capture a wider range of acoustic data and speech patterns.\n\nOverall, the changes needed according to the group and the professor's opinion included finding solutions for storage space, focusing on a variety of meetings from different domains, conducting research on the collected data, and ensuring a diverse range of speakers in the data collection process.",
        "According to the group and the professor's opinion, the changes needed in the discussion about IBM computers and data collection participants include:\n1. Instead of randomly selecting undergraduates, it was suggested to have pre-existing meetings with professors and doctoral students who are leading projects.\n2. The use of English in the discussion was important, but the focus was on fluency and proficiency rather than accents.\n3. It was mentioned that the corpus of data collected should be used for multiple purposes, such as language models and probabilistic grammars.\n4. There was a discussion about the need for a portable recording setup and the possibility of using a room in the linguistics department or another building on campus.\n5. The group discussed the need for more disk space to record meetings and the plan to acquire more disks in the future.\n6. The professor and the group were interested in having volunteers from outside of linguistics and engineering to participate in the discussions.\n7. There was a discussion about the classification of overlapping speech and the need for a control set to evaluate the tools being developed.\n8. The group discussed the importance of having accurate labeling and the use of clustering algorithms to classify different speech and overlapping speech segments.\n9. The professor and the group expressed their support for the research being conducted and the need for further testing and evaluation of the tools being developed.",
        "Based on the given meeting, the changes needed according to the group and the Professor's opinion on the use of English in the discussion about IBM computers and data collection participants are as follows:\n\n1. The group discussed the use of English in the discussion and mentioned that it is important to have clear communication and understanding among the participants. They emphasized the need to use English effectively to convey their ideas and opinions.\n\n2. The group talked about the different approaches to data collection and analysis, specifically focusing on the use of clustering algorithms and neural networks. They discussed the advantages and limitations of each approach and the need to understand the internal workings of the neural network.\n\n3. The Professor emphasized the importance of sensitivity analysis in understanding the importance of different input variables. He also suggested using simpler models, such as decision trees, to analyze the data before using more complex classifiers.\n\n4. The group discussed the challenges of using neural networks and other models to analyze speech data, especially in the case of overlapping speech. They discussed the need to consider the temporal properties of the data and suggested using features based on larger chunks of time, such as context windows or Markov models.\n\n5. The group also discussed the use of different parameters, such as MFCC and LPC, in analyzing the speech data. They discussed the importance of selecting the most relevant features and visualizing the data to gain insights into the separation of different classes.\n\n6. The group talked about the challenges of detecting overlaps in speech data and the need to develop models that can accurately detect and classify overlapping zones. They discussed the use of different classifiers and models to achieve this objective.\n\n7. The group also discussed the possibility of using microphone arrays and beamforming techniques to improve the detection of speaker overlaps. They discussed the advantages and limitations of these techniques and the need for further research in this area.\n\n8. The group discussed the need for anonymizing the data and the challenges of maintaining privacy while analyzing the speech data. They discussed the possibility of using anonymized names in the transcripts and the importance of ensuring that the transcript and audio data are consistent.\n\nIn conclusion, the group and the Professor identified several changes and considerations related to the use of English in the discussion about IBM computers and data collection participants. These changes include the need for clear communication, the selection of appropriate models and features, the analysis of temporal properties, the detection and classification of speaker overlaps, the use of microphone arrays, and the anonymization of data.",
        "During the meeting, the group discussed the changes needed in the use of English in the discussion about IBM computers and data collection participants. One suggestion was to label the speakers in the discussion to make it more efficient for discourse tracking. However, this raised concerns about privacy and the need for a consistent licensing policy. The group also discussed the use of English in the context of IBM computers and data collection participants, and the professor emphasized the importance of communication and coordination between team members. \n\nIn terms of the changes needed, the group mentioned the need for better filters to reduce latency in the system. They discussed using recursive filters instead of FIR filters to achieve shorter delays. They also mentioned the need for better discourse tracking and identification of speakers in the discussion. The group discussed different approaches, such as anonymizing the speakers by not using their names or using labels like \"speaker-1\" instead of names. They also discussed the use of different norms and contextual explanations to improve discourse tracking.\n\nThe group also discussed the use of English in the discussion about IBM computers and data collection participants. They mentioned the importance of considering the needs of non-English speaking countries and the flexibility of people in understanding and adapting to different norms. They also discussed the challenges of anonymizing the discussion while still maintaining its usefulness for discourse analysis.\n\nOverall, the group emphasized the need for further discussion and decision-making regarding the changes needed in the use of English in the discussion about IBM computers and data collection participants. They mentioned the importance of considering privacy, licensing policies, and the impact on discourse analysis. They also discussed potential solutions, such as improved filters, better discourse tracking methods, and the use of contextual explanations.",
        "During the meeting, the group discussed the changes needed regarding the use of English in the discussion about IBM computers and data collection participants. The group and the professor agreed that there were a few key changes that needed to be made. Firstly, they discussed the need for more thorough transcription of the meeting data, as some parts were unclear or difficult to understand. They also mentioned the importance of having clear and accurate targets for the detectors used in the discussion. They discussed different low-level detectors that could be used, such as logistic regressions, and the need for multiple detectors for different phonetic features. The professor expressed his opinion on the use of narrow-band information and smooth spectral envelopes for speech recognition, and the need to train the detectors for a product of errors rule. They also discussed the possibility of using echo cancellation techniques and multiple microphones for better data collection. Overall, the group and the professor agreed that further discussions and research were needed to improve the use of English in the discussion about IBM computers and data collection participants.",
        "During the meeting, the group discussed various topics related to the use of English in the discussion about IBM computers and data collection participants. One of the changes suggested by the group was to have a paper trail or electronic trail for legal purposes. The Professor suggested sending emails and following up with phone calls to ensure that participants have received and acknowledged the information. The group also discussed the psychological effect of responding to emails and how it increases the likelihood of participants actually following through with their commitments. They also mentioned that participants would appreciate the follow-up emails and that it would foster goodwill among them. The Professor also emphasized the importance of considering worst-case scenarios and being prepared for potential problems with server issues or missed communications. The group concluded that email communication would be sufficient and that there was no need for signatures or notarization. The meeting then shifted to discussing the need for additional disk space and the possibility of ordering more hard drives. They also briefly discussed the transcription process and the need for better headphones. The meeting ended with a discussion about an upcoming phone call with Mari and the need to prepare an annual report. Overall, the group identified the changes needed in terms of communication and resources, and the Professor provided guidance and updates on various topics."
    ],
    [
        "During the meeting, the topic of the segmenter was discussed. It was mentioned that Thilo's segmenter is working well and there was a suggestion to re-evaluate the recognition results using the segmenter. It was also mentioned that the segmenter could be used to train the speech detector. The issue of adding SmartKom data to the Meeting Recorder corpus was also brought up. It was discussed whether this data should be considered part of the corpus or not, and it was decided that it should be kept separate but still use the same infrastructure. The issue of disk space and backup capacity was also mentioned, with the suggestion to use tape for archiving and having a separate file server for heavily accessed data. The question of consent issues and transcription was raised, and it was clarified that transcription is done in Munich. The idea of archiving the data on CD-ROM or DVD was brought up, but it was mentioned that these media can degrade over time. It was decided that tape would be a more reliable option for archiving. Overall, the decision was to keep the SmartKom data separate but still use the same tools and conventions as the Meeting Recorder corpus.",
        "During the meeting, there were discussions about the current status and recent changes to the segmenter. One of the main topics was the backup system and the need for faster nightly backups. It was suggested to buy high-density tape drives and store data on non-backed-up disks to reduce the burden on the backup system. The possibility of using the current tape drive was also discussed, but it was uncertain if it would interfere with the backup schedule. Another topic was the recognition experiments, specifically the difference in error rates between males and females. It was noted that the error rate was slightly higher for females and that further testing with a larger training set was needed. The meeting also touched on the topic of the transcription effort and the use of features for speech and nonspeech detection. The team discussed the use of a mixed file and the addition of multiple Gaussian mixtures for speech and nonspeech. The results of the transcription effort were positive, with the transcribers finding it to be a significant improvement. The meeting also covered the issue of representing overlaps in the transcription and the possibility of using existing tools or modifying the current interface. It was mentioned that a musical score notation might be the ideal representation for overlaps. Finally, there was a brief discussion about the future of the project and the need for transcribing data. It was mentioned that outside sponsors might provide funding for the project, reducing the need for extensive transcribing. Overall, the meeting provided updates on various topics and discussed possible solutions to improve the segmenter and transcription efforts.",
        "Based on the meeting, the current status of the segmenter is that there have been recent discussions about the need for transcription and the potential use of IBM transcripts for checking and augmenting the segmenter. It was mentioned that a postdoc named Dave Gelbart volunteered to modify the Transcriber tool to improve the segmenter's performance. The meeting also discussed the possibility of using amplitude and energy levels to separate different speakers and improve the accuracy of the segmenter. The transcribers who have been working on the project were praised for their perceptive and quick work, and it was suggested that they could be used for a more detailed analysis of overlaps in the recordings. The meeting also touched on the issue of microphone placement and how it can affect the quality of the recordings. It was mentioned that laughter and breath sounds should be marked in the transcripts and could be used to train models for these types of speech. There was also discussion about the potential for higher-order organization within the meetings and whether a manifest or outline of the topics covered could be created. It was suggested that more analysis is needed to improve the segmenter's performance, including exploring pitch-related and harmonicity-related features, as well as considering a different approach of using statistical modeling to determine overlaps.",
        "During the meeting, there was a discussion about the current status and recent changes to the segmenter. The team mentioned that Javier's system, which focuses on silences, already exists but has limitations. They discussed the possibility of using a new class, in addition to nonspeech and speech, to divide speech into overlapping and non-overlapping segments. They also mentioned the potential of using the BIC criterion and Gaussian training to distinguish between overlapping and speech zones. The team considered using Javier's software for this purpose and discussed the need for a second step in the clustering process. They also mentioned the possibility of using pitch tracking and the need to evaluate Javier's speech segmenter. \n\nIn terms of the current status, the team mentioned that they are almost done with the TI-digits dataset and will be able to train a recognizer soon. They also discussed the need to extract the actual digits from the dataset and enter the relevant information into the computer. They mentioned the possibility of doing some modeling of articulatory features with overlap on a subset of the conversational speech or digit dataset. The team also discussed the challenges of annotating and marking gestural features and the need for intermediate levels of representation. They considered the idea of starting with automatic systems and then having people go through and fix the annotations. \n\nOverall, the team discussed different approaches and considerations for the segmenter and mentioned the need for further exploration and evaluation. They also discussed the progress made on the TI-digits dataset and the potential for future research on modeling articulatory features.",
        "In the meeting, the current status and recent changes to the segmenter were discussed. It was mentioned that there are some problems with the lapel microphone and some specific issues with normalization and channel problems. The system is being retrained and new filters are being designed to reduce latency. The idea of using spectral subtraction and changing the contextual KLT for LDA was also discussed. It was mentioned that there may be a need for a third-party VAD and there was a discussion about the trade-off between latency and performance. Overall, there are ongoing efforts to improve the segmenter and address the issues that have been identified.",
        "During the meeting, the transcription status was discussed, and it was mentioned that several transcribers were hired and making good progress. Some of the transcriptions have been processed and sent to IBM. The DARPA demos were also discussed, with the front-end and back-end tools being mentioned. The front-end tool is a user interface, while the back-end tool is used for indexing and querying. The front-end tool is being modified to work with meeting data and will allow users to type in a query and receive a list of hits. The user interface will be based on a Tcl-TK GUI front-end. The meeting also discussed the possibility of porting the tools to Windows. The transcription status and DARPA demos were the main topics of the meeting.",
        "In the meeting, the current status of the segmenter was not discussed. The meeting mainly focused on issues related to playing sound files between two platforms and the possibility of merging Transcriber and THISL IR. It was mentioned that Dave Gelbart, who has experience with Transcriber, will be working on the segmenter. There was also discussion about using Snack and the Windows media player for the segmenter. The meeting touched on the idea of having running transcripts and the difficulty of implementing this feature. There was also discussion about the compatibility of PowerPoint shows on free BSD. It was mentioned that the Gnu compatibility library can be used to port the segmenter to any system. The meeting also discussed the possibility of showing prosody features and the process of finding sentence and turn boundaries graphically. The meeting briefly touched on XML tools and the need to improve the current transcription format. There was mention of ordering more wireless equipment for the project. The meeting also discussed the use of CrossPads and the challenges of synchronizing them with the recording. It was suggested that using PDAs with wireless cards might be a better solution. The meeting also touched on the idea of having a scribe take notes during the meeting using the CrossPad or another method. There was discussion about the data collection process and the tasks that participants will be asked to perform. The meeting also discussed the semantics of the belief-net and the decisions that need to be made in the system. It was mentioned that subjects will be recording dialogues with the system, and their phrasing and choices will provide valuable data for the project. The meeting also discussed the need for a room for the data collection sessions.",
        "During the meeting, the topic of the current status and any recent changes to the segmenter was briefly discussed. It was mentioned that the segmenter is part of a larger system that includes the zoo, university, castle, and other attractions. The system is designed to handle different parts of these attractions and allow users to select their preferences. The speech data gathered from users visiting these attractions is used to improve the system. There was also discussion about the level of complexity and variation in the data and how it can be handled. It was suggested to start with a simpler approach and then make adjustments based on the results. The meeting also touched on the importance of understanding the goals and expectations of the system and the need to gather enough data to cover a range of scenarios. The meeting concluded with plans for future actions, including data collection, building a belief-net, and defining the ontology."
    ],
    [
        "During the team's discussion on support vector machines, controlling the size of combinatorial input, and volume variation, several points were brought up. Firstly, there was a discussion on the transcription effort and the use of microphones. It was mentioned that the current transcription system uses an HMM-based system with Gaussian mixtures for speech and nonspeech, and there have been improvements made in the nonspeech-speech pre-segmenting of the signal. The team also discussed the need for a tool that can accurately represent overlaps in the transcriptions, such as a musical score notation. It was mentioned that there is a tool developed by Susanne Burger at CMU that can handle eight channels simultaneously, but it runs on Windows. The team also discussed the possibility of using the Praat software for transcription, which is multi-platform. \n\nThere was a suggestion to contact Brian, who is involved with the SRI recognizer, to discuss transcription standards and training models for breath and laughter. It was mentioned that laughter and breath could be treated as special words with dedicated phones in the recognition system. The team also discussed the importance of microphone placement and wearing the microphone correctly to reduce breathing noise. It was suggested to have people move the microphone slightly away from the center of their mouth and to wear it close enough to get good volume. \n\nOverall, the team had a thorough discussion on the transcription process, microphone issues, and the representation of overlaps in the transcriptions. They also discussed the possibility of using existing tools or developing new tools to improve the transcription process.",
        "During the team's discussion on support vector machines, controlling the size of combinatorial input, and volume variation, several experiments and findings were presented. \n\nFirstly, the team conducted experiments using different features and neural networks trained on various datasets. They found that using delta in the features improved performance compared to not using delta. Additionally, training on TIMIT for English produced better results compared to training on other languages. \n\nThe team also performed cross-language experiments, training on one language and testing on another. The results showed that training on English only yielded better results compared to training on French or Spanish. \n\nFurthermore, the team worked on a large database containing sentences from different languages and tested various combinations of features and neural network outputs. They found that combining PLP and MSG (Mel Spectral Cepstral Coefficients) did not significantly improve performance compared to using PLP alone. \n\nAdditionally, the team explored feature combination experiments, including combining different feature streams and using KLT (Karhunen-Loeve Transform) transformed MLP outputs. The results showed that combining features and neural network outputs together improved performance. \n\nFinally, the team discussed the possibility of using Javier's software, which uses BIC criterion and Gaussian models, to distinguish overlapping and non-overlapping zones. They also discussed the importance of using delta-delta and the limitations of the MSG feature. \n\nIn summary, the team conducted experiments using different features and neural networks, cross-language experiments, feature combination experiments, and explored the possibility of using Javier's software. The results showed that using delta in the features and combining features and neural network outputs improved performance. However, the MSG feature did not significantly improve performance.",
        "During the meeting, the team discussed several topics including support vector machines, controlling the size of combinatorial input, and volume variation. They found that adding MSG did not improve results, and the multi-English training performed better than other conditions. They also observed that the MLP alone did not improve accuracy, and that the TIMIT network was the best for the target task. However, they were unsure of the language dependency and the noise dependency in their results. They discussed the possibility of using different training targets such as articulatory targets or regression instead of classification. They also mentioned the need to address CPU and memory issues and to connect their system to the OGI system. They planned to double-check their results with the OGI features and VAD labels before adding additional paths to the system. They also discussed the possibility of using LogRASTA filtered features and combining multiple features to improve results. Overall, they had some unanswered questions and planned to conduct further experiments to address them.",
        "During the meeting, the team discussed various topics including support vector machines, controlling the size of combinatorial input, and volume variation. They mentioned trying different things and exploring different training targets and data. The team also discussed the potential for using different temporal properties and the need to cut down on the number of experiments. Additionally, they talked about the possibility of using the Swede machine for running jobs and the challenges they faced with disk and CPU resources. They also mentioned their work on a multi-band belief-net structure and the idea of coupling HMMs. In terms of support vector machines, they discussed the issues with noise estimation and the need to train the tandem network on more data. The team also mentioned their efforts to evaluate the system's performance compared to human performance, but there were some limitations in the evaluation process. Furthermore, they talked about the progress on the Wall Street Journal task and the need for a multi-CPU version of the scripts. They mentioned the error rates achieved by the Mississippi State system and the discussions around word insertion penalties. The team also considered scaling the features and simulating the back-end to determine the best scaling factor.",
        "In the team's discussion on support vector machines, controlling the size of combinatorial input, and volume variation, they talked about a Gaussian mixture model system that is similar to HTK. They discussed the mix-down procedure used in the system and the type of tying used. They also talked about a paper on histogram equalization and its potential use in speech recognition. The team also discussed the work of Michael Kleinschmidt, a PhD student from Germany, who is using an auditory model to generate speech recognition features. They discussed the idea of using neural nets to learn patterns in hidden units and using these patterns to determine intermediate categories. They also discussed the possibility of using a graphical model to learn about intermediate categories. They mentioned a conference call where they discussed the weighting of error rates and the need for consistent weighting across different languages and conditions. They also mentioned experiments on reducing the number of iterations in training and the compilation of HTK for Linux machines. Finally, they discussed the possibility of increasing the number of mixtures in the model and the need for consistent weighting of error rates.",
        "During the meeting, the team discussed support vector machines, controlling the size of combinatorial input, and volume variation. They talked about the hope that support vector machines would work well for good cases and have reasonable degradation for worse conditions. They also discussed the idea of weighting different conditions depending on the environment the system is being used in. The team debated whether to rely on a single number or have multiple numbers to evaluate the system's performance. They also discussed the possibility of using a voice activity detector (VAD) as a baseline and the potential improvement it could bring. They mentioned experiments using spectral subtraction, on-line normalization, and a new filter for downsampling and upsampling. The team also mentioned testing the use of neural networks in the KLT and the impact it had on performance. They discussed the idea of using features for voicing detection and the potential benefits it could bring to the system. They mentioned using statistical measures of the difference between the raw data and the smoothed version to capture information about the excitation signal. They also discussed the use of mel cepstrum and FFT to characterize the difference between the smoothed and raw data. The team mentioned that the differences between the two representations could provide useful information for robust feature extraction. They discussed the periodicity and pitch characteristics of the excitation signal and the potential for using these features to improve recognition. Overall, the team explored different approaches and discussed the potential benefits and drawbacks of each method.",
        "In the meeting, the team discussed several topics including support vector machines, controlling the size of combinatorial input, and volume variation. They also discussed the use of vocalsound and long frames in their work. They talked about the potential challenges of using FFT bins or mel spectrum in spectral subtraction. The team also discussed the possibility of using Avendano's method for transforming long analysis frames to short analysis frames for feature calculation. They considered the implications of this approach on the feature computation process. They also discussed the upcoming deadlines for their projects and the need for a standard source. The team also discussed the need for more female voices in their recordings and the potential for foreign voices in the future. They discussed the progress on their individual tasks and the reorganization of files and directories. They also discussed the transcription process and the use of IBM for transcription services. The team considered the possibility of using forced alignment for transcribing digits and the potential for using the SRI system for recognition experiments. They also discussed the importance of modulation spectrum in speech recognition and the use of MSG features. The team discussed the potential benefits of using Thilo's segmenter for recognition experiments and the possibility of using recognition alignments to train a speech detector. They also discussed the collection of dialogues for the SmartKom project and the decision to include them in the corpus. They debated whether to handle the SmartKom data as a special case or fold it into the existing infrastructure. The team also discussed the possibility of using the SmartKom data for acoustic studies. Overall, the team had a thorough discussion on various topics related to support vector machines, combinatorial input, and volume variation.",
        "During the meeting, the team discussed several topics including support vector machines, controlling the size of combinatorial input, and volume variation. They also talked about storing and organizing data, transcription, and the use of different media for archiving. In terms of support vector machines, they mentioned the use of different procedures and the need for a separate procedure for reading digits. They also discussed the consent issues and the use of transcription conventions. They talked about the volume variation in different datasets and the need for more disk space. The team also discussed the possibility of using different types of media for archiving, such as CD-ROM or tape, and the potential risks and benefits of each. They also mentioned the use of different types of features and models for recognition experiments and the challenges in achieving consistent results. They discussed the use of boot models and the impact of different feature sets on the quality of the final models. The team also briefly discussed the upcoming meeting and the agenda items, including the need for better quality close-talking microphones and the progress on speech and non-speech segmentation. Overall, the team had thorough discussions on various topics related to support vector machines, data storage, transcription, and recognition experiments.",
        "During the meeting, the team discussed the use of close talking microphones for capturing signals in meetings. They also talked about the possibility of using microphone arrays to improve the quality of recordings. The team discussed the challenges and benefits of using microphone arrays and the need for standardization of the microphones used. They also discussed the importance of controlling the size of combinatorial input and volume variation in the recordings. The team also discussed the progress of the transcriptions and the use of the ATLAS system for analyzing the transcriptions. They mentioned the need for reliability in the transcriptions and the potential for collaboration with other organizations interested in meeting data. Overall, the team had a productive discussion on the topics of support vector machines, controlling the size of combinatorial input, and volume variation.",
        "During the meeting, the team discussed support vector machines, controlling the size of combinatorial input, and volume variation. They mentioned that they haven't tried both ways to determine the answer yet. The team also discussed the use of mixed signals and how it is mostly used by the transcribers. They mentioned that if there is a large disparity in volume on the mix, the transcribers might not be able to catch anything except the prominent channel. They also discussed the possibility of having fine time markings and how it might change the way the transcribers work. They mentioned that it is hard to follow one channel of a conversation, especially if it involves highly abstract network concepts that they have never heard of before. The team also discussed the issue of transcribing the network group talk and how one of the transcribers had difficulty understanding some of the abbreviations used in the conversation. They also mentioned the benefit of having Brian involved in the transcription process due to his knowledge of how the data needs to be used. The team also discussed the historical decision to have IBM transcribe the meetings and the possibility of ramping up to do it themselves. They mentioned that IBM volunteered to do it and it was a contribution they could make in terms of time and money. They also discussed the possibility of doing forced alignment before chopping up the meetings into smaller segments. They mentioned that without time markings, they don't know where the words belong in the segments and it is a problem they need to address. They also discussed the issue of transcribing meetings with heavy accents and the effort that is going into transcribing the meetings. They mentioned the possibility of having IBM do an initial forced alignment and the need to have further discussions with them about it. The team also discussed the importance of having fine-grained time markings and the need for pre-segmentation before doing forced alignment. They mentioned the difficulty of knowing which words belong to which segment without time markings. They also discussed the possibility of having pre-segmentation for the first transcribed meeting and the challenge of normalizing the front-end. The team also discussed the possibility of having transcribers do other things like dialogue act tagging and disfluency tagging. They mentioned the value of having more data to try alignments on and the need to have a reference of which words belong to which segment. They also discussed the issue of controlling the size of combinatorial input and the need to chop things up into smaller pieces. They mentioned the challenge of dealing with cross-talk and the importance of having short segments for recognition, especially for forced alignment. They also discussed the issue of not knowing where the words belong without time markings and the need for a reference. The team also discussed the possibility of having transcribers do other tasks like marking overlapping segments and encoding articulatory features. They mentioned the value of having a corpus of natural conversations and the potential use of expanded annotation choices. They also discussed the possibility of collecting more meetings and the importance of having meetings with heated discussions"
    ]
]