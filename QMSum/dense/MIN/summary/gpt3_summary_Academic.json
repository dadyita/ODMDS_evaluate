[
    "In a meeting, the participants discussed XML tools, data quality, and the current XML format used to link different components in data. Stephane mentioned his work on online normalization and experimenting with different approaches and the use of two means for silence and speech. Barry discussed his work on preparing for quals and conducting cheating experiments. Dave talked about his work on phase normalization and collaboration with Andreas and Thilo on the SmartKom system. Morgan mentioned his focus on Meeting Recorder. Dick discussed his experiments with phase normalization and challenges faced with unwrapping the phase.\n\nDuring the discussion, D talked about implementing Wiener filtering for an Aurora task but encountered worse results when running the whole recognition experiment with Italian. They mentioned the possibility of a bug. E discussed their work with VTS to remove noise and the need for VAD and LDA to improve results. They also discussed the use of a codebook and the estimation of clean speech given noisy speech. The professor asked about the adequacy of using mean and variance to characterize noise and the complexity of higher-order Taylor series expansions.\n\nOverall, the meeting provided insights into the ongoing work and opinions of the participants on XML tools, data quality, and the current XML format.",
    "During the meeting, the participants discussed the topic of electronics, specifically wireless microphones and their proper usage. They also emphasized the importance of signing consent and speaker forms. The discussion also revolved around the process of reading digit strings and the need for individuals to state which transcript they are on during the reading.\n\nThe topic of intentionality was brought up, focusing on differentiating between different intentions such as viewing, entering, or touching a certain object. The participants discussed the challenges of determining intention from language and discourse and the potential use of a belief-net to infer intention. They highlighted the need for contextual information such as the type of object, time of day, and situational and discourse context.\n\nThe meeting also addressed the segment they were working on and their current goal of solving problems related to it. They mentioned using a small room to record subjects for their experiments and discussed the intentionality of the experimental subjects. They acknowledged the need to collect data to determine the intentions of the subjects and mentioned that the current data did not differentiate between different intentions or tasks.\n\nThe participants talked about the possibility of using a belief-net package to analyze the collected data and extract features that can help determine the intentions of the subjects. They emphasized the need for a clear plan and time frame for the project, including converting the system to English and merging it with belief-net analysis. The use of XML files for data collection and analysis was also mentioned.\n\nOverall, the meeting focused on the discussion of electronics, specifically wireless microphones, the segment they were working on, the results from their experiments, and the topic of intentionality. They concluded the meeting with the idea of building a belief-net to determine intention and the need for further exploration of the factors involved in this task.",
    "The main thesis of the discussion was to explore ways to improve the accuracy of transcriptions in meetings. The professor and the participants discussed the need for better quality microphones and standardization of microphone types to capture the best audio signal. They also mentioned the potential collaboration with NIST on recording and transcription methods. The discussion touched on the use of the ATLAS system for transcription and the possibility of sharing data with NIST for further experimentation. The professor expressed interest in video recordings of the meetings but acknowledged the challenges of human subjects' consent and infrastructure. The progress of transcription work was discussed, with the professor emphasizing the importance of reliability and consistent encoding conventions. Potential collaborations with other researchers and institutions were also mentioned. In terms of the 12-second mean, there was a discussion about the need to check and adjust the mean for each person before combining them. Possible hypotheses were discussed, including the difficulty of following one channel of conversation and the importance of time markings for forced alignment. In concluding comments, it was mentioned that some questions raised remain unanswered and further discussions with the transcription team are desired. Future work includes collecting more meeting data from different groups, utilizing transcribers for tasks like dialogue act tagging, and using signal processing techniques to improve accuracy. Overall, the discussion focused on the challenges and potential solutions for improving transcription accuracy in meetings.",
    "During the meeting, the discussion revolved around various topics, including the update on transcripts. It was mentioned that the current transcripts needed filtering for the ASI references. The idea of summarizing a previous meeting on transcripts was brought up, which would involve extracting the actual digits from the transcripts to eliminate false starts, misreads, and miscues. The question of whether the transcribers should do this task or if it should be done by someone else was raised, and it was ultimately decided that the transcribers would handle this task.\n\nAnother small task discussed was entering the information at the top of the form onto the computer, which would go along with the recorded digits. It was suggested that this task could be done by either the transcribers or someone else, but there was concern about it taking away time from transcribing more words.\n\nThe meeting then moved on to discuss the TI-digits corpus. It was mentioned that the digits went up to around four thousand and that the corpus would be completed in a couple of weeks. It was also mentioned that there were some blank forms that needed to be filled in.\n\nThe idea of training a recognizer on the TI-digits corpus was brought up, with the suggestion of using a test set of TI-digits for evaluation. The discussion then shifted to the difficulty of digit recognition and the performance of different systems. It was mentioned that the best score on the Aurora dataset was around five percent error per digit, and the best score on the TI-digits corpus was under one percent. The challenges of digit recognition, especially in real-world scenarios with noise, were emphasized.\n\nThe meeting also touched on the differences between the prosodics and cross-word modeling in the TI-digits corpus compared to other speech recognition tasks. It was mentioned that the prosodics and grouping in the TI-digits corpus were different due to the lack of grouping and the absence of features like nasality and voicing.\n\nThe discussion then turned to the possibility of incorporating articulatory features into the transcription process. The idea was to have an intermediate level of representation that captures the articulatory features rather than just phones. It was suggested that this could be done on a small subset of the Switchboard corpus to compare predictable speech with less predictable speech.\n\nThe meeting concluded with the idea of starting with an automatic system that provides a rich pronunciation dictionary and then having people go through and fix any errors or inconsistencies. It was also mentioned that the transcribers could make guesses about the articulatory features based on the phone representation to make the process quicker.\n\nIn summary, the discussion regarding the transcripts focused on the need for an update and the potential inclusion of articulatory features in the transcription process. The meeting also touched on the progress of the TI-digits corpus and the challenges of digit recognition.\n\nDuring the meeting, the participants discussed the issue of transcripts and the requirements for them. They mentioned that regular dictionaries do not always provide accurate pronunciations, so human transcribers are necessary. They also",
    "In a meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly stated. However, the meeting mainly focused on discussing the progress of the team's work on improving latency and performance. PhD B mentioned their work on redesigning filters using recursive filters to address bugs and latency issues. They also discussed the possibility of using linear discriminant analysis filters and the potential benefits of adding spectral subtraction to the system. PhD B emphasized the importance of communication with Sunil and the need to discuss their work with him.\n\nThe meeting also touched on the topic of latency and the proposed changes to the rules regarding latency in a conference talk. PhD B mentioned that the current latency is around 240 milliseconds but could reach around 330 milliseconds with additional filters and processing. They discussed the trade-offs between latency and performance and how users may not notice or complain about latency delays.\n\nThe discussion briefly mentioned the estimation of the noise spectrum for spectral subtraction. PhD B mentioned the use of histograms and Gaussian mixture models for estimating the noise spectrum and the challenges of dealing with non-stationary noise. Different methods and potential trade-offs in estimating the noise spectrum were discussed.\n\nRegarding generating queries automatically, PhD F mentioned using spectral subtraction for stationary noises and alternative methods for non-stationary noises. PhD B agreed and suggested that if the noise is stationary, there may not be a need for a noise estimation algorithm. They also discussed the use of adaptive schemes and dictionaries in generating queries automatically.\n\nThe meeting also included a discussion about the work of PhD E, who is planning to extend previous work on detecting phonetic features using multi-band features and detectors. Professor C expressed interest in this approach and highlighted the use of narrow band information and the training of detectors for a product of errors rule.\n\nThe topic of de-reverberation in far microphone speech recognition was also discussed. PhD F mentioned different approaches, such as using longer time windows, reconstructing the excitation signal, and using LPC analysis to reduce reverberation. PhD B mentioned the work of a researcher in Mons who is working on de-reverberation using single microphones.\n\nLastly, the meeting touched upon the topic of multiple microphone systems and the potential use of two microphones with an obstruction between them to take advantage of the shadow created. Professor C also mentioned the use of echo cancellation and the challenges of working with arrays.\n\nOverall, while the opinions of PhD F and PhD B on generating queries automatically were not explicitly mentioned, the meeting covered topics related to improving latency and performance, the potential use of spectral subtraction and linear discriminant analysis filters, extending previous work on detecting phonetic features, de-reverberation, and multiple microphone systems.",
    "During the meeting, the discussion on latency in the system was brought up. The professor expressed concern about the latency because it was causing delays in the system. The exact duration of the latency was not specified during the meeting. The discussion focused on various issues related to latency, including downsampling problems, the length of filters, and online normalization. The professor suggested that there may have been a problem with communication and coordination between the different groups working on the system, which could be contributing to the latency issue.\n\nIn addition to the latency issue, the meeting also touched on other topics such as echo cancellation, acoustic features, and improvements in the back-end recognizer. These discussions were likely related to addressing other issues and improving the overall performance of the system.\n\nDespite the concerns raised about latency, the meeting concluded with the professor recommending that the team continue working on their current tasks and explore different ways to improve the system. This suggests that the professor acknowledged the issue and wanted the team to actively seek solutions to reduce latency and improve the system's performance. However, without specific information on the duration of the latency, it is unclear how urgent or significant the issue is.",
    "In the meeting between Grad D and Grad C, they discussed the roles of the computer and wizard. The computer was seen as a tool for processing and analyzing data, as well as performing calculations and simulations. On the other hand, the wizard was viewed as a guide or mentor who could provide expert advice and support to the user.\n\nGrad E contributed to the discussion on storage disks. They talked about the different types of storage disks available, such as hard drives and solid-state drives, and discussed their advantages and disadvantages. Grad E also emphasized the importance of data backup and the need for reliable storage solutions.\n\nGrad B provided updates on the meeting on disk storage. They discussed the progress made in implementing a new storage system and the challenges they faced. Grad B also shared information about the performance improvements achieved with the new system and outlined plans for future enhancements.\n\nOverall, the meeting covered the roles of the computer and wizard, the types of storage disks, and updates on the disk storage project. These discussions provided a comprehensive understanding of these topics and their significance within the project.",
    "SmartKom is an architecture and module system that is part of the German SmartKom project. The project aims to develop a speech recognition and synthesis system that can understand and generate natural language in multiple languages. The system uses a German synthesis module for English sentences, but there are still some issues with certain words and structures. The dialogue manager in SmartKom uses XML and a knowledge base in a LISP-like form to generate syntactic structures, which are then passed to a generation module. The belief-net for the system is being designed based on the knowledge and hypotheses of the team, with the possibility of learning from data in the future. The architecture includes various modules for generating spatial descriptions and providing information on objects in multiple languages. SmartKom also incorporates an ontology API for accessing ontologies and making decisions about the system's ontology. The project plans to involve new doctoral students and an undergraduate student in the research and collaborate with Ellen on image schemas. The overall focus of the project is on the progress and future plans for SmartKom.",
    "During the meeting, the options discussed regarding the location of the recording equipment were not explicitly mentioned. The focus of the meeting was mainly on discussing the latency problem and the performance of the system in terms of error rate. It was noted that the current system has a latency of 230 milliseconds, which needs to be reduced by 10 milliseconds. The primary factor contributing to the latency was identified as the Voice Activity Detection (VAD) network, and it was suggested to make the VAD shorter to reduce latency.\n\nThe meeting also discussed the performance of the system in comparison to human performance. Currently, the system has a 7% error rate on digits, while human performance is around 1%. The possibility of including pitch information in the system was discussed as it could potentially have a significant impact on performance. However, it was also mentioned that the LPC-12 synthesis used in the system introduces some degradation, which may affect the comparison with human performance.\n\nIn relation to the Wall Street Journal task, it was mentioned that the Mississippi State system has achieved an 8.2% word error rate using a bigram grammar. The scripts provided by Mississippi State for running the system on the Wall Street Journal data were downloaded, but there were issues with the single CPU version of the scripts. The multi-CPU version was expected to be released soon.\n\nThere was no specific discussion about the compute power required for running the Wall Street Journal task or about Mississippi State running the systems for other sites. The status and details of the Wall Street Journal task were not clear, and further communication and updates were needed to determine the specific conditions and parameters for the task.\n\nAlthough the options for the location of the recording equipment were not explicitly mentioned, the meeting did discuss various approaches and ideas related to speech recognition and feature extraction. These included using log probabilities to model observations, simulating the back-end with another system to determine scaling factors, using an auditory model for generating speech recognition features, analyzing input signals with Gabor functions, utilizing neural networks to learn posterior probabilities of phones, and employing graphical models and the EM algorithm to learn about latent variables.\n\nIn conclusion, the meeting focused on addressing the latency problem and improving the system's performance. It also touched upon the Wall Street Journal task and discussed different approaches for speech recognition and feature extraction. However, the decision regarding the location of the recording equipment was not mentioned during the meeting.",
    "During the meeting, there were discussions about the talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions started with comparing the performance of Meeting Recorder digits with a large amount of training data, which significantly improved the results. The SRI system with adaptation showed better results than the HTK system, but without adaptation, the error rate was worse. It was suggested to feed tandem features into the SRI system for further improvement.\n\nThe difference in results between the Meeting Recorder digits and the TI-digits database was also discussed. The TI-digits had a lower error rate, and it was speculated that this difference could be due to the amount of training data and the recording conditions. The Meeting Recorder digits had more background noise and were not controlled like the TI-digits.\n\nThe meeting also touched upon the use of a new Voice Activity Detection (VAD) system to improve performance. The VAD was designed to be used before the Linear Discriminant Analysis (LDA) to reduce delay and improve accuracy, but there were concerns about where to implement it and its potential interaction with the feature extraction process.\n\nExtending the work of Larry Saul and using factorial Hidden Markov Models (HMMs) to model time series was another topic of discussion. The idea was to have parallel features transitioning independently and then coupling them with undirected links based on additional data. The use of modulation spectrum as features and the trade-off between time and frequency resolutions were also mentioned.\n\nDealing with reverberation effects in speech recognition was another topic discussed. A method was proposed to include the reverberation response by using longer analysis frames and adjusting the time and frequency resolutions to effectively capture the reverberation effects.\n\nOverall, the discussions in the meeting focused on comparing different systems, using VAD, extending previous work, and addressing reverberation effects in speech recognition."
]