[
    [
        "During the meeting, the participants discussed various topics including XML tools, data quality, and the current XML format used to link different components in data. The discussion began with a general update on individual work and progress. Stephane mentioned that their paper on the proposed system for Aurora was accepted for the Eurospeech conference in Aalborg, Denmark in September. He also discussed his work on online normalization, specifically focusing on different approaches and the use of two means for silence and speech. He mentioned that while these approaches didn't significantly improve performance, they also didn't harm it. Stephane also mentioned experimenting with thresholding and adding noise to smooth out the mel filter bank coefficients. He discussed the differences between C-zero and C-one coefficients and how they can vary based on different noises. Barry talked about his work on preparing for quals and conducting cheating experiments to determine the effectiveness of intermediate categories in classification. He mentioned using the SmartKom language model and adapting it for far-mike use. Dave mentioned his work on phase normalization and the bug he encountered in his code. He mentioned trying it again and getting better results but still not as good as subtracting log magnitude means. He also discussed his collaboration with Andreas and Thilo on the SmartKom system and their plans to train a Broadcast News net and adapt it on similar data to SmartKom. He mentioned the potential long training time for the net and the need to standardize on certain aspects. Morgan mentioned his focus on Meeting Recorder stuff and not much progress on the discussed topics. Finally, Dick discussed his experiments with phase normalization and the challenges he faced with unwrapping the phase. He mentioned potential alternative approaches using complex arithmetic or Taylor series expansion. The meeting provided insights into the ongoing work and opinions of the participants on XML tools, data quality, and the current XML format.",
        "In the meeting, there was a discussion about XML tools, meeting data quality, and the current XML format to link up different components in data. The discussion started with a PhD student, D, talking about implementing Wiener filtering for an Aurora task. They mentioned that they initially thought it was working fine, but when they ran the whole recognition experiment with Italian, the results were worse than not using it. D was trying to find the problem and mentioned that there might be a bug somewhere. \n\nThen, there was some confusion about what D was talking about, but they clarified that they implemented the Wiener filtering as a module and tested it separately. They mentioned that they plugged it in somewhere and removed some part, which caused the problem. They also talked about using filters from another student, Carlos, in their Wiener filtering implementation. D mentioned that they were considering using those filters to see if they would improve the results.\n\nAnother PhD student, E, talked about working with VTS (Vectorial Taylor Series) to remove noise. They mentioned doing experiments with the Spanish database using only VTS and nothing else. They discussed the need for VAD (Voice Activity Detection) and LDA (Linear Discriminant Analysis) to improve the results. E mentioned that when they put everything together, the results were better, but not better than without using VTS. They discussed the need to standardize the noise estimation and the possibility of using known sections of nonspeech for estimation. They also discussed the use of a codebook for the clean speech and the need for more reliable stretches of nonspeech for estimation.\n\nThere was some confusion about the equations and expressions E presented, but it was clarified that they were discussing the log domain and the use of Taylor series approximation for the nonlinear relation between clean and noisy speech. They discussed the estimation of the clean speech given the noisy speech and the use of a codebook for the clean speech. They also mentioned the use of a single Gaussian for the noise and the adaptation of the mean and variance of the noisy speech based on noise detection.\n\nThe professor asked questions about the adequacy of using only mean and variance to characterize the noise, the possibility of using more parameters, and the complexity of using higher-order Taylor series expansions. The PhD students acknowledged that these were important questions and that further investigation was needed.\n\nOverall, the discussion revolved around the implementation of Wiener filtering and VTS for noise removal in speech recognition tasks. The students shared their experiences and challenges, and the professor raised important questions for further exploration."
    ],
    [
        "During the meeting, the discussion revolved around the topic of electronics, specifically regarding wireless microphones and their proper usage. The participants also talked about the importance of signing consent forms and speaker forms for the meeting. They discussed the process of reading digit strings and the need for individuals to state which transcript they are on during the reading. The topic of intentionality was also brought up, with a focus on differentiating between different intentions, such as viewing, entering, or touching a certain object. The participants talked about the challenges of determining intention from language and discourse and the potential use of a belief-net to infer intention. They also discussed the need for contextual information, such as the type of object, time of day, and situational and discourse context. The meeting concluded with the idea of building a belief-net to determine intention and the need for further exploration of the factors involved in this task.",
        "During the meeting, the discussion revolved around the topic of electronics and the segment they were working on. They mentioned that their current goal is to solve problems related to the segment, and they are using a small room to record subjects for their experiments. They discussed the intentionality of the experimental subjects and the need to collect data that can help determine their intentions. They also mentioned that the data collected so far did not differentiate between different intentions or tasks. They talked about the possibility of using a belief-net package to analyze the data and extract features that can be used to determine the intentions of the subjects. They also discussed the need for a clear plan and time frame for the project. They mentioned that they will need to convert the system to English and merge it with the belief-net analysis. They discussed the possibility of using XML files for data collection and analysis. They also mentioned the need to pick a belief-net package and present it in the next meeting. Overall, the meeting focused on the discussion of electronics, the segment, the results from the experiments, and the topic of intentionality."
    ],
    [
        "The main thesis of the discussion was about improving the quality of close-talking microphones and the use of microphone arrays for recording meetings. The professor and the participants discussed the need for better quality microphones and the standardization of microphone types to capture the best audio signal. They also talked about the upcoming visit from NIST and the potential collaboration with them on recording and transcription methods. The participants mentioned the use of the ATLAS system for transcription and the possibility of sharing data with NIST for further experimentation. The professor also mentioned the interest in video recordings of the meetings, but acknowledged the challenges of human subjects' consent and the need for additional infrastructure. The participants also discussed the progress of transcription work, with some transcribers already finishing their assigned data sets. The professor mentioned the importance of reliability in the transcription process and the need for consistent encoding conventions. The discussion also touched on potential collaborations with other researchers and institutions interested in meeting data and transcription. Overall, the main thesis of the discussion was to improve the recording and transcription methods for meeting data and explore potential collaborations with other researchers in the field.",
        "The main thesis of the discussion was to explore ways to improve the accuracy of transcriptions in meetings. The professor and the participants discussed various aspects related to this topic. \n\nRegarding the 12-second mean, there was a discussion about the need to check and adjust the mean for each person before combining them. It was also mentioned that there could be potential problems with this approach.\n\nPossible hypotheses were discussed, such as the difficulty of following one channel of a conversation, especially when there is cross-talk or reduced phonetic words. The participants also discussed the importance of having time markings for forced alignment.\n\nIn concluding comments, it was mentioned that the answer to some of the questions raised is unknown because they haven't been tried both ways. The professor expressed interest in having more discussions with the transcription team to address concerns and explore future work.\n\nIn terms of future work, the participants discussed the possibility of collecting more meeting data from different groups, such as political or artistic groups. They also mentioned the potential use of transcribers for tasks like dialogue act tagging and disfluency tagging. The participants also discussed the possibility of using signal processing techniques to improve the signal-to-noise ratio and alignment accuracy.\n\nOverall, the discussion focused on the challenges and potential solutions for improving transcription accuracy in meetings."
    ],
    [
        "During the meeting, the discussion revolved around various topics, including the update on transcripts. It was mentioned that the current transcripts needed filtering for the ASI references. The idea of summarizing a previous meeting on transcripts was brought up, which would involve extracting the actual digits from the transcripts to eliminate false starts, misreads, and miscues. The question of whether the transcribers should do this task or if it should be done by someone else was raised, and it was ultimately decided that the transcribers would handle this task.\n\nAnother small task discussed was entering the information at the top of the form onto the computer, which would go along with the recorded digits. It was suggested that this task could be done by either the transcribers or someone else, but there was concern about it taking away time from transcribing more words.\n\nThe meeting then moved on to discuss the TI-digits corpus. It was mentioned that the digits went up to around four thousand and that the corpus would be completed in a couple of weeks. It was also mentioned that there were some blank forms that needed to be filled in.\n\nThe idea of training a recognizer on the TI-digits corpus was brought up, with the suggestion of using a test set of TI-digits for evaluation. The discussion then shifted to the difficulty of digit recognition and the performance of different systems. It was mentioned that the best score on the Aurora dataset was around five percent error per digit, and the best score on the TI-digits corpus was under one percent. The challenges of digit recognition, especially in real-world scenarios with noise, were emphasized.\n\nThe meeting also touched on the differences between the prosodics and cross-word modeling in the TI-digits corpus compared to other speech recognition tasks. It was mentioned that the prosodics and grouping in the TI-digits corpus were different due to the lack of grouping and the absence of features like nasality and voicing.\n\nThe discussion then turned to the possibility of incorporating articulatory features into the transcription process. The idea was to have an intermediate level of representation that captures the articulatory features rather than just phones. It was suggested that this could be done on a small subset of the Switchboard corpus to compare predictable speech with less predictable speech.\n\nThe meeting concluded with the idea of starting with an automatic system that provides a rich pronunciation dictionary and then having people go through and fix any errors or inconsistencies. It was also mentioned that the transcribers could make guesses about the articulatory features based on the phone representation to make the process quicker.\n\nIn summary, the discussion regarding the transcripts focused on the need for an update and the potential inclusion of articulatory features in the transcription process. The meeting also touched on the progress of the TI-digits corpus and the challenges of digit recognition.",
        "During the meeting, the participants discussed the issue of transcripts and the requirements for them. They mentioned that regular dictionaries do not always provide accurate pronunciations, so human transcribers are necessary. They also discussed the possibility of using phone recognizers and the need for a good meeting recorder or transcriber. They mentioned the idea of using Switchboard for additional data and the need for training the transcribers with IPA coding. The participants agreed that having manually transcribed references for the system would be beneficial and discussed the process of forced alignment and the use of acoustic features. They also talked about the need for variety in meetings and speakers for the training set. The participants mentioned the possibility of using the new microphones and discussed the different types of microphones and their comfort. They also discussed the process of editing the transcripts and the format for processing them with the SRI recognizer. They mentioned the need for consistency in conventions and discussed incorporating acronyms and numbers into the transcripts. The participants also talked about the need for an additional channel to handle noises and uncertainties and discussed the process of post-processing the transcripts for force alignment and recognition. They mentioned the upcoming arrival of the new microphones and the plan to try them out before getting more. Overall, the participants had a thorough discussion about the requirements and agreement regarding the transcripts."
    ],
    [
        "In the given meeting, the opinions of PhD F and PhD B on the topic of generating queries automatically were not explicitly stated. The meeting mostly focused on discussing the progress of the team's work on improving the latency and performance of the system. PhD B mentioned that they have been working on redesigning filters using recursive filters to address the bugs and latency issues. They discussed the possibility of using linear discriminant analysis (LDA) filters instead of the current nonlinear filters and the potential benefits of adding spectral subtraction to the system. PhD B also mentioned the importance of communication with Sunil and the need to discuss their work with him.\n\nThe meeting also touched on the topic of latency and the proposed changes to the rules regarding latency in the conference talk. PhD B mentioned that their current latency is around 240 milliseconds, but with additional filters and processing, it could reach around 330 milliseconds. They discussed the trade-offs between latency and performance, as well as the perception of latency in user experience. They mentioned previous experiences with latency in other systems and how users did not notice or complain about the delay.\n\nThe discussion also briefly touched on the estimation of the noise spectrum for spectral subtraction. PhD B mentioned the use of histograms and Gaussian mixture models to estimate the noise spectrum, as well as the challenges of dealing with non-stationary noise. The different methods of estimating the noise spectrum and the potential trade-offs were discussed.\n\nOverall, while the opinions of PhD F and PhD B on generating queries automatically were not explicitly mentioned in the meeting, the discussion mainly focused on the team's work on improving latency and performance, as well as the potential use of spectral subtraction and linear discriminant analysis filters.",
        "In the meeting, PhD F and PhD B discussed their opinions on the topic of generating queries automatically. PhD F mentioned that one approach is to use spectral subtraction for stationary noises, while for non-stationary noises, another method could be used. PhD B agreed with this and suggested that if the noise is stationary, there may not even be a need for a noise estimation algorithm. PhD A added that a good estimate of the noise could be obtained by using noise files and building averages from them. PhD B also mentioned that the use of adaptive schemes and dictionaries could be useful in generating queries automatically.\n\nDuring the meeting, there was also a discussion about the work of PhD E, who is planning to extend the work done by Larry Saul, John Allen, and Mazin Rahim. PhD E explained that their system uses multi-band features and detectors to detect phonetic features such as sonorance. The system uses independent tests in each sub-band to detect the presence of sonorance and combines them using soft AND and OR gates. The low-level detectors used in the system are logistic regressions.\n\nProfessor C expressed his interest in this approach, highlighting the use of narrow band information for phonetic features and the training of detectors for a product of errors rule. He also mentioned the issue of determining the targets for training the intermediate detectors and the need for further exploration in this area.\n\nThe discussion then shifted to the topic of de-reverberation in far microphone speech recognition. PhD F mentioned different approaches, including using longer time windows for de-convolution, reconstructing the excitation signal, and using LPC analysis to reduce reverberation. PhD B mentioned the work of a researcher in Mons who is working on de-reverberation using single microphones.\n\nLastly, the meeting touched upon the topic of multiple microphone systems and the possibility of using two microphones with an obstruction between them to take advantage of the shadow created. Professor C also mentioned the use of echo cancellation and the challenges of working with arrays.\n\nIn summary, PhD F and PhD B expressed their opinions on generating queries automatically, while the meeting also covered topics related to extending previous work, de-reverberation, and multiple microphone systems."
    ],
    [
        "During the meeting, the discussion on latency in the system was brought up. The professor had an issue with the latency because it was causing delays in the system. The duration of the latency was not specified in the meeting. The discussion focused on various issues related to latency, such as downsampling problems, length of filters, and online normalization. The professor mentioned that there may have been a problem with communication and coordination between the different groups working on the system. Additionally, the meeting touched on other topics such as echo cancellation, acoustic features, and improvements in the back-end recognizer. The meeting concluded with the professor suggesting that the team continue working on their current tasks and explore different ways to improve the system."
    ],
    [
        "In the meeting between Grad D and Grad C, several key points were discussed about the roles of the computer and wizard. They talked about the use of the computer in processing and analyzing data, as well as its ability to perform calculations and simulations. The wizard, on the other hand, was seen as a guide or mentor who could provide expert advice and support to the user.\n\nIn addition, Grad E contributed to the discussion on storage disks. They discussed the different types of storage disks available, such as hard drives and solid-state drives, and their advantages and disadvantages. Grad E also talked about the importance of data backup and the need for reliable storage solutions.\n\nLastly, Grad B provided updates on the meeting on disk storage. They discussed the progress made in implementing a new storage system and the challenges they faced. Grad B also shared information about the performance improvements achieved with the new system and the plans for future enhancements.\n\nOverall, the meeting covered various aspects of computer and wizard roles, storage disks, and updates on disk storage. The discussions provided a comprehensive understanding of these topics and their importance in the context of the project."
    ],
    [
        "SmartKom is an architecture and module system that is part of the German SmartKom project. The project aims to develop a speech recognition and synthesis system that can understand and generate natural language in multiple languages. The meeting discussed the progress of the project, including the ability to speak into the SmartKom system and have it generate speech in response. The system uses a German synthesis module for English sentences, but there are still some issues with certain words and structures. The meeting also mentioned the use of XML tags and tree adjoining grammar for sentence generation. The dialogue manager in SmartKom uses XML and a knowledge base in a LISP-like form to generate syntactic structures, which are then passed to a generation module. The meeting also discussed the importance of understanding the architecture and modules of SmartKom, as well as the need to finish the belief-net for the system. The belief-net is being designed based on the knowledge and hypotheses of the team, with the possibility of learning from data in the future. The meeting also mentioned the availability of data for analysis and the relevance of fictive motion in the system. Overall, the meeting focused on the progress and future plans for SmartKom.",
        "SmartKom is an architecture that consists of various modules for generating spatial descriptions and providing information on objects in multiple languages, including German, English, and Japanese. The architecture includes a project called Deep Map, which focuses on spatial descriptions and differences in spatial descriptions across different languages. SmartKom also incorporates an ontology API for accessing ontologies and making decisions about the system's ontology. The project aims to build a construction analyzer that can be used for both SmartKom and child language modeling. Additionally, the project plans to involve new doctoral students and an undergraduate student in the research. The group is working on formalizing the belief-net and making decisions about the system's design. They also plan to collaborate with Ellen on image schemas."
    ],
    [
        "During the meeting, the options discussed regarding the location of the recording equipment were not mentioned. The meeting mainly focused on discussing the latency problem and the performance of the system in terms of error rate. It was mentioned that the current system has a latency of 230 milliseconds, which needs to be reduced by 10 milliseconds. The primary factor determining the latency is the Voice Activity Detection (VAD) network. It was suggested to make the VAD shorter to reduce latency. \n\nThe meeting also discussed the performance of the system in comparison to human performance. It was mentioned that the system is currently at a 7% error rate on digits, while human performance is around 1%. The possibility of including pitch information in the system was discussed, as it might have a significant impact on performance. However, it was also noted that the LPC-12 synthesis used in the system introduces some degradation, which may affect the comparison with human performance.\n\nRegarding the Wall Street Journal task, it was mentioned that the Mississippi State system has achieved an 8.2% word error rate using a bigram grammar. The scripts provided by Mississippi State for running the system on the Wall Street Journal data were downloaded, but there were some issues with the single CPU version of the scripts. The multi-CPU version was expected to be released soon.\n\nThere was no discussion during the meeting about the compute power required for running the Wall Street Journal task or about Mississippi State running the systems for other sites. The status and details of the Wall Street Journal task were not clear, and it was mentioned that further communication and updates were needed to determine the specific conditions and parameters for the task.",
        "In the meeting, the options discussed regarding the location of the recording equipment were not explicitly mentioned. However, there was a discussion about different approaches and ideas related to speech recognition and feature extraction. One option discussed was using log probabilities as a way to model the observations and taking advantage of the fact that log probabilities have a Gaussian shape. Another option discussed was simulating the back-end with another system to determine the scaling factor for the features. Additionally, there was a discussion about using an auditory model to generate speech recognition features and using Gabor functions to analyze the input signal. Another topic of discussion was the use of neural networks to learn posterior probabilities of phones and the patterns learned by the hidden units of the network. Finally, there was a mention of using a graphical model and the EM algorithm to learn about latent variables corresponding to intermediate categories. The decision made regarding the location of the recording equipment was not mentioned in the meeting."
    ],
    [
        "During the meeting, there were discussions about various topics including the talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions started with the comparison of the Meeting Recorder digits that were tested. It was found that using a large amount of training data significantly improved the results. The SRI system, with adaptation, showed better results than the HTK system. However, without adaptation, the error rate was around fifty percent worse. It was suggested to feed the tandem features into the SRI system to further improve the results.\n\nThe meeting also touched upon the issue of the difference in results between the Meeting Recorder digits and the TI-digits database. The TI-digits had a much lower error rate, and it was speculated that the difference could be due to the amount of training data and the recording conditions. It was mentioned that the Meeting Recorder digits had more background noise and were not controlled like the TI-digits.\n\nAnother topic discussed was the use of a new Voice Activity Detection (VAD) system, which showed promising results in improving the system's performance. The VAD was designed to be used before the Linear Discriminant Analysis (LDA) to reduce delay and improve accuracy. However, there were concerns about where to implement the VAD and the potential interaction between the VAD and the feature extraction process.\n\nThe meeting also involved discussions about extending the work of Larry Saul and using factorial Hidden Markov Models (HMMs) to model time series. The idea was to have parallel features transitioning independently and then coupling them with undirected links based on additional data. The use of modulation spectrum as features and the trade-off between time and frequency resolutions were also mentioned.\n\nAdditionally, there were discussions about dealing with reverberation effects in speech recognition. A method was proposed to include the reverberation response by using longer analysis frames. The time and frequency resolutions were adjusted to capture the reverberation effects effectively.\n\nOverall, the discussions in the meeting focused on various aspects of the talk, including the comparison of different systems, the use of VAD, extending previous work, and addressing reverberation effects in speech recognition."
    ]
]