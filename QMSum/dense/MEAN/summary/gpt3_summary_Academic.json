[
    "During the meeting, there was a discussion about XML tools, data quality in meetings, and the current XML format used to link up different components in data. The opinions of F and A on the current XML format were not explicitly mentioned in the meeting. However, based on the discussion, it can be inferred that the participants had mixed opinions on the effectiveness of the current XML format and were exploring different approaches and tools to improve data quality and component linking.\n\nThe meeting began with a discussion on who would lead the meeting, with PhD F ultimately taking charge. Updates from each participant were then discussed. PhD C announced that their paper on the Eurospeech system had been accepted and would be presented at a conference in Denmark. They also discussed their work on online normalization and investigating the impact of different noises on mean estimation.\n\nPhD A discussed their experiments with thresholding in online normalization and the surprising finding that speech recognition performance was not worse with added noise. They also mentioned considering varying the normalization approach for different MFCCs.\n\nPhD G talked about their experiments with phone recognition using VTS, mentioning that the results were not as good as expected when using VTS alone but improved when combined with VAD. They also mentioned that using VTS with other components did not yield better results.\n\nPhD D discussed their work on Wiener filtering for the Aurora task and the bug in their code that resulted in worse results than without Wiener filtering. They were in the process of finding and fixing the bug and considering using filters from Carlos' thesis.\n\nPhD E discussed their work on VTS and mentioned that using VTS alone did not yield better results than without VTS. They were considering using noise estimation from clean sections of speech for better results and questioning the initial codebook used for VTS.\n\nThe discussion also touched on the potential use of Taylor series expansion and different methods for noise estimation. There was some confusion and debate about the equations and methods, but it was agreed that further investigation and experimentation were needed.\n\nIn addition to the discussion on XML tools, data quality in meetings was also addressed. The meeting mentioned the need for better quality close-talking microphones for all speakers to improve data quality and make transcription and research easier. The NIST visit was also mentioned, with a visitor interested in the room and modified multitrans. There was also a discussion about the potential use of microphone arrays for recording meetings.\n\nThe opinions of F and A on the current XML format were not explicitly stated. However, there was a general interest in experimenting with different tools and formats to improve the analysis of meeting data. The participants had mixed opinions on the effectiveness of the current XML format and were exploring different approaches and tools to improve data quality and component linking.",
    "During the meeting, there was a discussion about electronics, specifically related to the Meeting Recorder project. The project aims to collect data on meetings using different microphones. The purpose is to create a corpus for research on meetings. The meeting also touched on the topic of intentionality, specifically in the context of determining intentions based on language and context. The challenges of extracting intention information from the data were discussed, and the potential use of belief nets was mentioned. The current front-end system used in the project was found to be insufficient in determining intentions, so additional factors and features would need to be extracted. Context, both situational and discourse, was considered important in determining intentions. Plans for future data collection and experiments to further explore intentionality were discussed.\n\nDuring the meeting, the discussion also covered the use of Thilo's segmenter in the experiments. The segmenter was found to work well, and the recognition results were re-evaluated using the segmenter without cheating on the segmentations. The issue of finding transcripts for the segments was mentioned, and the use of NIST's scoring program for this purpose was suggested. The participants also discussed using recognizer alignments to train Thilo's speech detector, which would reduce manual labeling. They mentioned training data collection and the possibility of reducing false alarms in the speech detector. The SmartKom group's dialogues for a travel task were considered useful for acoustic and language model training and were included in the corpus.\n\nThe meeting also discussed SRI recognition experiments, including the use of tandem features and different approaches to improve performance. The issue of vocal tract length normalization and the difference in results between males and females were mentioned. The participants discussed overfitting and the possibility of tightening pruning without affecting results. The meeting also briefly touched on the trapezoidal and triangular filters used in the SRI front-end, with a slight difference in scale noted but not considered significant.\n\nThe results from the experiments conducted on the SRI front-end were discussed, with a small difference in performance observed between triangular and trapezoidal filters. The segment and results from the experiments were briefly discussed, highlighting the potential impact of a larger training set on the Baum-Welch algorithm. The boot models used for training were mentioned, with the nature of the boot alignments not considered a significant factor. The meeting concluded with the need for further experiments with a larger training set and the potential use of PLP filters in noisy situations.\n\nIn addition, the meeting discussed the placement of microphones and its effect on naturalness of recordings. The challenges of recognizing breathing and laughter as speech were mentioned, as well as the quality of transcriptions and the possibility of using display to judge correctness. The effectiveness of different energy levels in separating overlapping speech was explored, along with the use of pitch and harmonicity as indicators. The potential of Javier's speech segmenter in distinguishing overlapping and non-overlapping speech was also discussed, and an experiment using Javier's software and hand-segmented data was suggested to determine its",
    "The main thesis of the discussion was improving the recording quality in meetings and the use of close-talking microphones. The professor expressed interest in obtaining better quality microphones and ensuring they are worn correctly to capture the signal effectively. There were discussions about collaborating with other institutions interested in microphone arrays, but concerns were raised about the additional infrastructure and setup required. The upcoming NIST visit and topics to be discussed, such as the modified multitrans system and pre-segmentation, were also mentioned. The progress of transcriptions and the use of the ATLAS system for analyzing the data were discussed, with an emphasis on reliability and consistency in the coding process. Future work would involve contacting and collaborating with various groups and organizations to gather more meeting recordings and exploring post-processing techniques to improve accuracy.\n\nThe discussion also focused on the possibilities of collecting more meeting data for transcription and analysis. Collaboration with other institutions, reaching out to different departments and groups within their own organization, and involving external groups were mentioned as potential sources for obtaining more diverse and interesting data. The professor expressed interest in having meetings with all English speakers, preferably native American English speakers. The potential for post-processing and improving accuracy through methods like pre-processing and echo cancellation was also discussed. Future work would involve conducting more recordings of meetings, particularly with different numbers of participants, and exploring post-processing techniques to enhance transcription and analysis.\n\nThe occurrence of overlaps in meetings and understanding the patterns and factors influencing them was another main thesis discussed. The professor acknowledged the significant number of overlaps throughout the meeting and mentioned the influence of the number of participants and the type of overlap. The importance of considering overlaps in meetings and how it differs from single-channel processing was emphasized. The participants expressed interest in further analysis to determine the duration of overlaps and how it varies based on the type of overlap. Future work would involve studying overlaps in different types of meetings, comparing overlap occurrence in different settings, and analyzing the impact of overlaps on communication and understanding.\n\nThe discussion also aimed to analyze the occurrence and nature of overlaps in conversations. The professor and participants discussed the possibility of overlaps being related to rhythmic structure in conversation and the intention behind them. The audibility of overlaps and the potential upper bound on the number of overlaps based on participants' loudness were also mentioned. Future work would involve conducting two-person or three-person meetings to gather more data on overlaps. The professor's opinions on the 12-second mean were not explicitly mentioned, but the use of energy measures and acoustic change detection in analyzing overlaps was discussed. Possible hypotheses included studying the spatial relationship and body language of speakers to understand the dynamics of overlaps better.\n\nIn terms of concluding comments, the participants expressed the need for more research and experimentation to improve the accuracy of overlap detection algorithms. Challenges in adapting existing models to new data and the potential benefits of considering energy levels and speaker combinations in overlap analysis were discussed. Future work would involve contacting and collaborating with various groups and organizations to gather more meeting recordings, exploring post-processing techniques to improve accuracy,",
    "During the meeting, the discussion primarily focused on the transcripts and their requirements. The postdoc expressed the need for an update on the transcripts and the need to filter out ASI references. The meeting also delved into the progress on the digits and TI-digits dataset. The postdoc provided an update on the progress and mentioned the necessity of extracting actual digits from the transcripts, considering false starts and miscues. They debated whether the transcribers should handle this task or if someone else should. Eventually, they reached a consensus that the transcribers could handle extracting the digits and entering information into the computer.\n\nThe conversation then shifted to the challenges of speech recognition in noisy environments like cars. The participants discussed the difficulties of modeling articulatory features and the differences between reading digits and conversational speech. They suggested using Switchboard data to overcome these challenges.\n\nThe meeting also included a discussion on a new version of presegmentation that incorporates channel-specific speech-nonspeech detection. The speaker explained the process and emphasized the need for evaluation with manually transcribed references. They also explored the possibility of having the transcribers manually adjust the forced alignment.\n\nIn another part of the meeting, the team discussed the status and requirements of the transcripts. They contemplated providing five minutes of different meetings for transcription, excluding the first minute due to potential issues. They also considered training a segmenter based on the provided five-minute segments, believing it would yield tighter time bands. The team decided to order new microphones and discussed the plan for the old ones. They also discussed the progress of transcription and the potential of sending the first five EDU meetings to IBM.\n\nFurthermore, the team talked about the use of XML tools and the need to improve the transcription format for better compatibility with other tools. They explored the possibility of merging the Transcriber interface with the THISL IR tool. Additionally, they discussed showcasing the prosody work in the demo and agreed to have all necessary pieces ready by the end of the month.\n\nAddressing the collection and analysis of digit data for speech recognition, the team acknowledged the current two hours of transcribed digits but expressed the need for more data for training and adaptation. They discussed eliciting different prosodics and decided to write the digits as numbers instead of words to elicit different readings. There was a debate about reading them as digits or connected numbers, and it was ultimately decided to read them as digits. The group also considered replicating the original data set with different language groups to study the effect of dialects on speech recognition. They concluded the meeting by deciding to continue collecting digit data for future research and adaptation purposes.\n\nThe meeting also addressed various issues regarding the transcription process. The team discussed testing algorithms on digits for farfield and the need for overlapping digits. They talked about the cognitive load and the possibility of using cross-talk cancellation. They also mentioned the need for transcription checking procedures and standardized forms. The team emphasized the importance of glossing certain words and ended the discussion with considerations about disk",
    "In the meeting, PhD F discussed their work on a system that uses a multi-band approach to detect phonetic features, such as sonorance. They mentioned plans to extend this work to train detectors for other features like frication, abrupt closure, nasality, and voicing. The system was found to be robust in detecting sonorance but performed less well than a standard recognizer in noisy conditions. PhD F also mentioned considering using a similar approach for detecting other features and experimenting with different low-level detectors.\n\nPhD B agreed with PhD F that stress may not be helpful in distinguishing between words in English but could be more important in other languages. They also discussed the possibility of using transcription to mark certain portions of the data for analysis. The use of different algorithms for de-reverberation and echo cancellation in speech recognition was also discussed, with PhD B mentioning the work of Carlos and Hynek on de-convolution and PhD F mentioning the use of LPC analysis.\n\nPhD A and PhD B discussed the use of arrays and multiple microphones for better directionality and the potential benefits of having an obstruction between two microphones. They mentioned the work of a researcher in Mons who is working on reverberation. PhD B also mentioned the use of echo cancellation and cancelling out the linear time-invariant system between microphones as a baseline for comparison.\n\nPhD D shared the results of their experiments on generating queries automatically. They found that training on task-specific data led to better results but there was a decrease in performance when testing on a different language. They compared the performance of different features and found that PLP with JRASTA performed better in mismatched conditions, while MFCC performed better in well-matched conditions. They discussed the impact of noise conditions and the differences between training on one language versus multiple languages.\n\nPhD C discussed the on-line normalization approach and mentioned trying different variations of the approach but not seeing significant improvement. They also mentioned an experiment with adding white noise to the signals, which resulted in smoother trajectories of MFCCs but did not significantly impact speech recognition performance. The idea of combining two streams of features and using different thresholds and adaptively adjusting the noise level was also mentioned.\n\nOverall, the meeting provided insights into ongoing research and experiments on generating queries automatically using a multi-band approach, the impact of different features and training data, as well as discussions on noise compensation techniques and the use of VTS for noise removal. However, specific opinions of PhD F and PhD B on generating queries automatically were not explicitly discussed.",
    "During the meeting, the discussion on latency in the system was brought up. The professor had an issue with the latency because it was causing problems in the system. The duration of the latency was mentioned to be 136 milliseconds. The professor expressed concern about the coordination between the two groups and mentioned that they were waiting for each other to take action. The professor also mentioned that they are waiting for a decision from the committee regarding the latency requirements.\n\nAnother discussion on latency took place, with the duration estimated to be around 240 milliseconds. The professor expressed concern because this latency would need to be reduced significantly in order to meet the desired system requirements. The team considered implementing methods like spectral subtraction schemes to handle latency and improve the system's performance. The professor emphasized the importance of reducing latency to maintain the real-time nature of the system and mentioned that users did not notice a significant difference between a quarter of a second and 30 milliseconds of latency.\n\nThe professor also mentioned that the current system has a latency of 220 milliseconds, which includes the cleaning of the speech, neural network processing, and delta computation. The professor suggested reducing the number of features and adjusting the system configuration to decrease latency. The team is actively working to improve latency by exploring different feature sets and considering the impact of the tandem neural network approach on system performance.\n\nThe discussion on latency mentioned the sources of latency, such as the noise compensation process, input to the neural net, and output smoothing. The professor suggested exploring different features and correlations between them to improve the training set. The team also discussed the possibility of using LDA on the features and feeding VAD information into the neural net to provide additional discriminating information. The team also discussed the possibility of using context-dependent units instead of phonemes for the tandem net.\n\nThe meeting also touched on other topics such as echo cancellation, improving the performance of the back-end recognizer, and proposals for upcoming quals. The team discussed a multi-band system and the advantages of using narrow-band information for phonetic features. They also discussed the possibility of marking other low-level features and exploring de-reverberation algorithms for far-mic speech recognition.\n\nIn conclusion, the professor and the team are actively addressing the latency issue in the system by adjusting the system configuration, exploring different feature sets, and considering alternative approaches. They are also working on improving coordination and communication between team members. The duration of the latency ranges from 136 milliseconds to 240 milliseconds, and the professor had an issue with it because it was affecting the system's performance and real-time nature.",
    "In the meeting between Grad D and Grad C, the key points discussed about the roles of the computer and wizard were related to the crashing issue caused by the temp files. Grad E provided information about the storage of the temp files and their behavior during power failure. Grad B provided updates on upcoming conferences and the need for an agenda for the meeting with the UW folks.\n\nIn another meeting, the key points discussed about the roles of the computer and wizard were related to improved interfaces, channelizing data, and the challenges of inserting missed segments. Grad E's contribution to the discussion on storage disks was not mentioned. There were no updates provided by Grad B regarding the meeting on disk storage.\n\nIn another meeting, the key points discussed about the roles of the computer and wizard were related to lapel microphones and their advantages in reducing breath noises and clothes rustling. Grad E contributed to the discussion on storage disks by mentioning the task of reading digits. Grad B provided updates on the meeting on disk storage, including the use of lapel mics and the need for adaptation in the SRI system.\n\nIn yet another meeting, the key points discussed were about speaker labeling and interruptions in the transcription process. Grad E's contribution to the discussion on storage disks was not mentioned. There were no updates provided by Grad B regarding the meeting on disk storage. The meeting mainly focused on challenges and analysis of speech data, as well as upcoming Eurospeech submission and the departure of Jose.",
    "SmartKom is an architecture and module-based system that allows users to speak into it and receive responses in synthesized speech. It is part of the German SmartKom project and is currently being developed for both German and English languages. The system utilizes a German synthesis module for English sentences, although there are limitations in recognition. It also includes a dialogue manager that generates syntactic structures based on a LISP-like knowledge base and a Prolog-based structure builder.\n\nSmartKom is important because it enables natural language interaction with a computer system, enhancing communication and accessibility for individuals who may have difficulty with traditional input methods. It has potential applications in virtual assistants, language learning, and accessibility for individuals with disabilities.\n\nDuring a recent meeting, the team discussed their progress with SmartKom and the integration of different modules. They emphasized the importance of understanding the system architecture and modules within the larger SmartKom project. They also mentioned collaborating with researchers from Heidelberg and their plans to continue working together.\n\nThe team highlighted the need for data and transcripts of initial interactions with the system. They discussed the relevance of fictive motion in spatial descriptions and the differences in spatial references between languages. They mentioned a project on spatial descriptions and the potential for collaboration on this topic.\n\nThe team also discussed the belief-net module and the design and learning needed to create connections and semantics for the system. They considered using existing ontologies or developing their own. They also mentioned the requirement for a system that can handle both the construction analyzer for SmartKom and the child language modeling project.\n\nThe team is focused on advancing the SmartKom system, integrating different modules, designing the belief-net, and addressing system-related issues. They are collaborating with other researchers and gathering data to improve performance. They are also collecting dialogues for acoustic and language model training data, which can be processed and analyzed separately but using the same tools and conventions as the meeting corpus.\n\nThe architecture of SmartKom includes modules for on-line normalization and different means for speech and silence. It incorporates time constants and thresholding techniques to adapt to different types of noise and improve speech recognition accuracy. The system has been tested and evaluated, with positive results and comparable performance to the original system. Future work may involve further analysis of error patterns and exploring different noise types for training and testing.\n\nDuring the meeting, the team discussed speech recognition errors, the impact of different features and thresholds, noise compensation, and the effects of LDA filters on recognition rates. They also mentioned using the VTS method for noise removal and the use of a codebook for clean speech. They discussed estimating mean and variance for noisy speech and the potential benefits of using more parameters to characterize the noise. The team is working on improving the performance of SmartKom through various techniques and experiments.",
    "During the meeting, the topic of discussion was the location of the recording equipment. The decision made was to reduce the latency problem by decreasing it to 220 milliseconds, which is 80 milliseconds less than before. It was determined that the primary factor affecting the latency is the voice activity detection (VAD) system. It was suggested to make the VAD shorter to further reduce the latency. Other options discussed included improving the VAD system and working on the second stream of the system. It was mentioned that the tandem network could be improved by using a hierarchical structure and incorporating the silence probability from the VAD network. It was also suggested to train the tandem network on more data and to explore different noise estimation techniques. \n\nIn regards to the Wall Street Journal task, it was mentioned that the Mississippi State system achieved an 8.2% word error rate using a bigram grammar. The scripts for running the system on the Wall Street Journal data were downloaded, but there were some technical issues with running it on a single CPU. It was also discussed that some sites may not have the compute power to run the Wall Street Journal task, and there was a possibility of Mississippi State running the system for them. The need for tuning parameters, such as word insertion penalties, was also mentioned. \n\nThe options discussed regarding the location of the recording equipment were to have more regular meetings of known types and to have data from different domains or types of meetings. The decision made was to have more regular meetings and to aim for a variety of meeting types. It was also mentioned that advertising to linguistics graduate students may help in getting more native speakers for the recordings. Additionally, there was a discussion about the need for both regular meetings and random scattered meetings to gather data for different research purposes. It was suggested that having multiple speakers and different meeting types would be beneficial for acoustic-oriented research. Overall, the decision was to have a mix of regular and random scattered meetings to gather a diverse set of data.\n\nDuring the meeting, the options discussed regarding the location of the recording equipment were to use a room in the linguistics department or another building on campus, to turn the equipment into a portable setup, or to continue recording meetings at ICSI. The decision regarding the location of the recording equipment was not explicitly stated in the meeting. However, there was a consensus among the participants that the first priority should be to try to get people to come to ICSI for the meetings. It was also mentioned that more disk space is needed for recording future meetings. It was discussed that the current disk space can accommodate about four more meetings, and they are planning to move some data from other disks to free up space.\n\nIn terms of the progress on the project, PhD C shared their work on identifying and marking overlapping zones in the meeting recordings. They mentioned their plan to use a supervised clustering process to classify the different zones and evaluate the performance of different parameters. They also mentioned the possibility of using a neural network for classification, but expressed",
    "During the meeting, there were discussions about various topics including talk, neurons, transcriber pool, and acoustic-phonetic analyses. The discussions covered a range of subjects related to these topics.\n\nOne topic discussed was the testing of the Meeting Recorder digits and the results obtained. It was mentioned that the SRI system showed improved performance compared to other systems, especially with a large amount of training data. The use of tandem features with the SRI system was also discussed.\n\nThe pronunciation of the digit \"zero\" was also discussed, with no specific convention mentioned and people having their own preferences.\n\nOther topics included the need for a good voice activity detection system, the design of a new filter to improve the system, and the investigation of time-frequency representations to deal with reverberation effects.\n\nFactorial HMMs were briefly discussed and their potential use in modeling time series, highlighting their advantages in parameter estimation and focusing on sub-problems.\n\nThe discussions also revolved around the schedule of the upcoming meeting, the process of transcribing and analyzing speech data, and the need for a clear deadline for participants to respond. The importance of reminding participants about the meeting and obtaining their input was emphasized. The use of a transcriber pool and acoustic-phonetic analyses in the transcription and analysis process was also discussed.\n\nThe need for better quality close-talking microphones for all speakers was mentioned, as well as the upcoming NIST visit and the progress on speech transcription. The modifications to the multitrans system were also discussed.\n\nThe prototype for marking the beginning and ending of overlapping segments more accurately was mentioned, along with the limitations of the original software design. The use of array microphones and the potential collaboration with John Canny and Birger Kollmeier were also discussed. The construction of a map of where people were sitting during meetings based on audio data was considered, as well as the use of video recordings in meetings.\n\nThe challenges of transcribing multiple channels and the collaboration with IBM for transcription were mentioned. The discussions also covered the process of transcribing and aligning speech segments, the potential use of transcribers for other tasks such as dialogue act tagging and disfluency tagging, and the need for more meeting data.\n\nImproving waveforms through pre-processing techniques and post-processing methods to separate speakers or improve signal-to-noise ratio were also discussed. The potential use of visual displays and symbols during transcription was mentioned.\n\nOverall, the meeting provided valuable insights and ideas for further research and development related to talk, neurons, transcriber pool, and acoustic-phonetic analyses."
]