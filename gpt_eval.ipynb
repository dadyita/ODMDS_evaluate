{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import argparse\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load pred and ref\n",
    "path = 'SQuALITY/LLM-embedding/max'\n",
    "ref_files = ['max.json', 'mean.json', 'min.json', 'Academic.json', 'Committee.json', 'Product.json', 'dev.json',\n",
    "             'test.json', 'test.json']\n",
    "references = []\n",
    "for ref_file in ref_files:\n",
    "    file_path = os.path.join(path, ref_file)\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            item_ref = json.load(f)\n",
    "        item_ref = [data_item['Summary_1'] for data_item in item_ref]\n",
    "        references.extend(item_ref)\n",
    "\n",
    "references = references[250:510]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "pred_files = ['gpt3_summary_' + item for item in ref_files]\n",
    "\n",
    "for pred_file in pred_files:\n",
    "    file_path = os.path.join(path, 'summary/' + pred_file)\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            item_pred = json.load(f)\n",
    "        predictions.extend(item_pred)\n",
    "\n",
    "predictions = predictions[250:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Test score\n",
    "from PACKAGE import asyncThread\n",
    "\n",
    "ej_api_key = \"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\"\n",
    "\n",
    "prompt = open('GPTeval/prompts/con_detailed.txt').read()\n",
    "messages = []\n",
    "for index, prediction in enumerate(predictions):\n",
    "    reference = references[index]\n",
    "    cur_prompt = prompt.replace('{{Document}}', reference).replace('{{Summary}}', prediction)\n",
    "    messages.append([{\"role\": \"system\", \"content\": cur_prompt}])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k-0613\", openai_api_key=ej_api_key, temperature=0.7, max_tokens=600)\n",
    "tokens = [llm.get_num_tokens(str(message)) for message in messages]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response_list = asyncThread.run(messages=messages,\n",
    "                                engine_name=\"gpt-3.5-turbo-16k-0613\",\n",
    "                                temperature=2,\n",
    "                                max_tokens=5,\n",
    "                                top_p=1,\n",
    "                                api_key=ej_api_key,\n",
    "                                requests_per_minute=100)\n",
    "with open('gpt_eval.json', 'w') as f:\n",
    "    temp = json.dumps(response_list)\n",
    "    f.write(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[985,\n 867,\n 863,\n 979,\n 1000,\n 907,\n 696,\n 678,\n 686,\n 611,\n 1243,\n 896,\n 910,\n 834,\n 687,\n 1079,\n 1260,\n 619,\n 981,\n 807,\n 1068,\n 597,\n 613,\n 641,\n 568,\n 1340,\n 566,\n 813,\n 846,\n 531,\n 1066,\n 926,\n 899,\n 660,\n 895,\n 1193,\n 534,\n 578,\n 588,\n 803,\n 1197,\n 740,\n 618,\n 1044,\n 819,\n 1242,\n 584,\n 1053,\n 875,\n 652,\n 1145,\n 541,\n 572,\n 601,\n 631,\n 891,\n 537,\n 498,\n 575,\n 430,\n 1022,\n 751,\n 847,\n 618,\n 623,\n 614,\n 656,\n 542,\n 528,\n 528,\n 956,\n 662,\n 635,\n 602,\n 569,\n 1113,\n 606,\n 641,\n 614,\n 516,\n 974,\n 641,\n 623,\n 786,\n 683,\n 815,\n 686,\n 445,\n 573,\n 780,\n 1050,\n 712,\n 866,\n 1137,\n 724,\n 761,\n 597,\n 537,\n 620,\n 626,\n 751,\n 853,\n 716,\n 638,\n 522,\n 720,\n 496,\n 748,\n 504,\n 645,\n 1067,\n 609,\n 828,\n 657,\n 577,\n 1101,\n 858,\n 1126,\n 983,\n 837,\n 1458,\n 716,\n 799,\n 607,\n 734,\n 928,\n 668,\n 757,\n 450,\n 952,\n 979,\n 495,\n 575,\n 594,\n 584,\n 1196,\n 895,\n 595,\n 1185,\n 522,\n 917,\n 540,\n 674,\n 784,\n 622,\n 950,\n 788,\n 563,\n 495,\n 836,\n 1258,\n 573,\n 667,\n 784,\n 726,\n 1332,\n 686,\n 511,\n 695,\n 535,\n 1024,\n 729,\n 606,\n 530,\n 657,\n 1031,\n 619,\n 658,\n 550,\n 646,\n 1158,\n 573,\n 557,\n 735,\n 486,\n 1016,\n 587,\n 530,\n 588,\n 789,\n 930,\n 682,\n 548,\n 805,\n 525,\n 849,\n 537,\n 471,\n 501,\n 679,\n 979,\n 828,\n 1074,\n 580,\n 587,\n 1045,\n 631,\n 739,\n 534,\n 680,\n 1099,\n 690,\n 632,\n 922,\n 876,\n 1046,\n 804,\n 586,\n 773,\n 791,\n 1009,\n 1009,\n 432,\n 522,\n 509,\n 1038,\n 541,\n 608,\n 735,\n 645,\n 727,\n 658,\n 637,\n 655,\n 560,\n 959,\n 863,\n 662,\n 504,\n 833,\n 1144,\n 617,\n 609,\n 570,\n 872,\n 772,\n 574,\n 784,\n 627,\n 686,\n 1032,\n 693,\n 837,\n 563,\n 646,\n 1024,\n 629,\n 669,\n 788,\n 590,\n 1140,\n 652,\n 1095,\n 771,\n 599,\n 860,\n 651,\n 478,\n 820,\n 645]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752.8192307692308\n"
     ]
    }
   ],
   "source": [
    "print(sum(tokens)/len(tokens))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
